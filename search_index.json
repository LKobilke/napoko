[["index.html", "Continuing education: R 1 Intro to R 1.1 General information on the course 1.2 What can I learn from this tutorial? 1.3 Provisional schedule for this seminar 1.4 What can I do if I have problems with my R code?", " Continuing education: R Lara Kobilke, IfKW, Ludwig-Maximilians-Universität München 2023-07-22 1 Intro to R 1.1 General information on the course Dear colleagues, This online tutorial will accompany my seminar on “Continuing education for employees: R” at the IfKW (Ludwig-Maximilians-Universität München, SS2023). This seminar, part of the WS2023/24 curriculum at the IfKW (Ludwig-Maximilians-Universität München), will be held in person at Oettingenstraße 67, Room to be announced, from the 9th to the 13th of October, 2023, running from 09:00 AM to 15:00 PM (s.t.!). Please note that we will take a break on Wednesday, 11th October 2023, to refresh our minds. For those unable to attend in person due to off-site obligations or caretaker duties, a Zoom link is provided here. I kindly ask that this option be used only under the above-mentioned circumstances, as providing comprehensive mentoring to online attendees can be challenging and a complex hybrid mode may slow down the course progress. The seminar is open to everyone at all times, which means that you may attend at your convenience without any prior registration. However, whenever you decide to attend the seminar, it is imperative that you bring along a laptop so that you may test the R code yourself. Whenever you are unable to attend, this tutorial will be a helpful resource for catching up. Additionally, it provides the flexibility to review and study the material at your own pace. It can also serve as a useful reference book for those who are conducting their first research project in R and need to look up specific functions! 1.2 What can I learn from this tutorial? After completing the entire tutorial, you will have acquired three important skills: Mastery of using R and RStudio for data management and analysis, which will replace SPSS at the IfKW. Understanding the benefits of using R over SPSS. Developing a P A S S I O N for working with R. Each chapter of this tutorial consists of: an introduction to new functions/analysis methods in R, including corresponding R code main take-aways that you should remember information on additional tutorials / sources exercises to practice your new skills (you’ll often work through these with your colleagues) 1.3 Provisional schedule for this seminar Day 1 Morning Session (09.10.2023): Introduction to the teaching concept as well as to R and RStudio. In this session, I will answer all of your burning questions: How is the R course structured? How does it fit into the transition to R at the institute? What packages (i.e., R extensions) will we be working with? Additionally, I will demonstrate how to import a dataset, manipulate it, and generate descriptive results with just a few clicks using RStudio and the tidyverse + tidycomm packages. Lunch (12-12.45 pm) Afternoon Session (09.10.2023): Getting started with Base R. In this session, you will use R as a calculator, work with vectors, and learn to open datasets. The session is designed to help you recognize tutorials and answers in help forums that use Base R and distinguish them from those that use tidyverse R. Later on, you will only use tidyverse R, but you must be able to differentiate it from Base R to find helpful resources on the internet. If time allows, you will be introduced to the logic of the tidyverse metapackage for simplifying your data management. Day 2 Morning Session (10.10.2023): Using the tidyverse metapackage for data management. Part I. Introduction to the logic of tidyverse metapackage for simplifying your data management. You will learn why the tidyverse is A W E S O M E and how easily it allows you to filter, group, and generate descriptions of data. You will also have plenty of time to solve exercises, i.e., to flex your tidyverse skills. Lunch (12-12.45 pm) Afternoon Session (10.10.2023): This last tidyverse session will cover advanced tidyverse operations that we do not teach to our Bachelor students, but that will make your own life as a researcher S O M U C H more enjoyable. These are topics like reading in multiple datasets, merging them, selecting and renaming multiple columns, or applying a function across many columns. Day 3 Morning Session (12.10.2023): Using the ggplot2 package for data visualization. Introduction to the grammar of graphics to create beautiful, publication-ready graphs. You will learn how to create advanced graphs that will enhance your publications. You will also have plenty of time to solve exercises, i.e., to flex your ggplot2 skills. Lunch (12-12.45 pm) Afternoon Session (12.10.2023): Using the tidycomm package to do a quick inspection of new datasets, rescale variables, and run own analyses, e.g., perform significance tests. In this session, we will cover the usual inference tests that we teach our students: chi-square, t-test, ANOVA, and linear regression. We will also have a look at Pearson’s r and partial correlation, of course. Day 4 Morning Session (13.10.2023): We will solve an exercise that covers dplyr, `ggplot2, andtidycomm`. This allows you to recap everything that you’ve learned throughout this seminar. Lunch (12-12.45 pm) Afternoon Session (13.10.2023): Getting started with a good coding style. In this session, we will discuss good coding practices and project management workflows in R. When you first learn how to use R, your primary focus is on getting the job done. However, as you advance, you will want to have well-designed and organized code. By adopting best practices early on and internalizing them, you can make your life easier and streamline your coding process. Note: In the event of any delays or a particularly clever audience ;), changes to the schedule may occur. 1.4 What can I do if I have problems with my R code? Besides asking me during the course ( :) ) there are some great places to have a look at when you encounter problems. To give you a head start, here’s a quick rundown of the three best places to look if you have a problem with your code: R’s integrated help function: Use the ?-function whenever possible. Let’s assume you struggle with creating a histogram for your data (hist function in R). You can open the R documentation of the hist function in R by writing: ?hist Preview of ?hist in R: Search engines: Like Bing or Google. Yup, those who work withR keep googling all the time! Nobody knows all the code and errors by heart. Often you can find perfect answers to your questions on Stackoverflow, StatsExchange, or Rseek because other people had exactly the same problems. And more importantly, the communities on these websites are very friendly and helpful. Packages’ reference manuals: Finally, problems with R packages (we’ll get to packages later, see: Packages) can often be solved by looking at their reference manuals (an overview document containing all of a package’s functions). For example, you can learn more about dplyr (a data management package that we are going to use later in this tutorial) by visiting its reference manual on “CRAN” (Comprehensive R Archive Network), which is R’s main repository: https://cran.r-project.org/web/packages/dplyr/dplyr.pdf. That’s everything there is. I hope you find my class and this tutorial to be a valuable resource on your journey with R. I did not take the easy road to learning R, so I am really looking forward to show you the quick way! I’ve tested (a variation of) this tutorial on 4 classes of BA and MA students in Zurich and Munich before, so don’t be afraid: You got this! Let’s now begin with our first tutorial: Tutorial: Installing &amp; Understanding R/R Studio "],["tutorial-installing-understanding-rr-studio.html", " 2 Tutorial: Installing &amp; Understanding R/R Studio 2.1 What is R? 2.2 Using R is easy! 2.3 Installing R 2.4 Installing R Studio 2.5 Updating R and R Studio 2.6 How does R work? 2.7 Why should I use R? 2.8 How does R Studio work? 2.9 Why aren’t we using a GUI for point-and-click analyses? 2.10 Packages 2.11 Take-Aways 2.12 Additional tutorials", " 2 Tutorial: Installing &amp; Understanding R/R Studio After working through Tutorial 1, you’ll… know how to install R and RStudio know how to update R and RStudio understand the layout of RStudio 2.1 What is R? R is the programming language we’ll use to import, edit, and analyze data. It’s original form is called Base R. A more recent and streamlined syntax for R is called the tidyverse. Base R and the tidyverse are both popular approaches to data manipulation and analysis in R, but they differ in their philosophies and syntax. Base R is the set of core functions that come with the R programming language without any additional installations. These functions allow you to perform a wide range of data manipulation and analysis tasks, including reading and writing data, transforming and summarizing data, and creating visualizations. Base R is designed to be efficient and flexible, and it provides a lot of low-level functionality for working with data. The tidyverse, on the other hand, is a collection of R packages (thus called a “meta-package”) developed by Hadley Wickham and his team at RStudio. The tidyverse is very readable code: You can usually read the code out loud and understand what it is doing. Moreover, the tidyverse is built around a set of principles and syntax that emphasize the importance of tidy data, i.e. data that is organized into rows and columns, where each column represents a variable and each row represents an observation. As you can see: tidy data looks just like your typical SPSS data window! Our approach to teaching our BA students is to use the tidycomm package developed by Julian Unkel. It uses the tidyverse style of coding, but incorporates many convenience functions for communication researchers, such as calculating ICR tests (e.g., Krippendorff’s alpha or Fretwurst’s lotus). Julian, Mario Haim, and I are currently enhancing the package to greatly simplify data analysis for our students as compared to using SPSS. For example, with each significance test tidycomm will automatically provide students suitable graphical visualizations. To convince yourself of the ease of working with tidycomm, please refer to the following section: Using R is easy! A hint for best practice: Usually, R users decide to use either Base R or the tidyverse at some point. When writing code, it’s a good practice to stick two one of the two approaches, Base R or tidyverse, and not mix them up because that makes the code less readable (just like writing in German dialect, Bavarian and East Frisian are both German, but a Bavarian will struggle more when reading a text that is partly written in East Frisian). The approach of this tutorial is to use the first lesson to teach you a little bit of Base R – just enough that you are able to identify code as being written in Base. This way, you can distinguish helpful answers in online forums that are written in “your dialect” (i.e. tidyverse R) from those that are not written in your dialect (i.e., Base R). After that first lesson, we will stick to the tidyverse approach because it is so much more similar to SPSS and much more readable and easy-to-learn for beginners. R and (meta-)packages covered in this course: 2.2 Using R is easy! R programming can be made easy with the usage of tidyverse and tidycomm. Allow me to demonstrate this by importing the well-known Worlds of Journalism data into R, filtering out all non-German journalists, describing the data using descriptive statistics, and analyzing it with an ANOVA. Loading data into R using the menu via File &gt; Import Dataset &gt; [your data type, e.g. SPSS: Choose your data in your folders and hit “Import” Let’s activate the tidyverse and tidycomm packages (we will come back to this later in the Packages section): library(tidyverse) library(tidycomm) And now, let us filter our data to include only German journalists in the dataset. WoJ &lt;- WoJ %&gt;% filter(country == &quot;Germany&quot;) Looks great! Now let’s describe our data. Let’s get some descriptives for the variable “reach”, i.e., whether the journalists are working for regional or national outlets. WoJ %&gt;% describe_cat(reach) ## # A tibble: 1 × 6 ## Variable N Missing Unique Mode Mode_N ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; ## 1 reach 173 0 3 Regional 80 Repeat this for the variable “autonomy_selection,” which refers to the level of autonomy that journalists feel they have in their daily work life. WoJ %&gt;% describe(autonomy_selection) ## # A tibble: 1 × 15 ## Variable N Missing M SD Min Q25 Mdn Q75 Max Range ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonomy_select… 172 1 3.97 0.881 1 3 4 5 5 4 ## # ℹ 4 more variables: CI_95_LL &lt;dbl&gt;, CI_95_UL &lt;dbl&gt;, Skewness &lt;dbl&gt;, ## # Kurtosis &lt;dbl&gt; It’s time to run an ANOVA with the two variables! IV = reach, DV = autonomy_selection. WoJ %&gt;% unianova(reach, autonomy_selection, descriptives = TRUE, post_hoc = TRUE) ## # A tibble: 1 × 15 ## Variable F df_num df_denom p eta_squared M_Local SD_Local M_Regional ## * &lt;chr&gt; &lt;num&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;num&gt; &lt;num:.3!&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonomy_… 9.450 2 169 0.000 0.101 4.28 0.743 4.04 ## # ℹ 6 more variables: SD_Regional &lt;dbl&gt;, M_National &lt;dbl&gt;, SD_National &lt;dbl&gt;, ## # post_hoc &lt;list&gt;, Levene_p &lt;dbl&gt;, var_equal &lt;chr&gt; That was pretty easy, wasn’t it? 2.3 Installing R When you are ready to install R, use Cran to install the newest version of Ra nd its GUI (graphical user interface) (version 4.2.3, realeased 2023-03-15, called “Shortstop Beagle”). You’ll have to specify your operation system to download the right version: Installer for Windows Installer for macOS 10.13 (High Sierra) and higher Installer for macOS 11 (Big Sur) and higher Mac Users: Please read the documentation of the installers on this site. You might need to install other dependencies to make R work. 2.4 Installing R Studio Next, install R Studio. R Studio is a desktop application with a graphical interface that facilitates programming with R. The newest version of R Studio can be downloaded via this Link. 2.5 Updating R and R Studio If you have already installed R and RStudio, please update your current version to the latest version. This way, we’ll all know that our versions are compatible. 2.5.1 On Windows Updating on Windows is tricky. Therefore, you can use a package called installr, which helps you manage your update. First, install the installr package in the R GUI (not RStudio!). Use the following code by copy-pasting it into the RStudio console and running it: # installing/loading the package: if (!require(installr)) { install.packages(&quot;installr&quot;) require(installr) } # load / install+load installr After you have run the above code, let’s start the updating process of your R installation by using the updateR() function. It will check for newer versions, and if one is available, will guide you through the decisions you’d need to make. You need to to copy the below code to your console and run it: # using the package: updateR() Finally, update R Studio. Updating RStudio is easy, just open RStudio and go to Help &gt; Check for Updates to install a newer version. 2.5.2 On MAC Go to CRAN and install the newer package installer. After that update R Studio. Updating RStudio is easy, just open RStudio and go to Help &gt; Check for Updates to install a newer version. 2.6 How does R work? R is an object- and function-oriented programming language. Chambers (2014, p. 4) explains “object- and function-oriented” like this: Everything that exists is an object. Everything that happens is a function call. In R, you will assign values (for instance, single numbers/letters, several numbers/letters, or whole data files) to objects in R to work with them. For example, this command will assign the letters “hello” to an object called word by using the assign operator &lt;- (a function used to assign values to objects): word &lt;- &quot;hello&quot; The type of each object will dictate what sorts of computations you may perform with this object. The object word, for example, is distinguished by the fact that it is made up of characters (i.e., it is a word) - which may make it impossible to compute the object’s mean value, for example (which is possible only for objects consisting of numerical data). 2.7 Why should I use R? There are several reasons why I’m an advocate of R (or similar programming languages such as Python) over programs such as SPSS. R is free. Other than most other (statistical) programs, you do not need to buy it (or rely on an university license, that is likely to run out once you leave your department). R is an open source program. Other than most other programs, the source code - i.e., the basis of the program - is freely available. So are the hundred of packages (we’ll get to those later – these are basically additional functions you may need for more specific analyses) on CRAN that you can use to extend R’s base functions. R offers you flexibility. You can work with almost any type of data and rely on a large (!) set of functions to import, edit, or analyze such data. You can perform “complex” statistical modeling like SEM, panel analysis, multilevel analysis, and computational methods in R. And if the function you need to do so hasn’t been implemented (or simply does not exist yet), you can write it yourself! R supports package development! Learning R increases your chances of on the job market. For many jobs (e.g., market research, data science, data journalism), applicants are required to know at least one programming language. You can even write your homework in R (using RMarkdown). This allows for the complete reproducibility of your analysis and report. All of the code, data, and visualizations can be easily shared and reproduced, ensuring transparency and enhancing the credibility of your work. Conveniently, documents can automatically update tables and graphs when changes are made to the underlying data or analysis. This saves time and reduces the likelihood of errors when updating results. 2.8 How does R Studio work? As mentioned before, R Studio is a graphical interface which facilitates programming with R. It contains up to four main windows, which allow for different things: Writing your own code (Window 1: Source). Important: When first installing R/R Studio and opening R Studio, you may not see this window right away. In this case, simply open it by clicking on File/New File/R Script. Executing your own code (Window 2: Console) Inspecting objects (Window 3: Environment) Visualizing data, searching for help, updating packages etc. (Window 4: Files/Plots/Packages etc.) Image: Four main windows in R Please note that the specific set-up of your R Studio may look different (the order of windows may vary and so may the windows’ names). I have made the experience that having these four windows open works best for me. This may be different for you. If you want to modify the appearance of your R Studio, simply choose “Tools/Global Options/Pane Layout”. In the options menu, you can perform various cool customizations, such as enabling rainbow parentheses (highly recommended). With this feature, a starting parenthesis will be displayed in the same color as its corresponding closing parenthesis. Image: Changing the Layout Image: Activating rainbow parantheses 2.8.1 Source: Writing your own code Using the window “Source”, you’ll write your own code to execute whichever task you want R to fulfill. 2.8.1.1 Writing Code Let’s start with an easy example: Assume you simply want R to print the word “hello”. In this case, you would first write a simple command that assigns the word “hello” to an object called word. The assignment of values to named objects is done via either the operator “&lt;-” or the operator “=”. The left side of that command contains the object that should be created; its right side the values that should be assigned to this object. In short, this command tells R to assign the world “hello” to an object called word. word &lt;- &quot;hello&quot; Image: “Source” 2.8.1.2 Annotating Code Another helpful aspect of R is that you can comment your own code. Often, this is very helpful for understanding your code later (if you write several hundred lines of codes, you may not remember their exact meaning months later). Comments or notes can be made via hashtags #. Anything following a hashtag will not be considered code by R but be ignored instead. word &lt;- &quot;hello&quot; # this line of code assigns the word &quot;hello&quot; to an object called word 2.8.1.3 Executing Code We now want to execute our code. Doing so is simple: Mark the parts of the code you want to run (for instance, single rows of code or blocks of code across several rows) Either press Run (see upper right side of the same window) or press Ctrl / Command + Enter (On Mac OS X, hold the command key and press return instead). R should now execute exactly those lines of codes that you marked (hereby creating the object word). If you haven’t marked any specific code, all lines of code will be executed. Image: Executing Code 2.8.1.4 Saving Code A great feature of R is that it makes analyses easily reproducible - given that you save your code. When reopening R Studio and your script, you can simply “rerun” the code with one click and your analysis will be reproduced. To save code, you have two options: Choose the menu option File/Save as. Important: Code needs to be saved with the ending “.R”. Chose the Save-button in the source window and save your code in the correct format, for instance as “MyCode.R” (some advice: try to avoid numbers or dates as file names because this can break the saving process). Image: Saving code 2.8.2 Console: Printing results Results of executing code are printed in a second window called “Console”, which includes the code you ran and the object you may have called when doing so. Previously, we defined an object called word, which consists of the single word “hello”. Thus, R prints our code as well as objects called when running this code (here, the object word) in the console. word &lt;- &quot;hello&quot; word ## [1] &quot;hello&quot; Image: Window “Console” 2.8.3 Environment: Overview of objects The third window is called “Environment”1. This window displays all the objects currently existing - in our case, only the object “word”. As soon as you start creating more objects, this environment will fill up. If you are an SPSS user, you may find this window very similar to what is referred to as the Datenansicht / Data overview in SPSS. However, the R version of this view is much more flexible as it can contain multiple datasets simultaneously in one environment. Image: Window “Environment” It is important to note that we can visually examine any object in R by using the View() command. Upon running this command, a new tab will open in the “Source” window. While this may not seem particularly useful at the moment, it becomes immensely helpful when working with larger datasets that have multiple observations and variables. View(word) Image: Window “View” 2.8.4 Plots/Help/Packages: Do everything else The fourth window in the standard R Studio interface, which contains several sub-sections like “Files”, “Plots”, or “Packages”, has specific functions that you will understand later. For example, it can be used to plot and visualize results or to see which packages are currently loaded. Image: Window “Files/Plots/Packages” 2.9 Why aren’t we using a GUI for point-and-click analyses? If you now SPSS, you might miss having a graphical user interface (GUI) in RStudio for point-and-click analyses. For those who prefer such a GUI, they can install jamovi, which is a GUI for R. However, I’d recommend against using jamovi. The reason for this is that coding skills allow for faster adaptation of the written syntax to fit individual needs. Those who first learn to handle a statistics program through point-and-click may have a weaker understanding of the resulting code. If adjustments to the code need to be made later on, you may not be able to do so, and analyses may need to be redone completely by clicking instead of quickly adapting them throughout the script (e.g., withSearch + Replace). Thus, starting to code early helps with understanding and efficiency. 2.10 Packages While Base R, i.e., the standard version of R, already includes many helpful functions, you may at times need other, additional functions. For instance, if we want to perform text analysis in R we’ll need to use specific packages including additional functions. Packages are collections of topic-specific functions that extend the functions implemented in Base R. In the spirit of “open science”, anyone can write and publish these additional functions and related packages and anyone can also access the code used to do so. You’ll find a list of all of R packages here. In this seminar, we’ll for instance use packages like dplyr for advanced data management. 2.10.1 Installing packages To use a package, you have to install it first. Let’s say you’re interested in using the package dplyr. Using the command install.packages(), you can install the package on your computer. You’ll have to give the function the name of the package you are interested in installing. install.packages(&quot;dplyr&quot;) After the installation, the package is now available locally on your computer. It is important to note that the install.packages() command only needs to be executed once for each package. In subsequent R sessions (e.g., after closing RSTudio and reopening it the next day), you only need to activate the installed package, which we will learn in the following section. 2.10.2 Activating packages Before we are able to use a package, we need to activate it in each session. Thus, you should not only define a working directory at the beginning of each session but also activate the packages you want to use via the library()_ command. Again, you’ll have to give R the name of the package you want to activate: library(dplyr) You can also use the name of the package followed by two colons :: to activate a package directly before calling one of its functions. For instance, I do not need use to activate the dplyr package (by using the library() function) to use the function summarize() if I use the following code: dplyr::summarize() 2.10.3 Getting information about packages The package is installed and activated - but how can we use it? To get an overview of functions included in a given package, you can consult its corresponding “reference manual” (overview document containing all of a package’s functions) or, if available, its “vignette” (tutorials on how to use selected functions for the corresponding package) provided by a package’s author on a website called “CRAN”. The easiest way to finding these manuals/vignettes is Google: Simply google CRAN dplyr, for instance, and you’ll be guided to the following website: Image: Cran Overview dplyr package The first paragraph (circled in red) gives you an overview of aspects for which this package may be useful. The second red-circled area links to the reference manual and the vignette. You can, for instance, check out the reference manual to get an idea of the many functions the dplyr package contains. 2.11 Take-Aways Window “Source”: used to write/execute code in R Window “Console”: used to return results of executed code Window “Environment”: used to inspect objects on which to use functions Window “Files/Plots/Packages etc.”: used for additional functions, for instance visualizations/searching for help/activating or updating packages 2.12 Additional tutorials You still have questions? The following tutorials &amp; papers can help you with that: YaRrr! The Pirate’s Guide to R by N.D.Phillips, Tutorial 2 Computational Methods in der politischen Kommunikationsforschung by J. Unkel, Tutorial 1 SICSS Boot Camp by C. Bail, Video 1 wegweisR by M. Haim, Video 1 R Cookbook by Long et al., Tutorial 1 Now that you know the layout of R, we can get started with some real action: Tutorial: Using R as a calculator again, this only applies for the way I set up my R Studio. You can change this via “Tools/Global Options/Pane Layout”↩︎ "],["tutorial-using-r-as-a-calculator.html", " 3 Tutorial: Using R as a calculator 3.1 Using variables for calculation 3.2 Using vectors for calculation 3.3 Selecting values from a vector 3.4 Take-Aways 3.5 Additional tutorials", " 3 Tutorial: Using R as a calculator After working through Tutorial 2, you’ll… be able to work with mathematical operators in R be able to use mathematical operators on variables and vectors subset values from vectors One of the first things everyone learns in R is to use R as a calculator. You have access to many mathematical operators in R (e.g. +, -, *, /, ^). Let’s try some of them. Addition: 5 + 7 ## [1] 12 Subtraction: 12 - 7 ## [1] 5 Exponentiation: 3^3 ## [1] 27 3.1 Using variables for calculation You can also assign numbers to variables with the assign operator “&lt;-”. We have already talked about assigning word or numbers to variables in the chapter Writing Code. Please remember that a variable name in R can include numeric and alphabets along with special characters like dot (.) and underline (_).’ Therefore, these are good options to name your variables: my_1st_number &lt;- 3 my.1st.numer &lt;- 3 Do ! N O T ! use these variable names because they will cause errors and throw warning messages. I have therefore put the code as annotation to avoid the warning messages (with #): # _number &lt;- 3 # .number &lt;- 3 # my-1st-number &lt;- 3 You can use variables in your calculations by assigning the numbers to variables (i.e. store the numerical value in the variable).’ five &lt;- 5 seven &lt;- 7 twelve &lt;- five + seven # here you add the two variables in which the numbers are stored. The result of the addition is stored in the variable &quot;twelve&quot; twelve # now you have to retrieve the content of the variable, so that the result is printed to the console ## [1] 12 The names of the variables are freely selectable. For example, you can also proceed like this: three &lt;- 5 three # print the content of the variable to the console ## [1] 5 3.2 Using vectors for calculation You can also store more than one number in a variable. We call this process “creating vectors” because variables that contain more than one number are called “vectors” in R. Vectors are created using the combine function c() in R. twelve &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12) twelve # print the content of the variable to the console ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 Again, the variable name is chosen arbitrarily. You can also do this: twelve &lt;- c(4, 10, 15, 21, 33) twelve # print the content of the variable to the console ## [1] 4 10 15 21 33 You can use mathematical operations on vectors (e.g., +, -, * and /). Let’s create two vectors “weight” and “height” that contain the weight and height measures of 6 individuals. For example, the first individual weighs 60 kg and is 1.75 m tall: weight &lt;- c(60, 72, 57, 90, 95, 72) height &lt;- c(1.75, 1.80, 1.65, 1.90, 1.74, 1.91) Now we can calculate the Body Mass Index (BMI) using the BMI formula: BMI &lt;- weight / height^2 BMI # print the content of the BMI variable to the console ## [1] 19.59184 22.22222 20.93664 24.93075 31.37799 19.73630 Now we know that the first person has a BMI of 19.59, which is within the range of normality (18.5 and 24.9). 3.3 Selecting values from a vector We still see the BMI of all the other five people, i.e. the entire vector. How can we select only the first person? You can select values from a vector by using square brackets [ ] and enter the number of the entry that you want to print to your console. BMI[1] ## [1] 19.59184 Again, you can see that the first person has a BMI of 19.59. You could also decide to look at all values except the first one: BMI[-1] ## [1] 22.22222 20.93664 24.93075 31.37799 19.73630 You can even use the [ ] selector on vectors that consist of words instead of numbers. These vectors are called “character vectors”, while vectors that contain numbers are called “numeric vectors”. Let’s create a character vector that contains the BMIs of the six individuals as words. We’ll need to put quotation marks around your entries so that R knows that those values are words not numbers. BMI_word &lt;- c(&quot;nineteen&quot;, &quot;twenty-two&quot;, &quot;twenty&quot;, &quot;twenty-four&quot;, &quot;thirty-one&quot;, &quot;nineteen&quot;) BMI_word ## [1] &quot;nineteen&quot; &quot;twenty-two&quot; &quot;twenty&quot; &quot;twenty-four&quot; &quot;thirty-one&quot; ## [6] &quot;nineteen&quot; We’ll now select only the first value of of this BMI_word character vector: BMI_word[1] ## [1] &quot;nineteen&quot; If you want to select multiple values, you can index them. Let’s select the BMI of the third, fourth and fifth individual: BMI_word[3:5] ## [1] &quot;twenty&quot; &quot;twenty-four&quot; &quot;thirty-one&quot; 3.4 Take-Aways Mathematical operators: use +, -, *, /, ^ Use case: use these operators on numbers, variables, and vectors Create vectors: use the combine function c() Select values from vectors: use square brackets [ ] 3.5 Additional tutorials You still have questions? The following online guides can help you with that: Using R as a Calculator R Vector Now it’s your time to get into coding: Try Exercise 1: Base R. "],["exercise-1-base-r.html", "Exercise 1: Base R Task 1 Task 2 Task 3", " Exercise 1: Base R After working through Exercise 1, you’ll… have assessed how well you know R and RStudio know what chapters and concepts you might want to repeat again have managed to apply the basic concepts of R to data Task 1 Below you will see multiple choice questions. Please try to identify the correct answers. 1, 2, 3 and 4 correct answers are possible for each question. 1. What panels are part of RStudio? source console input packages, files &amp; plots 2. How do you activate R packages after you have installed them? import.packages() install.packages() package() library() 3. How do you create a vector in R with elements 1, 2, 3? cbind(1,2,3) cb(1,2,3) c(1,2,3) cmb(1,2,3) 4. Imagine you have a vector called ‘vector’ with 10 numeric elements. How do you retrieve the 8th element? vector[-2] vector[„-2”] vector[8] vector[„8”] 5. Imagine you have a vector called ‘hair’ with 5 elements: brown, black, red, blond, other. How do you retrieve the color ‘blond’? hair[4] hair[„4”] hair[blond] hair[„blond”] Task 2 Create a numeric vector with 8 values and assign the name age to the vector. First, display all elements of the vector. Then print only the 5th element. After that, display all elements except the 5th. Finally, display the elements at the positions 6 to 8. Task 3 Create a non-numeric, i.e. character, vector with 4 elements and assign the name eye_color to the vector. First, print all elements of this vector to the console. Then have only the value in the 2nd element displayed, then all values except the 2nd element. At the end, display the elements at the positions 2 to 4. When you’re ready to look at the solutions, you can find them here:Solutions for Exercise 1. "],["tutorial-working-with-data-files.html", " 4 Tutorial: Working with data (files) 4.1 Defining your working directory 4.2 Import data from your working directory 4.3 Subsetting variables / columns in data frames 4.4 Subsetting observations / rows in data frames 4.5 Subsetting values / cells in data frames 4.6 Subsetting data with conditions 4.7 Optional: Import data from various file formats 4.8 Take-Aways 4.9 Additional tutorials", " 4 Tutorial: Working with data (files) After working through Tutorial 3, you’ll… understand how to import data know how to select variables in data frames know how to access values in data frames 4.1 Defining your working directory In most cases, you don’t want to manually enter all your values into R and combine them with the c() function. Instead, you’ll likely want to import data files that you already have on your personal computer or drive. Therefore, the first step to importing your data into R is usually to define your working directory. Your working directory is the folder from which data can be imported into R or to which you can export and save data created with R. Create a folder that you want to use as your working directory for this tutorial (or use an existing one). For this example, I’ll create a folder called “IPR” (short for In Public Repository, since this is a public tutorial). Go to that folder and copy the folder path to it: Image: Working Directory on Windows Image: Copy Working Directory on Windows On Mac, you go to a document in your folder and right click on it. An options menu opens and you can copy the folder path: Image: Copy Working Directory on MAC Now you know where this working directory is located - but R should know too! Telling R from which folder to import data or where to export data is called setting your working directory. We use a function called setwd() (you guessed it right: short for “set working directory”) which allows us to do exactly that. Important: The way this working directory is set differs between Windows- and Mac-Operating Systems. Windows: The dashes need to be pointing towards the right direction (if you simply copy the path to the folder, you may need to replace these signs “\\” with “/”) setwd(&quot;C:/Users/LaraK/Documents/IPR&quot;) Mac: You may need to add a “/” at the beginning like so: setwd(&quot;/Users/LaraK/Documents/IPR&quot;) NOTE: Setting your entire desktop as the working directory rarely works. It’s better to create a new folder on your desktop and set that folder as your working directory. If you have forgotten where you set your current working directory, you can also ask R about the path of your current working directory with getwd(): getwd() ## [1] &quot;C:/Users/LaraK/Documents/IPR&quot; 4.1.1 Optional: Setting the working directory on a remote desktop The LMU Munich provides you with remote desktop access to the PCs in the local CIP-Pools. If you want to use your remote desktop to run R &amp; RStudio, you can follow this link to log into the remote desktop. This is a great fix if – for whatever reason – you can’t get R(Studio) installed on your machine and need a quick solution! Once you have logged in to the remote desktop, you can open RStudio and set the working directory (and import data) just like it is described in this tutorial (see next image). Image: Working Directory (&amp; Data Import) on a Remote Desktop The drawback: Since Windows does not allow RStudio to save script files without permission, you can’t save script files on the remote desktop. You can solve this with a workaround: Paste your script into a text file before closing RStudio. E.g., WordPad is pre-installed. Save this file as .R. When you want to load your script in RStudio, right click on the .R file and choose “open with RStudio”. Image: Saving a Script File on a Remote Desktop 4.2 Import data from your working directory After setting the working directory, you need to transfer the data file that you want to work with to that folder (here: the “IPR” folder). To do this, download the “WoJ.csv” file from LRZ Sync &amp; Share using this link. The dataset is a subset of the Worlds of Journalism 2012-16 study containing survey data from 40 journalists from five European countries. Put the downloaded data file in the folder that you just set up as your working directory (here: the “IPR” folder). The data file WoJ.csv is structured as follows: Each row contains the survey answers of a single journalist. Each column contains the values given by all journalists for a single variable. The variables included here are: country: the home country of the journalist (e.g. Germany, Switzerland) reach: the reach of the outlet that the journalist is working for (Transnational, National, Regional, Local) employment: the journalist’s current employment status (Full-time, Part-time, Freelancer) temp_contract: the journalist’s type of contract (Permenent, Temporary) autonomy_selection: how much autonomy the journalist indicates to have in his/her daily work (from 1 = none at all to 5 = very much) work_experience: in years trust_parliament &amp; trust_government: how much trust the journalist indicates to have (from 1 = none at all to 5 = very much) We will read in the file using read.csv(). We specify the file path in quotation marks to indicate where to find the data file. However, if you have already set your working directory to the folder where the file is located, you don’t need to specify the path. Additionally, we use the argument header = TRUE to let R know that the first row contains variable names. Finally, we assign the data file to a source object named survey (but you could choose a different name for your source object like WoJ or data). The data is now stored in this object. survey &lt;- read.csv(&quot;WoJ.csv&quot;, header = TRUE) ## country reach employment temp_contract autonomy_selection ## 1 Germany National Full-time Permanent 5 ## 2 Germany National Full-time Permanent 3 ## 3 Switzerland Regional Full-time Permanent 4 ## 4 Switzerland Local Part-time Permanent 4 ## 5 Austria National Part-time Permanent 4 ## 6 Switzerland Local Freelancer &lt;NA&gt; 4 ## 7 Germany Local Full-time Permanent 4 ## 8 Denmark National Full-time Permanent 3 ## 9 Switzerland Local Full-time Permanent 5 ## 10 Denmark National Full-time Permanent 2 ## 11 Austria Local Full-time Permanent 5 ## 12 Denmark National Freelancer &lt;NA&gt; 4 ## 13 UK Regional Full-time Permanent 3 ## 14 UK Transnational Full-time Permanent 4 ## 15 Austria National Full-time Permanent 3 ## 16 Denmark National Freelancer &lt;NA&gt; 5 ## 17 UK Transnational Full-time Permanent 4 ## 18 Switzerland Regional Full-time Permanent 4 ## 19 Switzerland National Part-time Permanent 4 ## 20 Denmark National Full-time Permanent 4 ## work_experience trust_parliament trust_government ## 1 10 3 3 ## 2 7 4 4 ## 3 6 4 4 ## 4 7 4 4 ## 5 15 3 2 ## 6 27 4 4 ## 7 24 2 1 ## 8 11 4 3 ## 9 25 1 1 ## 10 4 3 3 ## 11 8 3 2 ## 12 25 3 3 ## 13 10 3 2 ## 14 5 3 2 ## 15 23 3 2 ## 16 25 4 2 ## 17 11 2 3 ## 18 8 3 3 ## 19 32 3 4 ## 20 21 3 3 NOTE: While read.csv() reads in comma-separated values, read.csv2() reads in values that are separated by semicolons. To make the dataset a little more tangible, we will give the journalists 40 different fictitious names. The names will be saved into a new column in the dataset, which we will call name. Please run this code to add names to your data: survey$name &lt;- c( &quot;Rosalie&quot;, &quot;Laurens&quot;, &quot;Florian&quot;, &quot;Chantal&quot;, &quot;Cynthia&quot;, &quot;Paul&quot;, &quot;Jonas&quot;, &quot;Tanja&quot;, &quot;David&quot;, &quot;Ferdinand&quot;, &quot;Caroline&quot;, &quot;Charline&quot;, &quot;Sev&quot;, &quot;Theodor&quot;, &quot;Helke&quot;, &quot;Joshua&quot;, &quot;Jona&quot;, &quot;Konrad&quot;, &quot;Lennart&quot;, &quot;Luise&quot;, &quot;Wiebke&quot;, &quot;Marie&quot;, &quot;Rosa&quot;, &quot;Alma&quot;, &quot;Ida&quot;, &quot;Jean&quot;, &quot;Leonie&quot;, &quot;Tom&quot;, &quot;Maximilian&quot;, &quot;Viktor&quot;, &quot;Marianne&quot;, &quot;Velma&quot;, &quot;Carl&quot;, &quot;Wolf&quot;, &quot;Merten&quot;, &quot;Tong-Tong&quot;, &quot;Sal&quot;, &quot;Joe&quot;, &quot;Alex&quot;, &quot;Robin&quot; ) 4.3 Subsetting variables / columns in data frames In the Tutorial: Using R as a calculator, your variables were “floating” in your workspace or environment. They were not stored in a container, so you could call them by simply writing their name in the console. When you import data files into R, all variables in that dataset are stored in a “container,” which is your source object. These containers for variables are called data frames in R. Variables that are part of a data frame can be accessed by their name, but we need to specify the data frame AND the variable name and combine them with the access operator: $. This takes the form of: dataframe$variablename # the first part is the container name, i.e. data frame # this is followed by the access operator $ # finally, you call the variable by name For instance, we could retrieve the variable / column “name” in our survey data frame by simply using its variable name: We specify the object we want to access, the data frame survey and then retrieve the column name via the operator $: survey$name ## [1] &quot;Rosalie&quot; &quot;Laurens&quot; &quot;Florian&quot; &quot;Chantal&quot; &quot;Cynthia&quot; ## [6] &quot;Paul&quot; &quot;Jonas&quot; &quot;Tanja&quot; &quot;David&quot; &quot;Ferdinand&quot; ## [11] &quot;Caroline&quot; &quot;Charline&quot; &quot;Sev&quot; &quot;Theodor&quot; &quot;Helke&quot; ## [16] &quot;Joshua&quot; &quot;Jona&quot; &quot;Konrad&quot; &quot;Lennart&quot; &quot;Luise&quot; ## [21] &quot;Wiebke&quot; &quot;Marie&quot; &quot;Rosa&quot; &quot;Alma&quot; &quot;Ida&quot; ## [26] &quot;Jean&quot; &quot;Leonie&quot; &quot;Tom&quot; &quot;Maximilian&quot; &quot;Viktor&quot; ## [31] &quot;Marianne&quot; &quot;Velma&quot; &quot;Carl&quot; &quot;Wolf&quot; &quot;Merten&quot; ## [36] &quot;Tong-Tong&quot; &quot;Sal&quot; &quot;Joe&quot; &quot;Alex&quot; &quot;Robin&quot; You know that the name variable is the ninth column of you data frame. Therefore, you can also access this column / variable by calling it by its index number (column index, here: 9). Just like you’ve learned in the Tutorial: Using R as a calculator, you can access sub-elements of a greater object with square brackets [ ]: survey[9] ## name ## 1 Rosalie ## 2 Laurens ## 3 Florian ## 4 Chantal ## 5 Cynthia ## 6 Paul ## 7 Jonas ## 8 Tanja ## 9 David ## 10 Ferdinand ## 11 Caroline ## 12 Charline ## 13 Sev ## 14 Theodor ## 15 Helke ## 16 Joshua ## 17 Jona ## 18 Konrad ## 19 Lennart ## 20 Luise ## 21 Wiebke ## 22 Marie ## 23 Rosa ## 24 Alma ## 25 Ida ## 26 Jean ## 27 Leonie ## 28 Tom ## 29 Maximilian ## 30 Viktor ## 31 Marianne ## 32 Velma ## 33 Carl ## 34 Wolf ## 35 Merten ## 36 Tong-Tong ## 37 Sal ## 38 Joe ## 39 Alex ## 40 Robin Note: While the first command gives you the names as a vector, the second one gives you the names as a data frame object with only one column. This keeps the column header “name” intact. However, if you want to retrieve a vector using the column index, you need to provide two indices: one for the row that you want to select, followed by a comma, and one for the column. Since we want to select all rows, but only column No. 9, we need leave the row No. blank: survey[, 9] # column index = 9 ## [1] &quot;Rosalie&quot; &quot;Laurens&quot; &quot;Florian&quot; &quot;Chantal&quot; &quot;Cynthia&quot; ## [6] &quot;Paul&quot; &quot;Jonas&quot; &quot;Tanja&quot; &quot;David&quot; &quot;Ferdinand&quot; ## [11] &quot;Caroline&quot; &quot;Charline&quot; &quot;Sev&quot; &quot;Theodor&quot; &quot;Helke&quot; ## [16] &quot;Joshua&quot; &quot;Jona&quot; &quot;Konrad&quot; &quot;Lennart&quot; &quot;Luise&quot; ## [21] &quot;Wiebke&quot; &quot;Marie&quot; &quot;Rosa&quot; &quot;Alma&quot; &quot;Ida&quot; ## [26] &quot;Jean&quot; &quot;Leonie&quot; &quot;Tom&quot; &quot;Maximilian&quot; &quot;Viktor&quot; ## [31] &quot;Marianne&quot; &quot;Velma&quot; &quot;Carl&quot; &quot;Wolf&quot; &quot;Merten&quot; ## [36] &quot;Tong-Tong&quot; &quot;Sal&quot; &quot;Joe&quot; &quot;Alex&quot; &quot;Robin&quot; 4.4 Subsetting observations / rows in data frames Using the same indexing technique, you can also select an entire row (i.e., journalist) by providing a row index and leaving the column index blank: survey[1, ] # row index = 1 ## country reach employment temp_contract autonomy_selection work_experience ## 1 Germany National Full-time Permanent 5 10 ## trust_parliament trust_government name ## 1 3 3 Rosalie 4.5 Subsetting values / cells in data frames To subset values of a data set, you can call a variable / column by its name. You just have to specify the data frame, the variable name, AND the row index. For example, to look only at the first name entry in the data, which is Rosalie, you can use the following code: survey$name[1] ## [1] &quot;Rosalie&quot; Now, can you guess how to access the exact same value using the column index instead of the column name? You can enter the row index first, followed by a comma, and then finish with the column index, like this: survey[1, 9] # row index = 1, column index = 9 ## [1] &quot;Rosalie&quot; Of course, you can use complex indexing on data frames. Let’s look at the first ten rows of the eighth (trust_government) and ninth (name) column: survey[1:10, 8:9] ## trust_government name ## 1 3 Rosalie ## 2 4 Laurens ## 3 4 Florian ## 4 4 Chantal ## 5 2 Cynthia ## 6 4 Paul ## 7 1 Jonas ## 8 3 Tanja ## 9 1 David ## 10 3 Ferdinand Or select the second ten rows of the sixth (work_experience) and ninth (name) column: survey[10:20, c(6, 9)] ## work_experience name ## 10 4 Ferdinand ## 11 8 Caroline ## 12 25 Charline ## 13 10 Sev ## 14 5 Theodor ## 15 23 Helke ## 16 25 Joshua ## 17 11 Jona ## 18 8 Konrad ## 19 32 Lennart ## 20 21 Luise 4.6 Subsetting data with conditions Let’s say we want to select all names of journalists who have a work experience of at least 25 years. This time, we’ll need to use a condition to select our rows: survey[survey$work_experience &gt;= 25, 9] ## [1] &quot;Paul&quot; &quot;David&quot; &quot;Charline&quot; &quot;Joshua&quot; &quot;Lennart&quot; ## [6] &quot;Alma&quot; &quot;Ida&quot; &quot;Maximilian&quot; &quot;Viktor&quot; &quot;Marianne&quot; ## [11] &quot;Merten&quot; # Read: I want to select column 9 (name) from the survey data frame # and display all rows in which the work experience column of the survey data frame has a value greater than or equal to 25 Alternatively, if you want to show all columns that belong to journalists who have a work experience of at least 25 years, you would do it like that: survey[survey$work_experience &gt;= 25, ] ## country reach employment temp_contract autonomy_selection ## 6 Switzerland Local Freelancer &lt;NA&gt; 4 ## 9 Switzerland Local Full-time Permanent 5 ## 12 Denmark National Freelancer &lt;NA&gt; 4 ## 16 Denmark National Freelancer &lt;NA&gt; 5 ## 19 Switzerland National Part-time Permanent 4 ## 24 UK Transnational Freelancer &lt;NA&gt; 4 ## 25 Austria National Full-time Permanent 4 ## 29 Austria Regional Full-time Permanent 4 ## 30 Denmark National Freelancer &lt;NA&gt; 4 ## 31 Denmark National Full-time Permanent 4 ## 35 Denmark National Full-time Permanent 4 ## work_experience trust_parliament trust_government name ## 6 27 4 4 Paul ## 9 25 1 1 David ## 12 25 3 3 Charline ## 16 25 4 2 Joshua ## 19 32 3 4 Lennart ## 24 29 4 4 Alma ## 25 30 3 3 Ida ## 29 30 3 3 Maximilian ## 30 35 3 3 Viktor ## 31 25 3 3 Marianne ## 35 29 3 3 Merten Of course, you can index more than one column: survey[survey$work_experience &gt;= 25, 8:9] ## trust_government name ## 6 4 Paul ## 9 1 David ## 12 3 Charline ## 16 2 Joshua ## 19 4 Lennart ## 24 4 Alma ## 25 3 Ida ## 29 3 Maximilian ## 30 3 Viktor ## 31 3 Marianne ## 35 3 Merten Finally, you can use multiple conditions: survey[survey$work_experience &gt;= 25 &amp; survey$trust_government &lt; 2, ] ## country reach employment temp_contract autonomy_selection work_experience ## 9 Switzerland Local Full-time Permanent 5 25 ## trust_parliament trust_government name ## 9 1 1 David 4.7 Optional: Import data from various file formats R provides a wide range of functions and packages to import data from various file formats such as Excel, SPSS, SAS, Stata, JSON and others. Here, we will focus on some commonly used file formats and the R functions to import them. 4.7.1 Importing data from Excel We will use the readxl package to import data from Excel files. First, we need to install and load the readxl package: # Install and load the &#39;readxl&#39; package install.packages(&quot;readxl&quot;) # run only the first time library(readxl) To import Excel data from your working directory into R, you can now use the read_excel() function: data &lt;- read_excel(&quot;WoJ.xlsx&quot;) This will create a data frame named “data” containing the Excel data. By default, the first row of the Excel file is assumed to contain column names. 4.7.2 Importing data from JSON JSON files are a popular file format for storing structured data, such as data collected from Social Networking Sites. To import data from a JSON file into R, you can use the jsonlite package: # Install and load the &#39;jsonlite&#39; package install.packages(&quot;jsonlite&quot;) # run only the first time library(jsonlite) And import your data: data &lt;- fromJSON(&quot;WoJ.json&quot;) 4.7.3 Importing data from SPSS SPSS files are still commonly used in social science research and you might want to import your current SPSS projects to R. In R, we can import SPSS files using the haven package. # Install and load the &#39;haven&#39; package install.packages(&quot;haven&quot;) # run only the first time library(haven) To import your data into R, use the read_spss() function (here I repeated the entire working directory, but you could only write read_spss(\"WoJ.sav\")): data &lt;- read_spss(&quot;C:/Users/LaraK/Documents/IPR/WoJ.sav&quot;) By default, the read_spss() function will convert user-defined missings to NA (i.e., missings in R). If you want to read variables with user defined missings into R (e.g., keep -9 instead of turning it into NA), you can use the user_na argument: data &lt;- read_spss(&quot;C:/Users/LaraK/Documents/IPR/WoJ.sav&quot;, user_na = TRUE) read_spss reads all your labelled variables in as an object type (i.e., class) called haven_labelled that stores your label information. You can check your label information by inspecting your data in your environment (by default: right-hand side of RStudio). Just click on the blue error next to your source object: Image: Inspecting your labelled data frame NOTE FOR ADVANCED USERS: If you want to add, change, or remove any kind of labels in R, you can use the labelled package: # Install and load the &#39;labelled&#39; package install.packages(&quot;labelled&quot;) library(labelled) To add a label to a variable, use the var_label() function: var_labels &lt;- c( country = &quot;The journalist&#39;s country of origin&quot;, reach = &quot;The reach of the journalist&#39;s outlet&quot;, employment = &quot;The journalist&#39;s employment status&quot;, temp_contract = &quot;The journalist&#39;s type of contract&quot;, autonomy_selection = &quot;The journalist&#39;s perceived autonomy&quot;, work_experience = &quot;The journalist&#39;s work experience in years&quot;, trust_parliament = &quot;The journalist&#39;s trust in the current parliament&quot;, trust_government = &quot;The journalist&#39;s trust in the current government&quot; ) # Creates a vector with your variable labels var_label(data) &lt;- var_labels # Applies the labels to your column variables To add value labels to a variable, use the set_value_labels function: trust_labels &lt;- c(&quot;none at all&quot; = 1, &quot;a little&quot; = 2, &quot;partly&quot; = 3, &quot;a lot&quot; = 4, &quot;very much&quot; = 5) data$trust_parliament &lt;- set_value_labels(data$trust_parliament, .labels = trust_labels) data$trust_government &lt;- set_value_labels(data$trust_government, .labels = trust_labels) To remove a variable label from a variable, use the remove_var_label function: data$trust_parliament &lt;- remove_var_label(data$trust_parliament) And to remove a value label from a variable, use the remove_val_labels function: data$trust_parliament &lt;- remove_val_labels(data$trust_parliament) For a full documentation and a helpful cheat sheet of the labelled package, click this link. It also contains information on how to use the labelled package in combination with the tidyverse. I’ve used Base R in this tutorial. 4.8 Take-Aways Setting the working directory: tells R where your folder with the data is located on your drive, setwd(your_filepath) Import data: after setting the working directory, with read.csv() (comma-separated) or read.csv2() (semicolon-separated) or the package of your choice (e.g., haven) Access variables: either by the access operator $ (dataframe&amp;variablename) or by the column index [,columnNo.] Access values: by indexing, i.e. using [ ] and row + column indices Conditions: you can select rows based on conditions, e.g.: greater &gt;, greater or equal &gt;=, equal ==, and not equal != 4.9 Additional tutorials You still have questions? The following online guides can help you with that: Import CSV Files into R Step-by-Step Guide Subsetting data Indexing into a data structure Now it’s your time to get into coding: Try Exercise 2: Base R. "],["exercise-2-base-r.html", "Exercise 2: Base R Task 1 Task 2 Task 3", " Exercise 2: Base R After working through Exercise 2, you’ll… have double-checked whether you understand how to import data have learned to subset variables in data frames have learned to subset observations and values in data frames Task 1 Download the “WoJ_names.csv” from LRZ Sync &amp; Share (click here) and put it into the folder that you want to use as working directory. Set your working directory and load the data into R by saving it into a source object called data. Note: This time, it’s a csv that is separated by semicolons, not by commas. Task 2 Now, print only the column to the console that shows the trust in the government. Use the $ operator first. Then try to achieve the same result using the subsetting operators, i.e. []. Task 3 Print only the first 6 trust in the government numbers to the console. Use the $ operator first. Then try to achieve the same result using the subsetting operators, i.e. []. When you’re ready to look at the solutions, you can find them here:Solutions for Exercise 2. "],["tutorial-data-management-with-tidyverse.html", " 5 Tutorial: Data management with tidyverse 5.1 Why not stick with Base R? 5.2 Tidyverse packages 5.3 Tidy data 5.4 The pipe operator 5.5 Data transformation with dplyr 5.6 Take-Aways 5.7 Additional tutorials", " 5 Tutorial: Data management with tidyverse After working through Tutorial 4, you’ll… know the advantages of the tidyverse vs. Base R know about different formats of tabular data understand what packages are included in the tidyverse meta-package know how to do data modifications and transformations with dplyr 5.1 Why not stick with Base R? You might wonder why we’ve spent so much time exploring functions in Base R to now learn data management with tidyverse. After all, data management can also be done in Base R, can’t it? I personally recommend that all R beginners should work with the tidyverse as early as possible. There are three reasons supporting my argument: Ease of use: The tidyverse is very accessible for R “beginners”, i.e. its syntax is very easy to understand. It allows you to set goals (i.e. what you want to do with your data) and get you working on these goals very quickly. Definitely more quickly than in Base R! Standard for data management: A few years ago, the tidyverse has become the de facto standard for data management in R. It is a meta-package, which means that it is a collection of distinct packages that all follow the same design principles to make code reading and writing as simple as possible. For example, all functions are named after verbs that indicate exactly what they perform (e.g. filter or summarize). Beautiful graphs: With the tidyverse, all data management steps can be swiftly transferred into beautiful graphs. This is because the most popular graph package in R, ggplot2, is part of the tidyverse. Are you excited now? Then let’s get started! 5.2 Tidyverse packages The tidyverse comes with a great arsenal of topic-specific packages and their respective functions. It includes packages for: tibble: creating data structures like tibbles, which is an enhanced type of data frame readr, haven, readxl: reading data (e.g. readr for CSV, haven for SPSS, Stata and SAS, readxl for Excel) tidyr, dplyr: data transformation, modification, and summary statistics stringr, forcats, lubridate: create special, powerful object types (e.g. stringr for working with text objects, forcats for factors, lubridate for time data) purrr: programming with R ggplot2: graphing/charting The most frequently used packages of the tidyverse can be installed and activated in one go (less frequently used packages like haven might still need to be installed and activated separately): install.packages(&quot;tidyverse&quot;) # install the package (only on the first time) library(tidyverse) # active the package 5.3 Tidy data Dataframes are tabular data. However, data can also have other formats, for example as nested, i.e. hierarchical, lists. In communication research, these other data formats are mainly used by social media and their respective APIs (e.g., “JSON” format). In our course, however, we’ll focus on tabular data. The same data can be represented differently in tables. We perceive some of these representations as tidy, others as messy. While tidy data principles establish a standard for organizing data values inside a data frame and thus all tidy data look the same, every messy dataset is messy in its own way. Take a look at the table below. It shows a Starwars data set that comes pre-installed with the dplyr package. Do you feel the tabled data is messy? Why (not)? ## # A tibble: 10 × 3 ## name body_feature value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Anakin Skywalker height 188 ## 2 Anakin Skywalker mass 84 ## 3 Chewbacca height 228 ## 4 Chewbacca mass 112 ## 5 Darth Vader height 202 ## 6 Darth Vader mass 136 ## 7 Jabba Desilijic Tiure height 175 ## 8 Jabba Desilijic Tiure mass 1358 ## 9 Leia Organa height 150 ## 10 Leia Organa mass 49 Overall, this data is messy. It comes with three messy problems: This body_feature column comprises information relating to both height and weight, i.e. both variables are stored in a single column. As a result, the value column is reliant on the body_feature column; we can’t tell the stored values apart by merely looking at the value column. We always need to check the body_feature column. Consequently, we have issues with vectorized functions (remember, in R, columns in data sets are vectors): We can’t, for example, use the mean() function on the value column to determine the average weight of the Star Wars characters since the height values are also stored there. What do you think of this table? Is it messy? ## # A tibble: 5 × 3 ## name height mass ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Anakin Skywalker 188 84 ## 2 Chewbacca 228 112 ## 3 Darth Vader 202 136 ## 4 Jabba Desilijic Tiure 175 1358 ## 5 Leia Organa 150 49 This table looks tidy! Tidy data is a standard way of mapping the meaning of a dataset to its structure. We determine whether a dataset is messy or tidy depending on how rows, columns and tables are matched up with observations, variables and types. We consider a table tidy when it follows the following golden rules: Columns: Every column is one variable. Rows: Every row is one observation. Cells: Every cell contains one single value. Image: The tidy data principle (Source: R for Data Science) In messy data sets, on the other hand… Column headers are values, not variable names. Multiple variables are stored in one column. Variables are stored in both rows and columns. Multiple types of observational units are stored in the same table. A single observational unit is stored in multiple tables. Why should you be concerned about tidy data organization? There are two major advantages: When you have a consistent data structure, it is easier to learn the respective tools that work well with this data structure. dplyr, ggplot2, and all the other tidyverse packages are designed for working with tidy data. Putting variables in columns makes R’s vectorized nature shine. The majority of built-in R-functions (like the mean() function) works with vectors of values. As a result, the tidy reorganization of data seems only natural for a good work flow in R. If you have been working mainly with survey data, then you will already be familiar with these basic rules, as data export from survey software usually follows these principles. However, “real-world” data from databases or social media often does not follow these principles. That’s why it’s sometimes true to say that 80% of data analysis is spent on cleaning and transforming data. 5.4 The pipe operator Truly, dplyr is my favorite tidyverse package (even more so than ggplot2, which we’ll cover later!). It allows you to perform powerful data transformations in just a few simple steps. To this end, dplyr relies on the pipe operator (%&gt;%).2 The %&gt;% operator allows functions to be applied sequentially to the same source object in a concise manner, so that step-by-step transformations can be applied to the data. Therefore, we always call the source object first and then add each transformation step separated by the %&gt;% operator. Let’s illustrate this concept with an example. We’ll use the Starwars data set that you are already familiar with. starwars_data %&gt;% # First, we define the source object, i.e. the data frame that we want to transform, followed by the pipe operator plot() # Second, we specify which function should be performed on the source object, here: scatterplot Now, that’s not very impressive. We could do the same in Base R like this: plot(starwars_data) However, dplyr gets really impressive when you chain functions sequentially. You can apply certain selection criteria to your data and plot it in one go. For example, we might exclude the variable name from our scatter plot, since it’s not a metric variable anyway. Also, we might want to look only at those Star Wars characters taller than 170 cm. Let’s try it in a single run! starwars_data %&gt;% # Define the source object select(height, mass) %&gt;% # Keep only the height and mass column filter(height &gt; 170) %&gt;% # Filter all observations that are taller than 170cm plot() # Plot! Now try to do the same in Base R: plot(starwars_data[starwars_data$height &gt; 170, ]$mass ~ starwars_data[starwars_data$height &gt; 170, ]$height, xlab = &quot;height&quot;, ylab = &quot;mass&quot;) The Base R code is longer, more nested, and not as readable as the code written in dplyr. And the more selection criteria and functions you need to implement, the worse it gets. For example, imagine you would also want to exclude Star Wars characters with a mass bigger than 1200kg. Piece of cake with dplyr: starwars_data %&gt;% select(height, mass) %&gt;% filter(height &gt; 170) %&gt;% filter(mass &lt; 1200) %&gt;% plot() 5.5 Data transformation with dplyr dplyrcomes with five main functions: select(): select variables column by column, i.e. pick columns / variables by their names filter(): filter observations row by row, i.e. pick observations by their values arrange(): sort / reorder data in ascending or descending order mutate(): calculate new variables or transform existing ones summarize(): summarize variables (e.g. mean, standard deviation, etc.), best combined with group_by() 5.5.1 select() You will frequently encounter large data sets including hundreds of variables. The first problem in this scenario is narrowing down the variables you are truly interested in. select() helps you to easily choose a suitable subset of variables. In this selection process, the name of the data frame is the source object, followed by the pipe %&gt;% operator. The expression that selects the columns that you are interested in comes after that. Take the Star Wars data, for example. The original data set has 87 observations (Star Wars characters) and 14 columns / variables (traits of these characters, e.g., birth_year, gender, and species). Yes, 14 columns is not a lot and you could get an overview of this data without subsetting columns. Let’s take a look at the original data frame: library(dplyr) # load dplyr starwars_data &lt;- starwars # assign the pre-installed starwars data from dplyr to a source object / variable starwars_data # print the content of the data frame to the console ## # A tibble: 87 × 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Sk… 172 77 blond fair blue 19 male mascu… ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 none mascu… ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 none mascu… ## 4 Darth V… 202 136 none white yellow 41.9 male mascu… ## 5 Leia Or… 150 49 brown light brown 19 fema… femin… ## 6 Owen La… 178 120 brown, gr… light blue 52 male mascu… ## 7 Beru Wh… 165 75 brown light blue 47 fema… femin… ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA none mascu… ## 9 Biggs D… 183 84 black light brown 24 male mascu… ## 10 Obi-Wan… 182 77 auburn, w… fair blue-gray 57 male mascu… ## # ℹ 77 more rows ## # ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; For the sake of practice, let’s say we only want to analyze the species, birth_year, mass, and height of these characters. To simplify data handling, we want to keep only the respective columns. starwars_data %&gt;% # define the source object select(name, species, birth_year, mass, height) # keep only the name, species, birth_year, mass and height column ## # A tibble: 87 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Luke Skywalker Human 19 77 172 ## 2 C-3PO Droid 112 75 167 ## 3 R2-D2 Droid 33 32 96 ## 4 Darth Vader Human 41.9 136 202 ## 5 Leia Organa Human 19 49 150 ## 6 Owen Lars Human 52 120 178 ## 7 Beru Whitesun lars Human 47 75 165 ## 8 R5-D4 Droid NA 32 97 ## 9 Biggs Darklighter Human 24 84 183 ## 10 Obi-Wan Kenobi Human 57 77 182 ## # ℹ 77 more rows At the moment you have only printed the transformed data to the console. However, most of the time we want to keep the transformed data ready for further calculations. In this case we should assign the transformed data into a new source object, which we can access later. starwars_short &lt;- starwars_data %&gt;% # assign a new source object and define the old source object select(name, species, birth_year, mass, height) # keep only the name, species, birth_year, mass and height column Let’s print the new source object, starwars_short, to the console. starwars_short ## # A tibble: 87 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Luke Skywalker Human 19 77 172 ## 2 C-3PO Droid 112 75 167 ## 3 R2-D2 Droid 33 32 96 ## 4 Darth Vader Human 41.9 136 202 ## 5 Leia Organa Human 19 49 150 ## 6 Owen Lars Human 52 120 178 ## 7 Beru Whitesun lars Human 47 75 165 ## 8 R5-D4 Droid NA 32 97 ## 9 Biggs Darklighter Human 24 84 183 ## 10 Obi-Wan Kenobi Human 57 77 182 ## # ℹ 77 more rows You can also delete columns by making a reverse selection with the - symbol. This means that you select all columns except the one whose name you specify. starwars_short %&gt;% select(-name) # keep all columns except the name column (i.e. delete name column) ## # A tibble: 87 × 4 ## species birth_year mass height ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Human 19 77 172 ## 2 Droid 112 75 167 ## 3 Droid 33 32 96 ## 4 Human 41.9 136 202 ## 5 Human 19 49 150 ## 6 Human 52 120 178 ## 7 Human 47 75 165 ## 8 Droid NA 32 97 ## 9 Human 24 84 183 ## 10 Human 57 77 182 ## # ℹ 77 more rows You can delete more than one column in one go: starwars_short %&gt;% select(-c(name, species)) # keep all columns except the name &amp; species column (i.e. delete these columns) ## # A tibble: 87 × 3 ## birth_year mass height ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 19 77 172 ## 2 112 75 167 ## 3 33 32 96 ## 4 41.9 136 202 ## 5 19 49 150 ## 6 52 120 178 ## 7 47 75 165 ## 8 NA 32 97 ## 9 24 84 183 ## 10 57 77 182 ## # ℹ 77 more rows Tip for advanced users: You can select columns and rename them at the same time. starwars_short %&gt;% select(&quot;character&quot; = name, &quot;age&quot; = birth_year) # select columns that you want to keep &amp; rename them ## # A tibble: 87 × 2 ## character age ## &lt;chr&gt; &lt;dbl&gt; ## 1 Luke Skywalker 19 ## 2 C-3PO 112 ## 3 R2-D2 33 ## 4 Darth Vader 41.9 ## 5 Leia Organa 19 ## 6 Owen Lars 52 ## 7 Beru Whitesun lars 47 ## 8 R5-D4 NA ## 9 Biggs Darklighter 24 ## 10 Obi-Wan Kenobi 57 ## # ℹ 77 more rows 5.5.2 filter() filter() divides observations into groups depending on their values. The name of the data frame is the source object, followed by the pipe %&gt;% operator. Then follow the expressions that filter the data. Let’s only select human Star Wars characters in our transformed data set starwars_short: starwars_short %&gt;% filter(species == &quot;Human&quot;) ## # A tibble: 35 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Luke Skywalker Human 19 77 172 ## 2 Darth Vader Human 41.9 136 202 ## 3 Leia Organa Human 19 49 150 ## 4 Owen Lars Human 52 120 178 ## 5 Beru Whitesun lars Human 47 75 165 ## 6 Biggs Darklighter Human 24 84 183 ## 7 Obi-Wan Kenobi Human 57 77 182 ## 8 Anakin Skywalker Human 41.9 84 188 ## 9 Wilhuff Tarkin Human 64 NA 180 ## 10 Han Solo Human 29 80 180 ## # ℹ 25 more rows And now let’s only select Star Wars characters who are younger than 24 or exactly 24 years old. starwars_short %&gt;% filter(birth_year &lt;= 24) ## # A tibble: 7 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Luke Skywalker Human 19 77 172 ## 2 Leia Organa Human 19 49 150 ## 3 Biggs Darklighter Human 24 84 183 ## 4 Wedge Antilles Human 21 77 170 ## 5 IG-88 Droid 15 140 200 ## 6 Wicket Systri Warrick Ewok 8 20 88 ## 7 Plo Koon Kel Dor 22 80 188 Chaining some functions, let’s look at Star Wars character who are a Droid and older than 24. starwars_short %&gt;% filter(species == &quot;Droid&quot; &amp; birth_year &gt; 24) # &amp; --&gt; filter all observations to which both logical statements apply ## # A tibble: 2 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 C-3PO Droid 112 75 167 ## 2 R2-D2 Droid 33 32 96 Alternatively, you can also write these filters like this: starwars_short %&gt;% filter(species == &quot;Droid&quot;) %&gt;% filter(birth_year &gt; 24) ## # A tibble: 2 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 C-3PO Droid 112 75 167 ## 2 R2-D2 Droid 33 32 96 Besides the &amp; operator, there are many more logical operators that you can choose from to optimize your filter choices. Here is an overview: Image: Logical, i.e. boolean, operators (Source: R for Data Science) Tip for advanced users 1: You can negate filters. This means that you keep all observations except the one that you have specified with the != operator (read != as: is not or is unequal to). For example, you can choose to include only non-human Star Wars characters. starwars_short %&gt;% filter(species != &quot;Human&quot;) ## # A tibble: 48 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 C-3PO Droid 112 75 167 ## 2 R2-D2 Droid 33 32 96 ## 3 R5-D4 Droid NA 32 97 ## 4 Chewbacca Wookiee 200 112 228 ## 5 Greedo Rodian 44 74 173 ## 6 Jabba Desilijic Tiure Hutt 600 1358 175 ## 7 Yoda Yoda&#39;s species 896 17 66 ## 8 IG-88 Droid 15 140 200 ## 9 Bossk Trandoshan 53 113 190 ## 10 Ackbar Mon Calamari 41 83 180 ## # ℹ 38 more rows Alternatively, you achieve the same goal by negating the entire function call. Negating the entire function call can be handy at times. starwars_short %&gt;% filter(!(species == &quot;Human&quot;)) ## # A tibble: 48 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 C-3PO Droid 112 75 167 ## 2 R2-D2 Droid 33 32 96 ## 3 R5-D4 Droid NA 32 97 ## 4 Chewbacca Wookiee 200 112 228 ## 5 Greedo Rodian 44 74 173 ## 6 Jabba Desilijic Tiure Hutt 600 1358 175 ## 7 Yoda Yoda&#39;s species 896 17 66 ## 8 IG-88 Droid 15 140 200 ## 9 Bossk Trandoshan 53 113 190 ## 10 Ackbar Mon Calamari 41 83 180 ## # ℹ 38 more rows Tip for advanced users 2: You can filter for missing values (NAs) with the is.na() function. starwars_short %&gt;% filter(is.na(birth_year)) ## # A tibble: 44 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 R5-D4 Droid NA 32 97 ## 2 Jek Tono Porkins Human NA 110 180 ## 3 Arvel Crynyd Human NA NA NA ## 4 Nien Nunb Sullustan NA 68 160 ## 5 Nute Gunray Neimodian NA 90 191 ## 6 Roos Tarpals Gungan NA 82 224 ## 7 Rugor Nass Gungan NA NA 206 ## 8 Ric Olié &lt;NA&gt; NA NA 183 ## 9 Watto Toydarian NA NA 137 ## 10 Sebulba Dug NA 40 112 ## # ℹ 34 more rows And you can negate that filter to get rid of all observation that have missing values (NAs). starwars_short %&gt;% filter(!is.na(birth_year)) ## # A tibble: 43 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Luke Skywalker Human 19 77 172 ## 2 C-3PO Droid 112 75 167 ## 3 R2-D2 Droid 33 32 96 ## 4 Darth Vader Human 41.9 136 202 ## 5 Leia Organa Human 19 49 150 ## 6 Owen Lars Human 52 120 178 ## 7 Beru Whitesun lars Human 47 75 165 ## 8 Biggs Darklighter Human 24 84 183 ## 9 Obi-Wan Kenobi Human 57 77 182 ## 10 Anakin Skywalker Human 41.9 84 188 ## # ℹ 33 more rows Tip for advanced users 3: Watch out for the | operator (read: or). This one can be tricky to negate! For example, with this code you get all characters that are NEITHER human NOR older than 33 years. I.e. you get all non-human characters who are younger than 33 or exactly 33 years old. starwars_short %&gt;% filter(!((species == &quot;Human&quot;) | (birth_year &gt; 33))) ## # A tibble: 4 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 R2-D2 Droid 33 32 96 ## 2 IG-88 Droid 15 140 200 ## 3 Wicket Systri Warrick Ewok 8 20 88 ## 4 Plo Koon Kel Dor 22 80 188 But with this code, you’ll get all observations that are either non-human (regardless of their age) OR humans who are older than 33 years old. starwars_short %&gt;% filter((species != &quot;Human&quot;) | (birth_year &gt; 33)) ## # A tibble: 67 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 C-3PO Droid 112 75 167 ## 2 R2-D2 Droid 33 32 96 ## 3 Darth Vader Human 41.9 136 202 ## 4 Owen Lars Human 52 120 178 ## 5 Beru Whitesun lars Human 47 75 165 ## 6 R5-D4 Droid NA 32 97 ## 7 Obi-Wan Kenobi Human 57 77 182 ## 8 Anakin Skywalker Human 41.9 84 188 ## 9 Wilhuff Tarkin Human 64 NA 180 ## 10 Chewbacca Wookiee 200 112 228 ## # ℹ 57 more rows 5.5.3 arrange() arrange() and filter() are like two brothers: both look similar, but they also differ in at least one essential aspect. Both functions change the rows of the data frame, but unlike filter(), arrange() does not select or delete rows, it only changes their order (either ascending or descending). By default, arrange() will sort in ascending order, i.e. from 1:100 (numeric vector) and from A:Z (character vector). arrange() must always be applied to at least one column that is to be sorted. starwars_short %&gt;% arrange(birth_year) ## # A tibble: 87 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Wicket Systri Warrick Ewok 8 20 88 ## 2 IG-88 Droid 15 140 200 ## 3 Luke Skywalker Human 19 77 172 ## 4 Leia Organa Human 19 49 150 ## 5 Wedge Antilles Human 21 77 170 ## 6 Plo Koon Kel Dor 22 80 188 ## 7 Biggs Darklighter Human 24 84 183 ## 8 Han Solo Human 29 80 180 ## 9 Lando Calrissian Human 31 79 177 ## 10 Boba Fett Human 31.5 78.2 183 ## # ℹ 77 more rows To get a descending order: starwars_short %&gt;% arrange(desc(birth_year)) ## # A tibble: 87 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Yoda Yoda&#39;s species 896 17 66 ## 2 Jabba Desilijic Tiure Hutt 600 1358 175 ## 3 Chewbacca Wookiee 200 112 228 ## 4 C-3PO Droid 112 75 167 ## 5 Dooku Human 102 80 193 ## 6 Qui-Gon Jinn Human 92 89 193 ## 7 Ki-Adi-Mundi Cerean 92 82 198 ## 8 Finis Valorum Human 91 NA 170 ## 9 Palpatine Human 82 75 170 ## 10 Cliegg Lars Human 82 NA 183 ## # ℹ 77 more rows If you specify more than one column, then subsequent columns are used to break ties. Also note that missing values are always displayed last: starwars_short %&gt;% arrange(species, birth_year) ## # A tibble: 87 × 5 ## name species birth_year mass height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Ratts Tyerell Aleena NA 15 79 ## 2 Dexter Jettster Besalisk NA 102 198 ## 3 Ki-Adi-Mundi Cerean 92 82 198 ## 4 Mas Amedda Chagrian NA NA 196 ## 5 Zam Wesell Clawdite NA 55 168 ## 6 IG-88 Droid 15 140 200 ## 7 R2-D2 Droid 33 32 96 ## 8 C-3PO Droid 112 75 167 ## 9 R5-D4 Droid NA 32 97 ## 10 R4-P17 Droid NA NA 96 ## # ℹ 77 more rows 5.5.4 mutate() Often you want to add new columns to a data set, e.g. when you calculate new variables or when you want to store re-coded values of other variables. With mutate(), new columns will be added to the end of you data frame. For example, we can resize the height column to provide the body height in m instead of cm. Let’s call that variable m_height. We’ll assign our transformed data (with the newly created m_height column) back into our source object (starwars_short) to keep the changes for the future (and not just print it to the console). starwars_short &lt;- starwars_short %&gt;% # assigns your source object, i.e. data, back to itself to save changes mutate(m_height = height / 100) # creates the new variable &quot;m_height&quot; and adds it to the end of the data frame starwars_short # print the data to your console to inspect the new column ## # A tibble: 87 × 6 ## name species birth_year mass height m_height ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Luke Skywalker Human 19 77 172 1.72 ## 2 C-3PO Droid 112 75 167 1.67 ## 3 R2-D2 Droid 33 32 96 0.96 ## 4 Darth Vader Human 41.9 136 202 2.02 ## 5 Leia Organa Human 19 49 150 1.5 ## 6 Owen Lars Human 52 120 178 1.78 ## 7 Beru Whitesun lars Human 47 75 165 1.65 ## 8 R5-D4 Droid NA 32 97 0.97 ## 9 Biggs Darklighter Human 24 84 183 1.83 ## 10 Obi-Wan Kenobi Human 57 77 182 1.82 ## # ℹ 77 more rows Let’s calculate the BMI of the Star Wars characters with the BMI formula and the newly created m_height variable. Save the changes to your data frame by assigning the source object back to itself. starwars_short &lt;- starwars_short %&gt;% # assigns your source object, i.e. data, back to itself to save changes mutate(BMI = mass / m_height^2) # creates the new variable &quot;BMI&quot; and adds it to the end of the data frame starwars_short # print the data to your console to inspect the new column ## # A tibble: 87 × 7 ## name species birth_year mass height m_height BMI ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Luke Skywalker Human 19 77 172 1.72 26.0 ## 2 C-3PO Droid 112 75 167 1.67 26.9 ## 3 R2-D2 Droid 33 32 96 0.96 34.7 ## 4 Darth Vader Human 41.9 136 202 2.02 33.3 ## 5 Leia Organa Human 19 49 150 1.5 21.8 ## 6 Owen Lars Human 52 120 178 1.78 37.9 ## 7 Beru Whitesun lars Human 47 75 165 1.65 27.5 ## 8 R5-D4 Droid NA 32 97 0.97 34.0 ## 9 Biggs Darklighter Human 24 84 183 1.83 25.1 ## 10 Obi-Wan Kenobi Human 57 77 182 1.82 23.2 ## # ℹ 77 more rows mutate() does not merely work with mathematical operators. You can also categorize numeric variables with the case_when function, which is part of the mutate() function. starwars_short &lt;- starwars_short %&gt;% mutate(age_cat = case_when( # &quot;cat&quot; is short for &quot;categorized&quot; birth_year &lt; 20 ~ &quot;very young&quot;, birth_year &lt; 40 ~ &quot;young&quot;, birth_year &lt; 70 ~ &quot;mid-aged&quot;, birth_year &lt;= 100 ~ &quot;old&quot;, birth_year &gt; 100 ~ &quot;very old&quot; )) starwars_short ## # A tibble: 87 × 8 ## name species birth_year mass height m_height BMI age_cat ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Luke Skywalker Human 19 77 172 1.72 26.0 very young ## 2 C-3PO Droid 112 75 167 1.67 26.9 very old ## 3 R2-D2 Droid 33 32 96 0.96 34.7 young ## 4 Darth Vader Human 41.9 136 202 2.02 33.3 mid-aged ## 5 Leia Organa Human 19 49 150 1.5 21.8 very young ## 6 Owen Lars Human 52 120 178 1.78 37.9 mid-aged ## 7 Beru Whitesun lars Human 47 75 165 1.65 27.5 mid-aged ## 8 R5-D4 Droid NA 32 97 0.97 34.0 &lt;NA&gt; ## 9 Biggs Darklighter Human 24 84 183 1.83 25.1 young ## 10 Obi-Wan Kenobi Human 57 77 182 1.82 23.2 mid-aged ## # ℹ 77 more rows Finally, you can recode variables by using the recode() function, which is part of the mutate() function. Let’s be crazy and recode all droids as robots3 and save the result in a new variable called crazy_species! Please note that recode() has an unusual syntax because it follows the order of old_var = new_var instead of the usual order: new_var = old_var. Therefore, recode() is likely to be retired in the future (use case_when instead). starwars_short &lt;- starwars_short %&gt;% mutate(crazy_species = recode( # alternatively, you could also recode directly back into the species variable species, &quot;Droid&quot; = &quot;Robot&quot; )) starwars_short ## # A tibble: 87 × 9 ## name species birth_year mass height m_height BMI age_cat crazy_species ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Sk… Human 19 77 172 1.72 26.0 very y… Human ## 2 C-3PO Droid 112 75 167 1.67 26.9 very o… Robot ## 3 R2-D2 Droid 33 32 96 0.96 34.7 young Robot ## 4 Darth V… Human 41.9 136 202 2.02 33.3 mid-ag… Human ## 5 Leia Or… Human 19 49 150 1.5 21.8 very y… Human ## 6 Owen La… Human 52 120 178 1.78 37.9 mid-ag… Human ## 7 Beru Wh… Human 47 75 165 1.65 27.5 mid-ag… Human ## 8 R5-D4 Droid NA 32 97 0.97 34.0 &lt;NA&gt; Robot ## 9 Biggs D… Human 24 84 183 1.83 25.1 young Human ## 10 Obi-Wan… Human 57 77 182 1.82 23.2 mid-ag… Human ## # ℹ 77 more rows Tip for advanced users 1: There is a special case of recoding: Sometimes you will receive data (e.g. through an import from SPSS) in which missings are not marked as NA, but with -9 (or any other number). Unfortunately, you will have to tell R that these are missing values and should be set to NA. In this case, use the na_if() function, which is also part of the mutate() function. Luke Skywalker, the first observation in our data frame, is 172cm tall. For the sake of practice, let’s set all heights that are equal to 172cm to NA. This time, we won’t save this transformation for later use (by reassigning the source object back to itself) since this transformation does not make a lot of sense. starwars_short %&gt;% mutate(height = na_if(height, 172)) ## # A tibble: 87 × 9 ## name species birth_year mass height m_height BMI age_cat crazy_species ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Sk… Human 19 77 NA 1.72 26.0 very y… Human ## 2 C-3PO Droid 112 75 167 1.67 26.9 very o… Robot ## 3 R2-D2 Droid 33 32 96 0.96 34.7 young Robot ## 4 Darth V… Human 41.9 136 202 2.02 33.3 mid-ag… Human ## 5 Leia Or… Human 19 49 150 1.5 21.8 very y… Human ## 6 Owen La… Human 52 120 178 1.78 37.9 mid-ag… Human ## 7 Beru Wh… Human 47 75 165 1.65 27.5 mid-ag… Human ## 8 R5-D4 Droid NA 32 97 0.97 34.0 &lt;NA&gt; Robot ## 9 Biggs D… Human 24 84 183 1.83 25.1 young Human ## 10 Obi-Wan… Human 57 77 182 1.82 23.2 mid-ag… Human ## # ℹ 77 more rows 5.5.5 summarize() [+ group_by()] Instead of using summarize(), you could omit the American English and write summarise(). This function collapses a data frame into a single row that shows you summary statistics about your variables. Be careful not to overwrite your source object with the collapsed data frame, i.e. do not reassign the source object to itself when you use summarize() (unless you have a really good reason to do so). starwars_short %&gt;% summarize(mean_height = mean(height, na.rm = TRUE)) # collapses the data frame into one variable called &quot;mean_height&quot; ## # A tibble: 1 × 1 ## mean_height ## &lt;dbl&gt; ## 1 174. # na.rm = TRUE -&gt; removes the missing values prior to the computation of the summary We now know that the average Star Wars character is 174cm tall. But the summarize()function grows especially powerful when it is combined with `group_by to display summary statistics for groups. starwars_short %&gt;% group_by(species) %&gt;% # every unique species becomes its own group summarize( mean_height = mean(height, na.rm = TRUE), # collapses the data frame into one row with one variable called &quot;mean_height&quot;... count = n() # and a second variable that shows the group size (i.e. count) ) ## # A tibble: 38 × 3 ## species mean_height count ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Aleena 79 1 ## 2 Besalisk 198 1 ## 3 Cerean 198 1 ## 4 Chagrian 196 1 ## 5 Clawdite 168 1 ## 6 Droid 131. 6 ## 7 Dug 112 1 ## 8 Ewok 88 1 ## 9 Geonosian 183 1 ## 10 Gungan 209. 3 ## # ℹ 28 more rows We learn from the 6 droids in our data set that droids are small, 131cm on average. But Ewoks are even smaller (88cm on average). Pro tip: you can even group by two groups at the same time with the method group_by(x1, x2, .add=TRUE) or group_by(x1, x2). Finally, we can also retrieve all relevant summary statistics of a classic box plot: starwars_short %&gt;% group_by(species) %&gt;% # every unique species becomes its own group summarize( MAX = max(height, na.rm = TRUE), UQ = quantile(height, 0.75, na.rm = TRUE), Med = median(height, na.rm = TRUE), M = mean(height, na.rm = TRUE), # SD = sd(height, na.rm = TRUE), # calculating the standard deviation is useless here because we often have only 1 observation per species LQ = quantile(height, 0.25, na.rm = TRUE), MIN = min(height, na.rm = TRUE), count = n() # shows the group_size (i.e. count) ) ## # A tibble: 38 × 8 ## species MAX UQ Med M LQ MIN count ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Aleena 79 79 79 79 79 79 1 ## 2 Besalisk 198 198 198 198 198 198 1 ## 3 Cerean 198 198 198 198 198 198 1 ## 4 Chagrian 196 196 196 196 196 196 1 ## 5 Clawdite 168 168 168 168 168 168 1 ## 6 Droid 200 167 97 131. 96 96 6 ## 7 Dug 112 112 112 112 112 112 1 ## 8 Ewok 88 88 88 88 88 88 1 ## 9 Geonosian 183 183 183 183 183 183 1 ## 10 Gungan 224 215 206 209. 201 196 3 ## # ℹ 28 more rows Tip for advances users 2: If you want to count the unique values of variables, then data %&gt;% group_by(a, b) %&gt;% summarize(n = n()) might not be the best solution (it’s a lot of code, isn’t it?). starwars_short %&gt;% group_by(species, age_cat) %&gt;% summarize(count = n()) ## # A tibble: 51 × 3 ## # Groups: species [38] ## species age_cat count ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Aleena &lt;NA&gt; 1 ## 2 Besalisk &lt;NA&gt; 1 ## 3 Cerean old 1 ## 4 Chagrian &lt;NA&gt; 1 ## 5 Clawdite &lt;NA&gt; 1 ## 6 Droid very old 1 ## 7 Droid very young 1 ## 8 Droid young 1 ## 9 Droid &lt;NA&gt; 3 ## 10 Dug &lt;NA&gt; 1 ## # ℹ 41 more rows For more efficient code, you can use the count() function instead: data %&gt;% count(a, b). starwars_short %&gt;% count(species, age_cat) ## # A tibble: 51 × 3 ## species age_cat n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Aleena &lt;NA&gt; 1 ## 2 Besalisk &lt;NA&gt; 1 ## 3 Cerean old 1 ## 4 Chagrian &lt;NA&gt; 1 ## 5 Clawdite &lt;NA&gt; 1 ## 6 Droid very old 1 ## 7 Droid very young 1 ## 8 Droid young 1 ## 9 Droid &lt;NA&gt; 3 ## 10 Dug &lt;NA&gt; 1 ## # ℹ 41 more rows 5.5.6 Chaining functions in a pipe All of the dplyr functions can be chained in one single pipe. Using the original starwars_data, we’ll only analyze Star Wars characters who are older than 25 years (filter()), calculate the BMI (mutate()), group them by their species (group_by()) and summarize the average BMI (summarize()). We’ll display the final result in an ascending order (arrange()). starwars_data %&gt;% mutate(BMI = mass / (height / 100)^2) %&gt;% filter(birth_year &gt; 25) %&gt;% group_by(species) %&gt;% summarize(mean_BMI = mean(BMI, na.rm = TRUE)) %&gt;% arrange(mean_BMI) ## # A tibble: 14 × 2 ## species mean_BMI ## &lt;chr&gt; &lt;dbl&gt; ## 1 Gungan 17.2 ## 2 Twi&#39;lek 17.4 ## 3 Mirialan 18.8 ## 4 Cerean 20.9 ## 5 Wookiee 21.5 ## 6 Rodian 24.7 ## 7 Human 25.3 ## 8 Mon Calamari 25.6 ## 9 Zabrak 26.1 ## 10 Droid 30.8 ## 11 Trandoshan 31.3 ## 12 Yoda&#39;s species 39.0 ## 13 Hutt 443. ## 14 &lt;NA&gt; NaN 5.6 Take-Aways Tidy data: is a tabular in which each column represents one single variable, each row represents a single observation and each cell contains only one single value Pipe operator: %&gt;% is used to chain functions and apply them to a source object. We call these chains of functions pipes dplyr functions: there are five main dplyr functions that you should know of: select, filter, arrange, mutate, and summarize [+ group_by]. 5.7 Additional tutorials You still have questions? The following tutorials &amp; papers can help you with that: Computational Methods in der politischen Kommunikationsforschung by J. Unkel, Tutorial 7, 9 &amp; 10 R for Data Science, Chapter 12 R for Data Science, Chapter 5.1.3 and the following YaRrr! The Pirate’s Guide to R by N.D.Phillips, Tutorial 10.4 The tidyverse style guide Data wrangling with dplyr &amp; tidyr Cheat Sheet Now let’s see what you’ve learned so far: Exercise 3: dplyr. To be precise, the pipe operator was introduced to R with the package magrittr, not with dplyr. Nowadays, the %&gt;% operator can be used outside the tidyverse package if magrittr is installed and loaded: library(magrittr).↩︎ Please, don’t hate me for this.↩︎ "],["exercise-3-dplyr.html", "Exercise 3: dplyr Task 1 Task 2 Task 3 Task 4 Task 5 Task 6 Task 7", " Exercise 3: dplyr After working through Exercise 3, you’ll… have assessed how well you know dplyr know what dplyr functions and concepts you might want to repeat again have managed to apply the dplyr concepts to data Task 1 Below you will see multiple choice questions. Please try to identify the correct answers. 1, 2, 3 and 4 correct answers are possible for each question. 1. What are the main characteristics of tidy data? Every cell contains values. Every cell contains a variable. Every observation is a column. Every observation is a row. 2. What are dplyr functions? summary() describe() mutate() manage() 3. How can you sort the eye_color of Star Wars characters from Z to A? starwars_data %&gt;% arrange(desc(eye_color)) starwars_data %&gt;% arrange(eye_color) starwars_data %&gt;% select(arrange(eye_color)) starwars_data %&gt;% select(eye_color) %&gt;% arrange(desc(eye_color)) 4. Imagine you want to recode the height of these characters. You want to have three categories from small and medium to tall. What is a valid approach? starwars_data %&gt;% mutate(height = case_when(height&lt;=150~\"small\",height&lt;=190~\"medium\",height&gt;190~\"tall\")) starwars_data %&gt;% mutate(height = case_when(height&lt;=150~small,height&lt;=190~medium,height&gt;190~tall)) starwars_data %&gt;% recode(height = case_when(height&lt;=150~\"small\",height&lt;=190~\"medium\",height&gt;190~\"tall\")) starwars_data %&gt;% recode(height = case_when(height&lt;=150~small,height&lt;=190~medium,height&gt;190~tall)) 5. Imagine you want to provide a systematic overview over all hair colors and what species wear these hair colors frequently (not accounting for the skewed sampling of species)? What is a valid approach? starwars_data %&gt;% group_by(hair_color) %&gt;% group_by(species) %&gt;% summarize(count = n()) %&gt;% arrange(hair_color) starwars_data %&gt;% group_by(hair_color, species) %&gt;% summarize(count = n()) %&gt;% arrange(hair_color) starwars_data %&gt;% group_by(hair_color &amp; species) %&gt;% summarize(count = n()) %&gt;% arrange(hair_color) starwars_data %&gt;% group_by(hair_color + species) %&gt;% summarize(count = n()) %&gt;% arrange(hair_color) Task 2 It’s you turn now. Load the starwars data like this: library(dplyr) # to activate the dplyr package starwars_data &lt;- starwars # to assign the pre-installed starwars data set (dplyr) into a source object in our environment How many humans are contained in the starwars data overall? (Hint: use summarize(count = n()) or count()) Task 3 How many humans are contained in starwars by gender? Task 4 What is the most common eye_color among Star Wars characters? (Hint: use arrange()) Task 5 What is the average mass of Star Wars characters that are not human and have yellow eyes? (Hint: remove all NAs) Task 6 Compare the mean, median, and standard deviation of mass for all humans and droids. (Hint: remove all NAs) Task 7 Create a new variable in which you store the mass in gram (gr_mass). Add it to the data frame. Test whether your solution works by printing your data to the console, but only show the name, species, mass, and your new variable gr_mass. When you’re ready to look at the solutions, you can find them here: Solutions for Exercise 3. "],["tutorial-advanced-data-management.html", " 6 5 Tutorial: Advanced data management 6.1 Stop hard-coding your working directory! 6.2 Start navigating your working directory like a pro! 6.3 Reading multiple files into R 6.4 Joining two datasets 6.5 Reformatting datasets 6.6 Advanced column selectors 6.7 Advanced selection of rows 6.8 Take-Aways", " 6 5 Tutorial: Advanced data management After working through Tutorial 5, you’ll… have learned some neat tricks that took me several years to figure out… :) … for example, soft-coding your working directory … using relative paths to navigate your folders … using advanced column selectors Some parts of this tutorial are heavily inspired by Christian Burkhart’s book Going from Beginner to Advanced in the Tidyverse. This book is the next step in your journey to tidyverse mastery! 6.1 Stop hard-coding your working directory! Hard-coding your working directory with setwd(\"C:/Users/LaraK/Documents/IPR/\") comes with a significant drawback: it is not reproducible on your colleagues’ machines! Your colleagues may have different user names, run the script from different source file paths, or have different folder structures. To avoid these problems, you can use the rstudioapi package. It provides a set of functions that allow you to interact with RStudio’s IDE (Integrated Development Environment) programmatically. First, install and load the package: # install.packages(&quot;rstudioapi&quot;) # run only the first time library(rstudioapi) Now you should open or create an R script file in RStudio that is located in the desired folder that you want to become your working directory. I will create a script in a folder called IPR that rests under the folder path: \"C:/Users/LaraK/Documents/IPR/\". Save that script in your folder! Now copy the following line of code in your R script and execute it: setwd(dirname(rstudioapi::getSourceEditorContext()$path)) By using the dirname() function on rstudioapi::getSourceEditorContext()$path, we extract the directory path of the currently active R script and pass it to setwd() to set it as the working directory. This approach also ensures that the working directory is set to the correct folder, even if you rename or move the R script within RStudio. Note : Remember to save the R script in the desired folder before executing the setwd() function to ensure that it sets the correct working directory. That’s really handy, isn’t it? 6.2 Start navigating your working directory like a pro! 6.2.1 The concept of relative paths If you have subfolders in your working directory or when your working directory itself is a subfolder of a more high-level folder, you can start navigating in it by using relative paths. A relative path is like giving directions from your current location (e.g.: “When you leave the IfKW, you turn right on the Oettingenstraße. Walk down the road until you see a crossroad. Turn left and then you can see the Bayrische Eismanufaktur!”). It’s the contrary of providing an absolute path, which means providing the full address of a place (e.g.: “You can find the Bayrische Eismanufaktur at Oettingenstr. 42a – 80538 München, longitude: 48.14646612168593, latitude: 11.593379619133687”). In R, a relative path specifies the path to a folder or file relative to your current working directory in RStudio. It doesn’t include the complete path from the root of your file system. Instead, it describes how to navigate through the folders and subfolders starting from your current location. Relative paths are flexible and can adapt to different working directories. For example, if your current working directory is \"C:/Users/LaraK/Documents/IPR/\", a relative path to a file named WoJ_names_1.csv in a subfolder named mutiple_files would be mutiple_files/WoJ_names_1.csv. 6.2.2 Moving up and down folders by using relative paths Please download the .csv files that are contained in the folder multiple_files on LRZ Sync &amp; Share and store them in a subfolder called mutiple_files in your working directory. To move down a folder, you can use the ./ notation. The ./ represents the child directory of the current working directory that you want to navigate to. For example, if you’re in the folder \"C:/Users/LaraK/Documents/IPR/\" and you want to move your working directory down to the \"mutiple_files\" subfolder, you can use the following code: setwd(&quot;./mutiple_files&quot;) To move up one level in the folder hierarchy again, you can use the ../ notation. The ../ represents the parent directory of the current working directory. You can use this notation with the setwd() function to navigate up the folder again: setwd(&quot;../&quot;) 6.3 Reading multiple files into R There are several common challenges when reading multiple files into R, such as inconsistent column names and file paths, as well as selecting only the necessary files. In this tutorial, I’ll teach you a convenient solution by creating a character vector of file paths and reading them into R using the read_* functions. First, you will need to set the folder \"multiple_files\" as your working directory. setwd(&quot;./mutiple_files&quot;) Now you need to save the folder path of your working directory as a character string. You can use getwd() and save the result in an R object called path: path &lt;- getwd() path Next, create a character vector that contains the file names of all files contained in your subfolder \"multiple_files\". You can look at the file names of a folder by using the function list.files(): file_names &lt;- list.files(path) file_names Now turn these names into a proper character vector of all the file paths by adding additional arguments to the function list.files(): file_paths &lt;- list.files( path = path, # takes the path to the working directory / folder pattern = &quot;csv&quot;, # file should contain the string &#39;csv&#39;, but you could also opt for &quot;WoJ_names&quot; full.names = TRUE ) # store the full file paths, not just the file names file_paths Finally, read the files using map(): Use map() from the purrr package (part of the tidyverse metapackage) to iterate over the file paths and read each file using a function like read.csv() (or read_excel(), etc.). The result will be a list of data frames. data_list &lt;- file_paths %&gt;% map(~ read.csv2(file = .x)) # use map to apply read.csv2 (semicolon-separated) to each individual file path, .x stands for each individual file path data_list However, we don’t want our data to be read in as separate files. We want to combine them in one single file. We can use bind_rows() from the dpylr package for that: combined_data &lt;- data_list %&gt;% bind_rows() # bind all of your rows in your data list into one dataframe That involved a great number of individual steps. Let’s now consolidate everything into a simpler pipeline and execute it: path &lt;- getwd() file_paths &lt;- list.files( path = path, pattern = &quot;csv&quot;, full.names = TRUE ) combined_data &lt;- file_paths %&gt;% map(~ read.csv2(file = .x)) %&gt;% bind_rows() Note: If the files have different column names or structures, you may encounter issues when binding them together with this approach. Make sure the files have compatible structures or consider preprocessing the data, as shown in the next chapter. 6.3.1 Reading multiple files into R with different column names Things can sometimes get messy. Please download the .csv files that are contained in the folder multiple_files_messy on LRZ Sync &amp; Share and store them in a folder called mutiple_files_messyin your working directory. In this messy folder, the WoJ_names_1.csv file has been altered. The column name country has been capitalized (i.e., changed to COUNTRY) , and the column containing names has been accidentally deleted. Let’s attempt to reload the .csv files once more and set the column names to lowercase dynamically. To handle the missing column, we will use bind_rows function: setwd(&quot;./mutiple_files_messy&quot;) path &lt;- getwd() file_paths &lt;- list.files( path = path, pattern = &quot;csv&quot;, full.names = TRUE ) combined_data &lt;- file_paths %&gt;% map(~ read.csv2(file = .x) %&gt;% setNames(tolower(names(.)))) %&gt;% bind_rows() Neat! Note that you can always exchange the string in the pattern argument of list.files include a regular expression. I can’t cover regular expressions and the stringr package in this tutorial, but if you are interested in mastering regular expressions, you can have look at my tutorial for our MA journalism students 6.4 Joining two datasets We’ve already covered how to join multiple datasets while loading the data into R. This next approach joins datasets after they’ve been loaded into R. It’s the more common approach. First things first, let’s load the libraries and data we’ll need: library(tidycomm) library(tidyverse) WoJ &lt;- tidycomm::WoJ %&gt;% mutate(case_id = row_number()) Next, we’ll split the WoJ dataset into two groups based on work experience: rookies and veterans. We’ll also reduce the numbers of rookies and veterans based on an arbitrary third variable to make the cases included in the datasets somewhat different from each other. rookies &lt;- WoJ %&gt;% filter(work_experience &lt;= 12) %&gt;% filter(autonomy_selection &gt; 1) veterans &lt;- WoJ %&gt;% filter(work_experience &gt;= 10) %&gt;% filter(ethics_1 &lt; 5) Combined, these two datasets include 1,169 unique journalists. The rookies are made up of 433 journalists and the veterans make up 853. 117 journalists are being classified as BOTH rookie AND veteran, i.e. have been counted twice. This means we are dealing with: 433 + 853 - 117 = 1,169. Now, let’s say you want to merge these datasets back together for some comparative analysis. The tidyr package (part of the tidyverse!) offers you different types of joins for this exact purpose. Let’s explore them! 6.4.1 inner_join This is like an overly correct librarian. It only takes rows that have matching keys in both datasets, otherwise it will drop the rows. inner_joined &lt;- inner_join(rookies, veterans, by = &quot;case_id&quot;) inner_joined ## # A tibble: 117 × 31 ## country.x reach.x employment.x temp_contract.x autonomy_selection.x ## &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 Germany National Full-time Permanent 5 ## 2 Denmark National Full-time Permanent 3 ## 3 UK Regional Full-time Permanent 3 ## 4 UK Transnational Full-time Permanent 4 ## 5 UK Regional Full-time Permanent 4 ## 6 Germany Local Full-time Permanent 4 ## 7 UK Regional Full-time Permanent 4 ## 8 Switzerland Regional Freelancer &lt;NA&gt; 2 ## 9 Denmark Regional Full-time Temporary 3 ## 10 Austria National Full-time Permanent 3 ## # ℹ 107 more rows ## # ℹ 26 more variables: autonomy_emphasis.x &lt;dbl&gt;, ethics_1.x &lt;dbl&gt;, ## # ethics_2.x &lt;dbl&gt;, ethics_3.x &lt;dbl&gt;, ethics_4.x &lt;dbl&gt;, ## # work_experience.x &lt;dbl&gt;, trust_parliament.x &lt;dbl&gt;, ## # trust_government.x &lt;dbl&gt;, trust_parties.x &lt;dbl&gt;, trust_politicians.x &lt;dbl&gt;, ## # case_id &lt;int&gt;, country.y &lt;fct&gt;, reach.y &lt;fct&gt;, employment.y &lt;chr&gt;, ## # temp_contract.y &lt;fct&gt;, autonomy_selection.y &lt;dbl&gt;, … 6.4.2 left_join This is like a fan of the first dataset. It takes all rows from the first dataset and the matched rows from the second dataset. left_joined &lt;- left_join(rookies, veterans, by = &quot;case_id&quot;) left_joined ## # A tibble: 433 × 31 ## country.x reach.x employment.x temp_contract.x autonomy_selection.x ## &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 Germany National Full-time Permanent 5 ## 2 Germany National Full-time Permanent 3 ## 3 Switzerland Regional Full-time Permanent 4 ## 4 Switzerland Local Part-time Permanent 4 ## 5 Denmark National Full-time Permanent 3 ## 6 Denmark National Full-time Permanent 2 ## 7 Austria Local Full-time Permanent 5 ## 8 UK Regional Full-time Permanent 3 ## 9 UK Transnational Full-time Permanent 4 ## 10 UK Transnational Full-time Permanent 4 ## # ℹ 423 more rows ## # ℹ 26 more variables: autonomy_emphasis.x &lt;dbl&gt;, ethics_1.x &lt;dbl&gt;, ## # ethics_2.x &lt;dbl&gt;, ethics_3.x &lt;dbl&gt;, ethics_4.x &lt;dbl&gt;, ## # work_experience.x &lt;dbl&gt;, trust_parliament.x &lt;dbl&gt;, ## # trust_government.x &lt;dbl&gt;, trust_parties.x &lt;dbl&gt;, trust_politicians.x &lt;dbl&gt;, ## # case_id &lt;int&gt;, country.y &lt;fct&gt;, reach.y &lt;fct&gt;, employment.y &lt;chr&gt;, ## # temp_contract.y &lt;fct&gt;, autonomy_selection.y &lt;dbl&gt;, … 6.4.3 right_join This is like a fan of the second dataset. It takes all rows from the second dataset and the matched rows from the first dataset. right_joined &lt;- right_join(rookies, veterans, by = &quot;case_id&quot;) # Pro tip: you can use the argument `by = your_column_here` to match the two datsets based on a specific column, e.g. case id right_joined ## # A tibble: 853 × 31 ## country.x reach.x employment.x temp_contract.x autonomy_selection.x ## &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 Germany National Full-time Permanent 5 ## 2 Denmark National Full-time Permanent 3 ## 3 UK Regional Full-time Permanent 3 ## 4 UK Transnational Full-time Permanent 4 ## 5 UK Regional Full-time Permanent 4 ## 6 Germany Local Full-time Permanent 4 ## 7 UK Regional Full-time Permanent 4 ## 8 Switzerland Regional Freelancer &lt;NA&gt; 2 ## 9 Denmark Regional Full-time Temporary 3 ## 10 Austria National Full-time Permanent 3 ## # ℹ 843 more rows ## # ℹ 26 more variables: autonomy_emphasis.x &lt;dbl&gt;, ethics_1.x &lt;dbl&gt;, ## # ethics_2.x &lt;dbl&gt;, ethics_3.x &lt;dbl&gt;, ethics_4.x &lt;dbl&gt;, ## # work_experience.x &lt;dbl&gt;, trust_parliament.x &lt;dbl&gt;, ## # trust_government.x &lt;dbl&gt;, trust_parties.x &lt;dbl&gt;, trust_politicians.x &lt;dbl&gt;, ## # case_id &lt;int&gt;, country.y &lt;fct&gt;, reach.y &lt;fct&gt;, employment.y &lt;chr&gt;, ## # temp_contract.y &lt;fct&gt;, autonomy_selection.y &lt;dbl&gt;, … 6.4.4 full_join This is like a hoarder. It takes all rows and throws in missings for variables that are not part of both datasets. full_joined &lt;- full_join(rookies, veterans, by = &quot;case_id&quot;) # Pro tip: you can use the argument `by = your_column_here` to match the two datsets based on a specific column, e.g. case id full_joined ## # A tibble: 1,169 × 31 ## country.x reach.x employment.x temp_contract.x autonomy_selection.x ## &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 Germany National Full-time Permanent 5 ## 2 Germany National Full-time Permanent 3 ## 3 Switzerland Regional Full-time Permanent 4 ## 4 Switzerland Local Part-time Permanent 4 ## 5 Denmark National Full-time Permanent 3 ## 6 Denmark National Full-time Permanent 2 ## 7 Austria Local Full-time Permanent 5 ## 8 UK Regional Full-time Permanent 3 ## 9 UK Transnational Full-time Permanent 4 ## 10 UK Transnational Full-time Permanent 4 ## # ℹ 1,159 more rows ## # ℹ 26 more variables: autonomy_emphasis.x &lt;dbl&gt;, ethics_1.x &lt;dbl&gt;, ## # ethics_2.x &lt;dbl&gt;, ethics_3.x &lt;dbl&gt;, ethics_4.x &lt;dbl&gt;, ## # work_experience.x &lt;dbl&gt;, trust_parliament.x &lt;dbl&gt;, ## # trust_government.x &lt;dbl&gt;, trust_parties.x &lt;dbl&gt;, trust_politicians.x &lt;dbl&gt;, ## # case_id &lt;int&gt;, country.y &lt;fct&gt;, reach.y &lt;fct&gt;, employment.y &lt;chr&gt;, ## # temp_contract.y &lt;fct&gt;, autonomy_selection.y &lt;dbl&gt;, … 6.5 Reformatting datasets In this subtutorial, we will learn how to use pivot_longer() and pivot_wider() functions from the tidyr package. We will create a fictional dataset based on the Worlds of Journalism (WoJ) dataset, with a twist - it will have several panel waves. Imagine that the WoJ dataset has been expanded to include data from different years: set.seed(123) WoJ_panel &lt;- WoJ %&gt;% slice_sample(n = 10) %&gt;% select(case_id, work_experience, autonomy_selection) %&gt;% mutate( work_experience_w2018 = work_experience + sample(-2:2, 10, replace = TRUE), work_experience_w2019 = work_experience_w2018 + sample(-2:2, 10, replace = TRUE), autonomy_selection_w2018 = autonomy_selection + sample(-1:1, 10, replace = TRUE), autonomy_selection_w2019 = autonomy_selection_w2018 + sample(-1:1, 10, replace = TRUE) ) %&gt;% select(-c(work_experience, autonomy_selection)) WoJ_panel ## # A tibble: 10 × 5 ## case_id work_experience_w2018 work_experience_w2019 autonomy_selection_w2018 ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 415 23 22 3 ## 2 463 6 5 4 ## 3 179 25 23 2 ## 4 526 37 37 3 ## 5 195 10 11 4 ## 6 938 26 24 5 ## 7 1142 1 1 5 ## 8 1038 7 9 4 ## 9 665 17 18 4 ## 10 602 2 1 1 ## # ℹ 1 more variable: autonomy_selection_w2019 &lt;dbl&gt; 6.5.1 pivot_longer() Let’s say you want to analyze how work experience and autonomy selection change over time. For this, you need to reshape the dataset into a longer format. long_data &lt;- WoJ_panel %&gt;% pivot_longer( cols = contains(&quot;_w&quot;), names_to = c(&quot;variable&quot;, &quot;wave&quot;), names_pattern = &quot;(.*)_(w\\\\d+)&quot;, # the symbol starts with any symbol that repeats 0 to several times until a _ is reached, followed by at least one digit values_to = &quot;value&quot; ) long_data ## # A tibble: 40 × 4 ## case_id variable wave value ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 415 work_experience w2018 23 ## 2 415 work_experience w2019 22 ## 3 415 autonomy_selection w2018 3 ## 4 415 autonomy_selection w2019 4 ## 5 463 work_experience w2018 6 ## 6 463 work_experience w2019 5 ## 7 463 autonomy_selection w2018 4 ## 8 463 autonomy_selection w2019 4 ## 9 179 work_experience w2018 25 ## 10 179 work_experience w2019 23 ## # ℹ 30 more rows This code transforms the dataset into a longer format where each row represents a single observation for a variable at a specific wave. 6.5.2 pivot_wider() Now, let’s say you want to do the opposite. You have a long dataset and you want to reshape it into a wider format. wide_data &lt;- long_data %&gt;% pivot_wider( names_from = c(&quot;variable&quot;, &quot;wave&quot;), names_sep = &quot;_&quot;, values_from = &quot;value&quot; ) wide_data ## # A tibble: 10 × 5 ## case_id work_experience_w2018 work_experience_w2019 autonomy_selection_w2018 ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 415 23 22 3 ## 2 463 6 5 4 ## 3 179 25 23 2 ## 4 526 37 37 3 ## 5 195 10 11 4 ## 6 938 26 24 5 ## 7 1142 1 1 5 ## 8 1038 7 9 4 ## 9 665 17 18 4 ## 10 602 2 1 1 ## # ℹ 1 more variable: autonomy_selection_w2019 &lt;dbl&gt; 6.6 Advanced column selectors Tidyselect is a package within the tidyverse that provides a set of functions for selecting and manipulating columns in a data frame. It is mainly used internally by other tidyverse packages, such as dplyr and tidyr, to handle column selections. Tidyselect functions, such as starts_with(), ends_with(), and contains(), allow you to specify column selections based on various patterns, such as prefixes, suffixes, and substrings. In this tutorial, we will look at the following tidyselect functions: 1. last_col() 2. starts_with() 3. ends_with() 4. contains() 5. matches() 6. num_range() 7. where() Let’s first import the full Worlds of Journalism dataset from the tidycomm package: data &lt;- tidycomm::WoJ 6.6.1 Selecting the last column Use last_col() when you want to select the last column of a data frame regardless of its name. data %&gt;% select(last_col()) ## # A tibble: 1,200 × 1 ## trust_politicians ## &lt;dbl&gt; ## 1 3 ## 2 3 ## 3 3 ## 4 3 ## 5 2 ## 6 2 ## 7 2 ## 8 3 ## 9 1 ## 10 3 ## # ℹ 1,190 more rows You can also select all columns except the last one: data %&gt;% select(!last_col()) ## # A tibble: 1,200 × 14 ## country reach employment temp_contract autonomy_selection autonomy_emphasis ## &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Germany Nati… Full-time Permanent 5 4 ## 2 Germany Nati… Full-time Permanent 3 4 ## 3 Switzerl… Regi… Full-time Permanent 4 4 ## 4 Switzerl… Local Part-time Permanent 4 5 ## 5 Austria Nati… Part-time Permanent 4 4 ## 6 Switzerl… Local Freelancer &lt;NA&gt; 4 4 ## 7 Germany Local Full-time Permanent 4 4 ## 8 Denmark Nati… Full-time Permanent 3 3 ## 9 Switzerl… Local Full-time Permanent 5 5 ## 10 Denmark Nati… Full-time Permanent 2 4 ## # ℹ 1,190 more rows ## # ℹ 8 more variables: ethics_1 &lt;dbl&gt;, ethics_2 &lt;dbl&gt;, ethics_3 &lt;dbl&gt;, ## # ethics_4 &lt;dbl&gt;, work_experience &lt;dbl&gt;, trust_parliament &lt;dbl&gt;, ## # trust_government &lt;dbl&gt;, trust_parties &lt;dbl&gt; 6.6.2 Selecting columns that start with, end with or contain a specific string starts_with() selects columns that start with a specific prefix: data %&gt;% select(starts_with(&quot;ethics&quot;)) ## # A tibble: 1,200 × 4 ## ethics_1 ethics_2 ethics_3 ethics_4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 3 2 1 ## 2 1 2 2 1 ## 3 2 4 2 1 ## 4 1 3 1 2 ## 5 2 3 2 1 ## 6 2 4 4 3 ## 7 1 3 2 2 ## 8 2 4 4 4 ## 9 1 2 1 3 ## 10 1 4 4 4 ## # ℹ 1,190 more rows ends_with() selects columns that end with onre or more specific suffixes: data %&gt;% select(ends_with(c(&quot;_1&quot;, &quot;_2&quot;))) # ends with _1 OR _2 ## # A tibble: 1,200 × 2 ## ethics_1 ethics_2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2 3 ## 2 1 2 ## 3 2 4 ## 4 1 3 ## 5 2 3 ## 6 2 4 ## 7 1 3 ## 8 2 4 ## 9 1 2 ## 10 1 4 ## # ℹ 1,190 more rows contains() selects columns that contain a specific substring: data %&gt;% select(contains(&quot;_&quot;)) ## # A tibble: 1,200 × 12 ## temp_contract autonomy_selection autonomy_emphasis ethics_1 ethics_2 ethics_3 ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Permanent 5 4 2 3 2 ## 2 Permanent 3 4 1 2 2 ## 3 Permanent 4 4 2 4 2 ## 4 Permanent 4 5 1 3 1 ## 5 Permanent 4 4 2 3 2 ## 6 &lt;NA&gt; 4 4 2 4 4 ## 7 Permanent 4 4 1 3 2 ## 8 Permanent 3 3 2 4 4 ## 9 Permanent 5 5 1 2 1 ## 10 Permanent 2 4 1 4 4 ## # ℹ 1,190 more rows ## # ℹ 6 more variables: ethics_4 &lt;dbl&gt;, work_experience &lt;dbl&gt;, ## # trust_parliament &lt;dbl&gt;, trust_government &lt;dbl&gt;, trust_parties &lt;dbl&gt;, ## # trust_politicians &lt;dbl&gt; matches() selects columns based on a regular expression pattern: data %&gt;% select(matches(&quot;^ethics&quot;)) # ^ stands for &quot;begins with&quot; in regex notation ## # A tibble: 1,200 × 4 ## ethics_1 ethics_2 ethics_3 ethics_4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 3 2 1 ## 2 1 2 2 1 ## 3 2 4 2 1 ## 4 1 3 1 2 ## 5 2 3 2 1 ## 6 2 4 4 3 ## 7 1 3 2 2 ## 8 2 4 4 4 ## 9 1 2 1 3 ## 10 1 4 4 4 ## # ℹ 1,190 more rows data %&gt;% select(matches(&quot;\\\\d&quot;)) # \\\\d stands for &quot;contains a digit/number&quot; ## # A tibble: 1,200 × 4 ## ethics_1 ethics_2 ethics_3 ethics_4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 3 2 1 ## 2 1 2 2 1 ## 3 2 4 2 1 ## 4 1 3 1 2 ## 5 2 3 2 1 ## 6 2 4 4 3 ## 7 1 3 2 2 ## 8 2 4 4 4 ## 9 1 2 1 3 ## 10 1 4 4 4 ## # ℹ 1,190 more rows Note: All of the above functions, except matches() are not case-sensetive. This means that they will match both upper- and lowercase letters. If you want to make them case-sensetive, use the ignore.case argument and set it to FALSE. data %&gt;% select(starts_with(&quot;Ethics&quot;, ignore.case = FALSE)) # but there is not capitalized Ethics in the data ## # A tibble: 1,200 × 0 6.6.3 Selecting columns based on a numeric range You can selects columns based on a numerical range with num_range(): data %&gt;% select(num_range(&quot;ethics_&quot;, 1:2)) # selects ethics_1 and ethics2, but not ethics_3, etc. ## # A tibble: 1,200 × 2 ## ethics_1 ethics_2 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2 3 ## 2 1 2 ## 3 2 4 ## 4 1 3 ## 5 2 3 ## 6 2 4 ## 7 1 3 ## 8 2 4 ## 9 1 2 ## 10 1 4 ## # ℹ 1,190 more rows 6.6.4 Selecting columns based on their type You can selects columns based on their type with where(), e.g., all character columns: data %&gt;% select(where(is.character)) ## # A tibble: 1,200 × 1 ## employment ## &lt;chr&gt; ## 1 Full-time ## 2 Full-time ## 3 Full-time ## 4 Part-time ## 5 Part-time ## 6 Freelancer ## 7 Full-time ## 8 Full-time ## 9 Full-time ## 10 Full-time ## # ℹ 1,190 more rows Or you could select all columns that contain numbers: data %&gt;% select(where(is.numeric)) ## # A tibble: 1,200 × 11 ## autonomy_selection autonomy_emphasis ethics_1 ethics_2 ethics_3 ethics_4 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5 4 2 3 2 1 ## 2 3 4 1 2 2 1 ## 3 4 4 2 4 2 1 ## 4 4 5 1 3 1 2 ## 5 4 4 2 3 2 1 ## 6 4 4 2 4 4 3 ## 7 4 4 1 3 2 2 ## 8 3 3 2 4 4 4 ## 9 5 5 1 2 1 3 ## 10 2 4 1 4 4 4 ## # ℹ 1,190 more rows ## # ℹ 5 more variables: work_experience &lt;dbl&gt;, trust_parliament &lt;dbl&gt;, ## # trust_government &lt;dbl&gt;, trust_parties &lt;dbl&gt;, trust_politicians &lt;dbl&gt; You could also use: 1) is.integer (whole numbers, e.g., 7) 2) is.double (decimal numbers, e.g., 7.25) 3) is.logical (e.g., TRUE/FALSE) 4) is.factor (e.g., “great”, “greater”, “the greatest”) 6.6.5 Combine selectors You can combine selectors, of course. Let’s select all character columns and columns that start with “autonomy”. data %&gt;% select(where(is.character) | starts_with(&quot;autonomy&quot;)) ## # A tibble: 1,200 × 3 ## employment autonomy_selection autonomy_emphasis ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Full-time 5 4 ## 2 Full-time 3 4 ## 3 Full-time 4 4 ## 4 Part-time 4 5 ## 5 Part-time 4 4 ## 6 Freelancer 4 4 ## 7 Full-time 4 4 ## 8 Full-time 3 3 ## 9 Full-time 5 5 ## 10 Full-time 2 4 ## # ℹ 1,190 more rows 6.6.6 Reorder your columns with everything() Finally, you can select all columns with everything(). This allows you to reorder your columns quickly: data %&gt;% select(temp_contract, country, everything()) ## # A tibble: 1,200 × 15 ## temp_contract country reach employment autonomy_selection autonomy_emphasis ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Permanent Germany Nati… Full-time 5 4 ## 2 Permanent Germany Nati… Full-time 3 4 ## 3 Permanent Switzerl… Regi… Full-time 4 4 ## 4 Permanent Switzerl… Local Part-time 4 5 ## 5 Permanent Austria Nati… Part-time 4 4 ## 6 &lt;NA&gt; Switzerl… Local Freelancer 4 4 ## 7 Permanent Germany Local Full-time 4 4 ## 8 Permanent Denmark Nati… Full-time 3 3 ## 9 Permanent Switzerl… Local Full-time 5 5 ## 10 Permanent Denmark Nati… Full-time 2 4 ## # ℹ 1,190 more rows ## # ℹ 9 more variables: ethics_1 &lt;dbl&gt;, ethics_2 &lt;dbl&gt;, ethics_3 &lt;dbl&gt;, ## # ethics_4 &lt;dbl&gt;, work_experience &lt;dbl&gt;, trust_parliament &lt;dbl&gt;, ## # trust_government &lt;dbl&gt;, trust_parties &lt;dbl&gt;, trust_politicians &lt;dbl&gt; 6.7 Advanced selection of rows You can make very advanced row selections by using the function str_detect from the stringr package in combination with filter from the dplyr package, especially if you combine str_detect with regular expressions Let’s start with partial matching, i.e., when your pattern is part of a string, select it: data %&gt;% filter(str_detect(employment, &quot;Free&quot;)) ## # A tibble: 172 × 15 ## country reach employment temp_contract autonomy_selection autonomy_emphasis ## &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Switzerl… Local Freelancer &lt;NA&gt; 4 4 ## 2 Denmark Nati… Freelancer &lt;NA&gt; 4 4 ## 3 Denmark Nati… Freelancer &lt;NA&gt; 5 5 ## 4 UK Tran… Freelancer &lt;NA&gt; 4 4 ## 5 Germany Regi… Freelancer &lt;NA&gt; 2 4 ## 6 Denmark Nati… Freelancer &lt;NA&gt; 4 4 ## 7 Denmark Nati… Freelancer &lt;NA&gt; 2 3 ## 8 Denmark Nati… Freelancer &lt;NA&gt; 4 3 ## 9 Austria Nati… Freelancer &lt;NA&gt; 5 5 ## 10 Denmark Regi… Freelancer &lt;NA&gt; 4 4 ## # ℹ 162 more rows ## # ℹ 9 more variables: ethics_1 &lt;dbl&gt;, ethics_2 &lt;dbl&gt;, ethics_3 &lt;dbl&gt;, ## # ethics_4 &lt;dbl&gt;, work_experience &lt;dbl&gt;, trust_parliament &lt;dbl&gt;, ## # trust_government &lt;dbl&gt;, trust_parties &lt;dbl&gt;, trust_politicians &lt;dbl&gt; Note that str_detect is case-sensitive, i.e., it reacts sensitive to capitalization. You won’tget a match for “free”: data %&gt;% filter(str_detect(employment, &quot;free&quot;)) ## # A tibble: 0 × 15 ## # ℹ 15 variables: country &lt;fct&gt;, reach &lt;fct&gt;, employment &lt;chr&gt;, ## # temp_contract &lt;fct&gt;, autonomy_selection &lt;dbl&gt;, autonomy_emphasis &lt;dbl&gt;, ## # ethics_1 &lt;dbl&gt;, ethics_2 &lt;dbl&gt;, ethics_3 &lt;dbl&gt;, ethics_4 &lt;dbl&gt;, ## # work_experience &lt;dbl&gt;, trust_parliament &lt;dbl&gt;, trust_government &lt;dbl&gt;, ## # trust_parties &lt;dbl&gt;, trust_politicians &lt;dbl&gt; In regex language, you can ask str_detectto look for lowercase and uppercase matches, when you are unsure of whether the entries are capitalized in your dataset: data %&gt;% filter(str_detect(employment, &quot;[fF]ree&quot;)) ## # A tibble: 172 × 15 ## country reach employment temp_contract autonomy_selection autonomy_emphasis ## &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Switzerl… Local Freelancer &lt;NA&gt; 4 4 ## 2 Denmark Nati… Freelancer &lt;NA&gt; 4 4 ## 3 Denmark Nati… Freelancer &lt;NA&gt; 5 5 ## 4 UK Tran… Freelancer &lt;NA&gt; 4 4 ## 5 Germany Regi… Freelancer &lt;NA&gt; 2 4 ## 6 Denmark Nati… Freelancer &lt;NA&gt; 4 4 ## 7 Denmark Nati… Freelancer &lt;NA&gt; 2 3 ## 8 Denmark Nati… Freelancer &lt;NA&gt; 4 3 ## 9 Austria Nati… Freelancer &lt;NA&gt; 5 5 ## 10 Denmark Regi… Freelancer &lt;NA&gt; 4 4 ## # ℹ 162 more rows ## # ℹ 9 more variables: ethics_1 &lt;dbl&gt;, ethics_2 &lt;dbl&gt;, ethics_3 &lt;dbl&gt;, ## # ethics_4 &lt;dbl&gt;, work_experience &lt;dbl&gt;, trust_parliament &lt;dbl&gt;, ## # trust_government &lt;dbl&gt;, trust_parties &lt;dbl&gt;, trust_politicians &lt;dbl&gt; You can also ask for matches that end on your pattern: data %&gt;% filter(str_detect(employment, &quot;time$&quot;)) ## # A tibble: 1,028 × 15 ## country reach employment temp_contract autonomy_selection autonomy_emphasis ## &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Germany Nati… Full-time Permanent 5 4 ## 2 Germany Nati… Full-time Permanent 3 4 ## 3 Switzerl… Regi… Full-time Permanent 4 4 ## 4 Switzerl… Local Part-time Permanent 4 5 ## 5 Austria Nati… Part-time Permanent 4 4 ## 6 Germany Local Full-time Permanent 4 4 ## 7 Denmark Nati… Full-time Permanent 3 3 ## 8 Switzerl… Local Full-time Permanent 5 5 ## 9 Denmark Nati… Full-time Permanent 2 4 ## 10 Austria Local Full-time Permanent 5 5 ## # ℹ 1,018 more rows ## # ℹ 9 more variables: ethics_1 &lt;dbl&gt;, ethics_2 &lt;dbl&gt;, ethics_3 &lt;dbl&gt;, ## # ethics_4 &lt;dbl&gt;, work_experience &lt;dbl&gt;, trust_parliament &lt;dbl&gt;, ## # trust_government &lt;dbl&gt;, trust_parties &lt;dbl&gt;, trust_politicians &lt;dbl&gt; I can’t cover regular expressions and the stringr package in this tutorial, but if you are interested in mastering regular expressions, you can have look at my tutorial for our MA journalism students. 6.8 Take-Aways Working directory: Avoid hard-coding your working directory as it is not reproducible on different machines. Instead, use the rstudioapi package to set the working directory dynamically based on the location of the R script. Use relative paths: Use relative paths to navigate your working directory. They describe how to navigate through folders and subfolders starting from your current location. Use ./ to move down a folder and ../ to move up one level in the folder hierarchy. Reading multiple files: When reading multiple files into R, create a character vector of file paths using list.files(). Use the map() function from the purrr package to iterate over the file paths and read each file using functions like read.csv(). Combine the resulting data frames using bind_rows() from the dplyr package. Advanced column selectors: Use advanced column selectors from the tidyselect package in dplyr::select() to select and manipulate columns in a data frame. Examples include last_col(), starts_with(), ends_with(), contains(), matches(), num_range(), and where() in select(). Reorder columns: using everything() in select() to select all columns and place them in a desired order. Advanced row selectors: Use str_detect() from the stringr package in dplyr::filter() to filter observations based on a pattern or regular expression. You still have questions? The following book can help you with that: Going from Beginner to Advanced in the Tidyverse by C. Burkhart "],["tutorial-data-visualization-with-ggplot.html", " 7 Tutorial: Data visualization with ggplot 7.1 Why not stick with Base R? 7.2 Components of a ggplot graph 7.3 Installing &amp; activating ggplot 7.4 Building your first plot 7.5 Other common plot types 7.6 Take Aways 7.7 Additional tutorials", " 7 Tutorial: Data visualization with ggplot After working through Tutorial 6, you’ll… know what each graphical component of a ggplot graph contributes to the final visualization understand the grammer of graphics (or simply: the ggplot2 syntax) to combine graphical components know how to make your own data visualizations using ggplot2 7.1 Why not stick with Base R? The ggplot2 package, i.e. the data visualization package of tidyverse, has become the R package for data visualization. While Base R can be used to visualize data, the ggplot2 package makes data visualization so much easier that I recommend starting with ggplot2 right away and skipping data visualization in Base R altogether. The gg in ggplot2 stands for grammar of graphics, which means that we can describe each component of a graph layer by layer and component by component. You only have to provide ggplot() with a source object (i.e. data) and specify what variables it should map to the aesthetical attributes (color, shape, size) of certain geometric objects (points, lines, bars) – and ggplot will take care of the rest! The inventor of ggplot2, Hadley Wickham, describes the benefits of ggplot2 like this: “In order to unlock the full power of ggplot2, you’ll need to master the underlying grammar. By understanding the grammar, and how its components fit together, you can create a wider range of visualizations, combine multiple sources of data, and customise to your heart’s content… The grammar makes it easier for you to iteratively update a plot, changing a single feature at a time. The grammar is also useful because it suggests the high-level aspects of a plot that can be changed, giving you a framework to think about graphics, and hopefully shortening the distance from mind to paper. It also encourages the use of graphics customised to a particular problem, rather than relying on specific chart types.” (Wickham et al., 2021, no page; bold words inserted) Just as dplyr simplifies data manipulation, ggplot2 simplifies data visualization. In addition, ggplot2 and dplyr work hand in hand: You can prepare your data selection and manipulation with dplyr and pipe it directly into ggplot to turn your transformed data into a beautiful graph. With only a few lines of code, you can produce graphs like this one: This is the code. Right now, it might still look a bit overwhelming to you, but once you’ve understood the grammar of graphics, it really is a just a small jigsaw puzzle. Moreover, you don’t usually start with graphs that are this complicated, but with basic scatter or bar plots. library(ggplot2) plot &lt;- starwars_data %&gt;% filter(species == &quot;Human&quot; | species == &quot;Droid&quot;) %&gt;% ggplot(aes(x = height, y = mass, size = birth_year, fill = species)) + geom_point(shape = 21, alpha = 0.25, color = &quot;black&quot;) + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) + scale_size(range = c(1, 11), name = &quot;age&quot;) + ggrepel::geom_text_repel(aes(label = name), size = 2.3) + theme_bw() + labs( title = &quot;Mass vs. height of humans and droids in Star Wars&quot;, x = &quot;Height (cm)&quot;, y = &quot;Weight (kg)&quot; ) + facet_wrap(~species) To visit the official documentation of ggplot2: 1. type ?ggplot2 in your console 2. visit the ggplot documentation 3. visit the ggplot homepage of the tidyverse 7.2 Components of a ggplot graph As mentioned before, the main idea behind ggplot is to generate a statistical plot by combining layers that represent geometric objects (e.g. points and lines). By linking data to the aesthetic features of these geometric objects (e.g. colors, size, transparency), the aesthetic properties of the geometric objects may be controlled. In the words of Wickham: “A graphic maps the data to the aesthetic attributes (colour, shape, size) of geometric objects (points, lines, bars).” Wickham et al., 2021, no page; bold words inserted Image: The logic of adding layer by layer in ggplot (Source: R @ Ewah 2020): The necessary components of a ggplot graph are: Source object / data: The data that you would like to visualize. Geometries geom_: Geom options allow you to specify what geometric objects will represent the data (i.e. points, bars, lines, and many more). Aesthetics aes(): Aesthetics allows you to map variables to the x- and y-axis and to the aesthetics of those geometric objects (i.e. position, color, size, shape, linetype, and transparency). The complementary, but not necessary components of a ggplot graph are: Scales scale_: Scale options allow you to fine-tune the mapping from the variables to the aesthetics. You can fine-tune axis limits, tick breaks, grid lines, or any other axis/geometric object transformations that depend on the range of a specific scale. Statistical transformations stat_: Allows you to produce statistical summaries of the data for visualization (i.e. means and standard deviations, fitted curves, and many more). Coordinate system coord_: Allows you to change the appearance of your coordinate system (i.e. flip the coordinates to turn horizontal bar chart into a vertical one). Position: to adjust overlapping objects, e.g. jittering, stacking or dodging. Facets facet_: Allows you to divide your plot into multiple subplots. Visual themes theme(): Allows you to specify the visual basics of a plot, such as background, default typeface, sizes, and colors. Axis labels labs(): Allows you to change the plot’s main title and the axis labels. 7.3 Installing &amp; activating ggplot You can always activate ggplot2 by activating the meta-package tidyverse: library(tidyverse) If for some reason you do not want to activate the whole tidyverse, you should install ggplot2 and activate this package separately: install.packages(&quot;ggplot2&quot;) # install the package (only on the first time) library(ggplot2) # active the package 7.4 Building your first plot In the next sections, you will create your very first plot – layer by layer. We will look at some of the most important components that you will regularly add to graphs and you will learn how to make use of them. 7.4.1 Data Obviously, you need data to perform data visualization. Therefore, our first step is to load the starwars data, but let’s keep only humans and droids for now. To this end, assign your transformed data to a new data frame called human_droid_data. human_droid_data &lt;- dplyr::starwars %&gt;% filter(species == &quot;Human&quot; | species == &quot;Droid&quot;) The function ggplot() can only create a plot if we explicitly tell the function what data to use, so this graphical component is necessary. Using our dplyr skills, let’s use the human_droid_data as our source object and apply the ggplot() function to it by using a pipe (i.e. %&gt;%). human_droid_data %&gt;% ggplot() The ggplot() function creates a blank canvas (i.e. first layer). We now have to draw on it. 7.4.2 Aesthetics To draw on this blank canvas, we must at least tell the ggplot() function which variables to assign to the x- and y-axis by using the aes() function. Thus, the Aesthetics graph component is also necessary in every single plot. human_droid_data %&gt;% ggplot(aes(x = height, y = mass)) The aes() function allows you to specify the following arguments (and many more, as you will learn over time): x: the variable that should be mapped to the x axis y: the variable that should be mapped to the y size: the variable that should be used for determining the size of a geometric object fill: the variable that should be used for filling a geometric object with a specific color color: the variable that should be used for outlining a geometric object with a specific color 7.4.3 Geometrics Finally, we can turn to the last necessary component of any ggplot graph: the geometric objects that fill your canvas. The choice of these geometric objects determines what kind of chart you create. The geom_ component of the ggplot() function allows you to create the following chart types (and many more, as you will learn over time): geom_bar(): to create a bar chart geom_histogram: to create a histogram geom_line(): to create a line graph geom_point(): to create a scatter or bubble plot geom_boxplot(): to create a box plot Now let’s add the data points (x,y) with geom_point() to our canvas to make it a scatter plot: human_droid_data %&gt;% ggplot(aes(x = height, y = mass)) + geom_point() That’s a scatter plot for sure! And you only needed three necessary components to create it: data (i.e. a source object), aesthetics aes(), and geometric objects geom_. 7.4.4 Scales A scale is a mapping from data to the final values that computers can use to actually show the aesthetics. In this sense, a scale regulates the aesthetic mapping of variables to aesthetics. Providing a scale_ is not necessary to create a graph, but it allows you to fine-tune aesthetic mappings to customize your graph. scale_ is very powerful and over time, you will learn about a lot of things that you can customize with it. For now, we will only focus on a few of these. We will use scale_ to : change the limits and ticks of the x and y axis change how a third variable (besides x and y) is mapped to the aesthetics of our geometric object First, we will use scale_ to modify the x and the y axis by providing the graph with new axis limits. human_droid_data %&gt;% ggplot(aes(x = height, y = mass)) + geom_point() + scale_y_continuous(limits = c(30, 140)) + # modify the y axis limits scale_x_continuous(limits = c(90, 210)) # modify the x axis limits Second, we’ll add more ticks to make the graph better readable. human_droid_data %&gt;% ggplot(aes(x = height, y = mass)) + geom_point() + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + # choose where the ticks of the y axis appear scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) # choose where the ticks of the x axis appear Until now, we have used scale_ to transform only the axes. But we can also use it to change the mapping of variables to geometric objects. To demonstrate this, we now add another variable to our graph, namely the age (birth_year) of the humanoid and droid Star Wars characters. Let’s map age to our data points (i.e. geom_point()) so that larger bubbles reflect older age. human_droid_data %&gt;% ggplot(aes(x = height, y = mass, size = birth_year)) + # map birth_year (age) to the size of the following geometric objects geom_point() + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) Personally, I feel like these bubbles could use a little bit of rescaling to make age differences stand out more. In addition, you could get a nicer title for the size legend than “birth_year”. Let’s try that. human_droid_data %&gt;% ggplot(aes(x = height, y = mass, size = birth_year)) + geom_point() + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) + scale_size(range = c(1, 11), name = &quot;age&quot;) # sets the bubbles&#39; size in a range between 1 and 11 and renames the respective legend title to &quot;age&quot; Perfect! The legend spells “age” and age differences seem a bit more obvious now. Unfortunately, some data points are now overlapping. I think this is a good time to introduce you to the differences between using scale_ and adding aesthetics to the geom_ objects directly. While the former allows you to change the mapping from variables to the aesthetics of geometric objects, the latter one allows you to provide a constant. This means that the aesthetic mapping does not depend on the values of a variable, but is set to a single default value. To demonstrate this and fix the overlap of our bubbles, we change the transparency value of the bubbles so that they become transparent. Note that all the values given are constants, which means that they do not depend on a third variable like birth_year. human_droid_data %&gt;% ggplot(aes(x = height, y = mass, size = birth_year)) + geom_point(shape = 21, fill = &quot;black&quot;, alpha = 0.25, color = &quot;black&quot;) + # shape = 21 is creating bubbles that have a border (i.e. outline), fill = &quot;black&quot; fills the bubble with black ink, alpha = 0.25 to make the bubbles` black ink 25% transparent and color = &quot;black&quot; to make the border (i.e. outline) pitch black scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) + scale_size(range = c(1, 11), name = &quot;age&quot;) This looks way more readable. I think we are ready to move on to Themes. 7.4.5 Themes Just like scale_, theme_is an optional ggplot component, i.e. not necessary. Themes are visually appealing presets for charts, e.g., they influence whether grid lines are visible or whether certain color palettes are applied to the data. By using themes you can make your graphs more beautiful and give them a consistent style without any effort, which is especially useful for longer texts like theses. To familiarize yourself with the various options, take a look at this overview of all ggplot2 themes. If you don’t like grid lines, for example, theme_classic() might be to your taste: human_droid_data %&gt;% ggplot(aes(x = height, y = mass, size = birth_year)) + geom_point(shape = 21, fill = &quot;black&quot;, alpha = 0.25, color = &quot;black&quot;) + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) + scale_size(range = c(1, 11), name = &quot;age&quot;) + theme_classic() Personally, I really enjoy the theme_bw() (black-and-white theme). So let’s apply it to our graph: human_droid_data %&gt;% ggplot(aes(x = height, y = mass, size = birth_year)) + geom_point(shape = 21, fill = &quot;black&quot;, alpha = 0.25, color = &quot;black&quot;) + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) + scale_size(range = c(1, 11), name = &quot;age&quot;) + theme_bw() 7.4.6 Labs Again, labs() is not a necessary, but an optional component of your graph. Using the labs() function allows you to set a main title for your plot and to change the labels of the x and y axis. Let’s try it: human_droid_data %&gt;% ggplot(aes(x = height, y = mass, size = birth_year)) + geom_point(shape = 21, fill = &quot;black&quot;, alpha = 0.25, color = &quot;black&quot;) + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) + scale_size(range = c(1, 11), name = &quot;age&quot;) + theme_bw() + labs( title = &quot;Mass vs. height of humans and droids in Star Wars&quot;, x = &quot;Height (cm)&quot;, y = &quot;Weight (kg)&quot; ) Now that we’ve added a main title, it becomes clear that we can’t really distinguish the data points that represent humans from those that represent droids. 7.4.7 Facets Faceting divides plot into tiny subplots, which display different subsets of your data. Facets are an effective way to explore your data because they allow you to rapidly detect divergent patterns in these subsets. Of course, faceting is optional, i.e. not necessary. You don’t need faceting if you don’t want to compare different groups within your data. The two approaches to faceting are: facet_wrap(): uses the levels of one (or more) variable(s) to create groups + panels for each group; useful if you have a single categorical variable with many levels facet_grid(): produces a matrix of panels defined by two variables which form the rows and columns Image: The logic of faceting (Source: Wickham et al., 2021): Let’s use the facet_wrap() function to create two subplots for our two different levels of the species variable: Droid and Human. You can provide two arguments to facet_wrap(): ~, followed by the grouping variable nrow: the number of rows in which panels should be placed human_droid_data %&gt;% ggplot(aes(x = height, y = mass, size = birth_year)) + geom_point(shape = 21, fill = &quot;black&quot;, alpha = 0.25, color = &quot;black&quot;) + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) + scale_size(range = c(1, 11), name = &quot;age&quot;) + theme_bw() + labs( title = &quot;Mass vs. height of humans and droids in Star Wars&quot;, x = &quot;Height (cm)&quot;, y = &quot;Weight (kg)&quot; ) + facet_wrap(~species, nrow = 2) # using ~grouping_variable and nrow = 2 shows the two panels on top of each other Great, finally we can distinguish the data points representing humans from those representing droids! On the left side, however, the panel with the humans looks a bit empty. Maybe we should put them next to each other. human_droid_data %&gt;% ggplot(aes(x = height, y = mass, size = birth_year)) + geom_point(shape = 21, fill = &quot;black&quot;, alpha = 0.25, color = &quot;black&quot;) + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) + scale_size(range = c(1, 11), name = &quot;age&quot;) + theme_bw() + labs( title = &quot;Mass vs. height of humans and droids in Star Wars&quot;, x = &quot;Height (cm)&quot;, y = &quot;Weight (kg)&quot; ) + facet_wrap(~species) # nrow=1 is the default, so you don´t have to call it explicitly I like that! 7.4.8 Saving graphs I think it’s time that we save this plot. To finish of this “masterpiece” (and make it less triste), let’s add some final colors before saving. We’ll fill our bubbles with colorful ink based on the species variable, so we need to add fill=species to the aes() and remove the default black ink provided in the geom_point() function. human_droid_data %&gt;% ggplot(aes(x = height, y = mass, size = birth_year, fill = species)) + geom_point(shape = 21, alpha = 0.25, color = &quot;black&quot;) + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) + scale_size(range = c(1, 11), name = &quot;age&quot;) + theme_bw() + labs( title = &quot;Mass vs. height of humans and droids in Star Wars&quot;, x = &quot;Height (cm)&quot;, y = &quot;Weight (kg)&quot; ) + facet_wrap(~species) Congratulations! You have just managed to recreate the plot from the beginning of this tutorial! The only thing we haven’t covered yet is the labeling of all data points, because for that you’d need the ggrepel package to not mess up the labels - and that’s not part of ggplot2. So let’s skip that and save our graph. To use your graph in another document, e.g. a theses written in Word, you’ll have to export the plot first. Therefore, you must assign your plot to a new object and call the ggsave() function on that object. The plot will be saved to your working directory and formatted according to the file extension you specified (for example: .jpeg or .png). plot &lt;- human_droid_data %&gt;% ggplot(aes(x = height, y = mass, size = birth_year, fill = species)) + geom_point(shape = 21, alpha = 0.25, color = &quot;black&quot;) + scale_y_continuous(limits = c(30, 140)) + scale_x_continuous(limits = c(90, 210)) + scale_y_continuous(breaks = c(40, 60, 80, 100, 120, 140, 160)) + scale_x_continuous(breaks = c(100, 120, 140, 160, 180, 200)) + scale_size(range = c(1, 11), name = &quot;age&quot;) + theme_bw() + labs( title = &quot;Mass vs. height of humans and droids in Star Wars&quot;, x = &quot;Height (cm)&quot;, y = &quot;Weight (kg)&quot; ) + facet_wrap(~species) ggsave(filename = &quot;mass_vs_height.jpeg&quot;, plot) 7.5 Other common plot types I can’t give an overview of all possible types of plots, but I can at least touch a bit on how other common types of geom_ behave. 7.5.1 bar plots Bar plots are very common. They are either (1) used to display the frequency with which a certain factor level of a categorical variable occurs or (2) to display relationships between a categorical variable and a metric variable. So let’s create a quick bar plot using the sex variable (categorical, three factor levels) and get an overview on how many human and droidic Star Wars characters are male, female, or do not have a sex. human_droid_data %&gt;% ggplot(aes(x = sex)) + # We only have to specify the variable that we want to get the count for (i.e. number of observations) geom_bar() Next, let’s look at the relationship between sex and the height (metric) variable. We will produce a bar plot that displays the mean height of each group: human_droid_data %&gt;% ggplot(aes(x = sex, y = height)) + # Now we need to specify the variable that we want to summarize with mean statistics geom_bar(stat = &quot;summary&quot;, fun.y = &quot;mean&quot;) # apply the summary statistic of y (mean) to the geom_bars There is an alternative writing style for those bar plots that show mean values. In this writing style, you don’t apply the summary statistics to the geom_bar, but you apply the geom_bar to the summary statistics (You might remember the optional stat_ component of graphs from chapter Components of a ggplot graph). While this writing style is a bit awkward, it is more flexible. So I’d recommend this code for mean bar plots: human_droid_data %&gt;% ggplot(aes(x = sex, y = height)) + stat_summary(geom = &quot;bar&quot;, fun = &quot;mean&quot;) Maybe we want to sort the bars according to their mean. Let’s reorder the factor levels manually. human_droid_data %&gt;% mutate(sex = factor(sex, levels = c(&quot;male&quot;, &quot;female&quot;, &quot;none&quot;))) %&gt;% # This command reorders the factor levels, male = first level, female = second level, none = third level ggplot(aes(x = sex, y = height)) + stat_summary(geom = &quot;bar&quot;, fun = &quot;mean&quot;) And if we would like to have a horizontal bar plot, we can use the coord_ component of ggplot() to flip the coordinates. human_droid_data %&gt;% mutate(sex = factor(sex, levels = c(&quot;male&quot;, &quot;female&quot;, &quot;none&quot;))) %&gt;% ggplot(aes(x = sex, y = height)) + stat_summary(geom = &quot;bar&quot;, fun = &quot;mean&quot;) + coord_flip() 7.5.2 box plots Box plots are a great option to summarize metric variables (by groups). They provide you with the Five-number-summary: the sample minimum (smallest observation) – lower whisker the lower quartile – lower end of the box the median (the middle value) – thick black line the upper quartile – upper end of the box the sample maximum (largest observation) – upper whisker Let’s create box plots of the height for human and droidic Star Wars characters who are male, female, or do not have a sex. human_droid_data %&gt;% ggplot(aes(x = sex, y = height)) + geom_boxplot() While box plots are a very powerful tool of data visualization, they are not understood by statistical laymen. Please don’t use them in non-scientific contexts. 7.6 Take Aways graph creation: ggplot() mapping variables to aesthetics: aes(x, y, color, fill, size, etc.) chart type: geom_bar(), geom_line(), geom_point(), geom_boxplot() (for example) titles: labs() axis limits/ticks: scale_x_continuous(), scale_y_continuous() mapping variables to geom size: scale_size() themes: theme_classic(), theme_light(), theme_bw() (for example) faceting: facet_wrap() or facet_grid save images: ggsave() 7.7 Additional tutorials You still have questions? The following tutorials &amp; papers can help you with that: Chang, W. R (2021). R Graphics Codebook. Practical Recipes for Visualizing Data. Link Wickham, H., Navarro, D., &amp; Pedersen, T. L. (2021). ggplot2: elegant graphics for data analysis. Online, work-in-progress version of the 3rd edition. Link Hehman, E., &amp; Xie, S. Y. (2021). Doing Better Data Visualization. Advances in Methods and Practices in Psychological Science. DOI: 10.1177/25152459211045334 Link R Codebook by J.D. Long and P. Teetor, Tutorial 10 Now let’s see what you’ve learned so far: Exercise 4: ggplot. "],["exercise-4-ggplot.html", "Exercise 4: ggplot Task 1 Task 2 Task 3 Task 4 Task 5 Task 6", " Exercise 4: ggplot After working through Exercise 4, you’ll… be able to see a problem and customize a scatter plot with dplyr &amp; ggplot2 to solve it First, load the WoJ (World of Journalism) dataset from the tidycomm package. Install tidycomm if you haven’t already and then assign the WoJ dataset in its own R object: install.packages(&quot;tidycomm&quot;) # run only the first time WoJ &lt;- tidycomm::WoJ If you want help to solve this exercise, here’s a step-by-step tutorial that I’ve created for you: Task 1 Try creating your own scatter plot. First, load tidyverse to access ggplot2 for data visualization: library(tidyverse) Show how journalists’ work experience (work_experience) is associated with their trust in politicians (trust_politicians). To do this, create a very basic scatter plot using ggplot2 and the respective ggplot() function. Use the aes() function inside ggplot() to map variables to the visual properties. Use geom_point() to add points to the plot. Task 2 Do more experienced journalists become less trusting in politicians? Add this code to your plot to create a regression line: + geom_smooth(method = lm, se = FALSE). What can you conclude from the regression line? Task 3 Does the relationship between work experience and trust in politicians remain stable across different countries? Alternatively, does work experience influence trust in politicians differently depending on the specific country context? Try to create a visualization to answer this question using facet_wrap(). Task 4 In your current visualization, it may be challenging to discern cross-country differences. Let’s aim to create a visualization that illustrates these differences across countries more distinctly. Remove the facet_wrap() and the geom_point() code line. This leaves you with this graph: WoJ %&gt;% ggplot(aes(x = work_experience, y = trust_politicians)) + geom_smooth(method = lm, se = FALSE) Now, display every country in a separate color by using the color argument inside the aes() function. Task 5 Add fitting labels to your plot. For example, set the main title to display: “Impact of Work Experience on Trust in Politicians”. The x-axis label should read “Years of Work Experience in Journalism”, and the y-axis label should read “Trust in Politicians on a 5-point Likert Scale”. The label for the color legend should be “Country”. Task 6 Add a nice theme that you like, e.g. theme_minimal(), theme_classic() or theme_bw(). "],["exercise-5-ggplot.html", "Exercise 5: ggplot 7.8 Task 1 7.9 Task 2 7.10 Task 3 7.11 Task 4 7.12 Task 5", " Exercise 5: ggplot After working through Exercise 5, you’ll… - be able to see a graph and recreate it with ggplot2 - be able to see a problem and customize any type of plot with dplyr &amp; ggplot2 to solve it 7.8 Task 1 Please set your working directory and load the WoJ_names.csv. setwd(&quot;C:/Users/LaraK/Documents/IPR/&quot;) data &lt;- read.csv2(&quot;WoJ_names.csv&quot;, header = TRUE) (Install + ) load the ggplot2 package. # installing/loading the package: if (!require(ggplot2)) { install.packages(&quot;ggplot2&quot;) require(ggplot2) } # load / install+load ggplot2 Now, create a box plot to visualize the distribution of work experience in years for each country in the dataset: - Assign country to the x-axis and work_experience to the y-axis. - Use the geom_boxplot() function to generate a box plot. - Choose an appropriate theme. - Label the axes and the title appropriately using labs(). 7.9 Task 2 Look at this graph and try to recreate it. 7.10 Task 3 Try to create an advanced version of your graph from Task 2 that shows the names of the journalists. You can use the geom_text function for the labels, like this: geom_text(aes(label = name), check_overlap = TRUE) ## mapping: label = ~name ## geom_text: parse = FALSE, check_overlap = TRUE, na.rm = FALSE ## stat_identity: na.rm = FALSE ## position_identity If you’d like to adjust the position of the labels, you can add the argument , hjust = 0, vjust = 0 to this command, like this: geom_text(aes(label = name), check_overlap = TRUE, hjust = 0, vjust = 0) ## mapping: label = ~name ## geom_text: parse = FALSE, check_overlap = TRUE, na.rm = FALSE ## stat_identity: na.rm = FALSE ## position_identity 7.11 Task 4 Next, try to recreate this bar plot. Use geom_bar to create it. data %&gt;% ggplot(aes(x = country, fill = employment)) + geom_bar(position = &quot;dodge&quot;) + theme_bw() + labs(x = &quot;Country&quot;, y = &quot;Count&quot;, fill = &quot;Employment Type&quot;, title = &quot;Employment Types by Country&quot;) 7.12 Task 5 Try to create an advanced version of the graph from Task 4. First, create a new variable ‘experience_level’ that categorizes the ‘work_experience’ into three groups: - “Junior” for work_experience &lt;= 10 - “Mid-Level” for work_experience &gt; 10 &amp; &lt;= 20 - “Senior” for work_experience &gt; 20 Next, use the new variable ‘experience_level’ to create separate graphs for juniors, mid-level staff, and seniors. Note: To make the graph look better, you should rotate the x-axis labels and move the labels a bit more to the bottom of the graph. You can use the theme() function and adjust the axis.text.x argument. In this case, you’d use theme(element_text(angle = 45, hjust = 1)) at the end of your code. "],["tutorial-data-analysis-with-tidycomm.html", " 8 Tutorial: Data analysis with tidycomm 8.1 Installing a package from GitHub 8.2 7.2 Compute intercoder reliability 8.3 7.3 How to run descriptive analyses 8.4 How to run significance tests", " 8 Tutorial: Data analysis with tidycomm After working through Tutorial 7, you’ll… understand how to install a package from GitHub instead of CRAN. learn how to use the tidycomm package to perform descriptive analyses and run significance tests. get a first glimpse into quick visualizations of your significance tests using tidycomm. 8.1 Installing a package from GitHub In this part of the tutorial, we’re going to learn how to install R packages directly from GitHub, specifically from a development branch named devel. Why might we want to do this? There are several reasons. Often, the most recent and innovative features of a package are found in these development branches. Developers use these branches to try out new features and fix bugs before merging them into the main branch that will be deployed via CRAN. By installing from the devel branch, you can access the latest features and updates ahead of their official release. It’s like a sneak peek into the future of the package! However, it’s important to note that because these branches are under development, they might be unstable or have unaddressed issues. Hence, these versions are recommended for users who want to try the latest features or for those who are involved in the development of the package. Now, let’s dive in and learn how to install the tidycomm package from the devel branch on GitHub. First, you will need to install and load the devtools package, a package that supports R package development. In addition, install and load the remotes package, which allows you to install packages from Github. # install.packages(&quot;devtools&quot;) # run only the first time # install.packages(&quot;remotes&quot;) # run only the first time library(devtools) library(remotes) Next, navigate to Julian Unkel’s Github repository that stores tidycomm in your internet browser. Here you can see that Julian has several branches in this repository, one of which is called devel. To install the tidycomm package from this devel branch, use the install.github function from the remotes package. Provide the GitHub username, the repository name, and the branch name as follows: remotes::install_github(&quot;joon-e/tidycomm@devel&quot;) # Alternatively, you can use this code: remotes::install_github(&quot;joon-e/tidycomm&quot;, ref=&quot;devel&quot;) Then, load the package: library(tidycomm) Finally, load the WoJ and the fbposts data: WoJ &lt;- tidycomm::WoJ fbposts &lt;- tidycomm::fbposts The tidycomm package provides convenience functions for common data modification and analysis tasks in communication research. This includes functions for univariate and bivariate data analysis, index generation and reliability computation, and intercoder reliability tests. 8.2 7.2 Compute intercoder reliability You can use tidycomm for your content analyses projects. The test_icr function performs an intercoder reliability test by computing various intercoder reliability estimates (e.g., Krippendorff’s alpha, Cohen’s kappa) for the included variables. If no variables are specified, the function will compute for all variables in the data set (excluding the unit_var and coder_var). Let’s take a quick look at the fbposts data set that comes pre-packaged with tidycomm. It’s a coder-annotated data set, with each Facebook post (post_id) annotated by several coders (coder_id). fbposts %&gt;% head() ## # A tibble: 6 × 7 ## post_id coder_id type n_pictures pop_elite pop_people pop_othering ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 photo 1 0 0 0 ## 2 1 2 photo 1 0 0 0 ## 3 1 3 photo 1 0 0 0 ## 4 1 4 photo 1 0 0 0 ## 5 1 5 photo 1 0 0 0 ## 6 1 6 photo 1 0 0 0 Next, let’s calculate intercoder reliability estimates for each variable in the fbposts data set, excluding post_id and coder_id. The output includes simple percent agreement, Holsti’s reliability estimate (mean pairwise agreement), and Krippendorff’s Alpha by default, but you can specify other estimates to compute via optional arguments / parameters. fbposts %&gt;% test_icr(post_id, coder_id) ## # A tibble: 5 × 8 ## Variable n_Units n_Coders n_Categories Level Agreement Holstis_CR ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 type 45 6 4 nominal 1 1 ## 2 n_pictures 45 6 7 nominal 0.822 0.930 ## 3 pop_elite 45 6 6 nominal 0.733 0.861 ## 4 pop_people 45 6 2 nominal 0.778 0.916 ## 5 pop_othering 45 6 4 nominal 0.867 0.945 ## # ℹ 1 more variable: Krippendorffs_Alpha &lt;dbl&gt; Here are some more ICR estimates: fbposts %&gt;% test_icr(post_id, coder_id, fleiss_kappa = TRUE, lotus = TRUE ) ## # A tibble: 5 × 10 ## Variable n_Units n_Coders n_Categories Level Agreement Holstis_CR ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 type 45 6 4 nominal 1 1 ## 2 n_pictures 45 6 7 nominal 0.822 0.930 ## 3 pop_elite 45 6 6 nominal 0.733 0.861 ## 4 pop_people 45 6 2 nominal 0.778 0.916 ## 5 pop_othering 45 6 4 nominal 0.867 0.945 ## # ℹ 3 more variables: Krippendorffs_Alpha &lt;dbl&gt;, Fleiss_Kappa &lt;dbl&gt;, ## # Lotus &lt;dbl&gt; 8.3 7.3 How to run descriptive analyses 8.3.1 7.3.1 Index generation The tidycomm package provides a workflow to quickly add mean/sum indices of variables to the dataset and compute reliability estimates for those added indices. The package offers two key functions: add_index() and get_reliability() 8.3.1.1 7.3.1.1 add_index(): The add_index() function adds a mean or sum index of the specified variables to the data. The second argument (or first, if used in a pipe) is the name of the index variable to be created. For example, if you want to create a mean index named ‘ethical_concerns’ using variables ‘ethics_1’ to ‘ethics_4’, you can use the following code: WoJ %&gt;% add_index(ethical_concerns, ethics_1, ethics_2, ethics_3, ethics_4) ## # A tibble: 1,200 × 16 ## country reach employment temp_contract autonomy_selection autonomy_emphasis ## * &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Germany Nati… Full-time Permanent 5 4 ## 2 Germany Nati… Full-time Permanent 3 4 ## 3 Switzerl… Regi… Full-time Permanent 4 4 ## 4 Switzerl… Local Part-time Permanent 4 5 ## 5 Austria Nati… Part-time Permanent 4 4 ## 6 Switzerl… Local Freelancer &lt;NA&gt; 4 4 ## 7 Germany Local Full-time Permanent 4 4 ## 8 Denmark Nati… Full-time Permanent 3 3 ## 9 Switzerl… Local Full-time Permanent 5 5 ## 10 Denmark Nati… Full-time Permanent 2 4 ## # ℹ 1,190 more rows ## # ℹ 10 more variables: ethics_1 &lt;dbl&gt;, ethics_2 &lt;dbl&gt;, ethics_3 &lt;dbl&gt;, ## # ethics_4 &lt;dbl&gt;, work_experience &lt;dbl&gt;, trust_parliament &lt;dbl&gt;, ## # trust_government &lt;dbl&gt;, trust_parties &lt;dbl&gt;, trust_politicians &lt;dbl&gt;, ## # ethical_concerns &lt;dbl&gt; To create a sum index instead, set type = \"sum\": WoJ %&gt;% add_index(ethical_flexibility, ethics_1, ethics_2, ethics_3, ethics_4, type = &quot;sum&quot;) ## # A tibble: 1,200 × 16 ## country reach employment temp_contract autonomy_selection autonomy_emphasis ## * &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Germany Nati… Full-time Permanent 5 4 ## 2 Germany Nati… Full-time Permanent 3 4 ## 3 Switzerl… Regi… Full-time Permanent 4 4 ## 4 Switzerl… Local Part-time Permanent 4 5 ## 5 Austria Nati… Part-time Permanent 4 4 ## 6 Switzerl… Local Freelancer &lt;NA&gt; 4 4 ## 7 Germany Local Full-time Permanent 4 4 ## 8 Denmark Nati… Full-time Permanent 3 3 ## 9 Switzerl… Local Full-time Permanent 5 5 ## 10 Denmark Nati… Full-time Permanent 2 4 ## # ℹ 1,190 more rows ## # ℹ 10 more variables: ethics_1 &lt;dbl&gt;, ethics_2 &lt;dbl&gt;, ethics_3 &lt;dbl&gt;, ## # ethics_4 &lt;dbl&gt;, work_experience &lt;dbl&gt;, trust_parliament &lt;dbl&gt;, ## # trust_government &lt;dbl&gt;, trust_parties &lt;dbl&gt;, trust_politicians &lt;dbl&gt;, ## # ethical_flexibility &lt;dbl&gt; Make sure to save your index back into your original data set if you want to keep it for later use: WoJ &lt;- WoJ %&gt;% add_index(ethical_concerns, ethics_1, ethics_2, ethics_3, ethics_4) 8.3.1.2 7.3.1.2 get_reliability() The get_reliability() function computes reliability/internal consistency estimates for indices created with add_index(). The function outputs Cronbach’s α along with descriptives and index information. WoJ %&gt;% get_reliability(ethical_concerns) ## # A tibble: 1 × 5 ## Index Index_of M SD Cronbachs_Alpha ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ethical_concerns ethics_1, ethics_2, ethics_3, et… 2.45 0.777 0.612 By default, if you pass no further arguments to the function, it will automatically compute reliability estimates for all indices created with add_index() found in the data. WoJ %&gt;% get_reliability() ## # A tibble: 1 × 5 ## Index Index_of M SD Cronbachs_Alpha ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ethical_concerns ethics_1, ethics_2, ethics_3, et… 2.45 0.777 0.612 8.3.2 Univariate analysis Univariate, descriptive analysis is usually the first step in data exploration. Tidycomm offers four basic functions to quickly output relevant statistics: describe(): For continuous variables tab_percentiles(): For continuous variables describe_cat(): For categorical variables tab_frequencies(): For categorical variables 8.3.2.1 Describe continuous variables There are two options two describe continuous variables in tidycomm: describe() and tab_percentiles() First, the describe() function outputs several measures of central tendency and variability for all variables named in the function call (i.e., mean, standard deviation, min, max, range, and quartiles). Here’s how you use it: WoJ %&gt;% describe(autonomy_emphasis, ethics_1, work_experience) ## # A tibble: 3 × 15 ## Variable N Missing M SD Min Q25 Mdn Q75 Max Range ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonomy_empha… 1195 5 4.08 0.793 1 4 4 5 5 4 ## 2 ethics_1 1200 0 1.63 0.892 1 1 1 2 5 4 ## 3 work_experience 1187 13 17.8 10.9 1 8 17 25 53 52 ## # ℹ 4 more variables: CI_95_LL &lt;dbl&gt;, CI_95_UL &lt;dbl&gt;, Skewness &lt;dbl&gt;, ## # Kurtosis &lt;dbl&gt; If no variables are passed to describe(), all numeric variables in the data are described: WoJ %&gt;% describe() ## # A tibble: 12 × 15 ## Variable N Missing M SD Min Q25 Mdn Q75 Max Range ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonomy_sele… 1197 3 3.88 0.803 1 4 4 4 5 4 ## 2 autonomy_emph… 1195 5 4.08 0.793 1 4 4 5 5 4 ## 3 ethics_1 1200 0 1.63 0.892 1 1 1 2 5 4 ## 4 ethics_2 1200 0 3.21 1.26 1 2 4 4 5 4 ## 5 ethics_3 1200 0 2.39 1.13 1 2 2 3 5 4 ## 6 ethics_4 1200 0 2.58 1.25 1 1.75 2 4 5 4 ## 7 work_experien… 1187 13 17.8 10.9 1 8 17 25 53 52 ## 8 trust_parliam… 1200 0 3.05 0.811 1 3 3 4 5 4 ## 9 trust_governm… 1200 0 2.82 0.854 1 2 3 3 5 4 ## 10 trust_parties 1200 0 2.42 0.736 1 2 2 3 4 3 ## 11 trust_politic… 1200 0 2.52 0.712 1 2 3 3 4 3 ## 12 ethical_conce… 1200 0 2.45 0.777 1 2 2.5 3 5 4 ## # ℹ 4 more variables: CI_95_LL &lt;dbl&gt;, CI_95_UL &lt;dbl&gt;, Skewness &lt;dbl&gt;, ## # Kurtosis &lt;dbl&gt; You can also group data (using dplyr) before describing: WoJ %&gt;% dplyr::group_by(country) %&gt;% describe(autonomy_emphasis) ## # A tibble: 5 × 16 ## # Groups: country [5] ## country Variable N Missing M SD Min Q25 Mdn Q75 Max Range ## * &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Austria autonom… 205 2 4.19 0.614 2 4 4 5 5 3 ## 2 Denmark autonom… 375 1 3.90 0.856 1 4 4 4 5 4 ## 3 Germany autonom… 172 1 4.34 0.818 1 4 5 5 5 4 ## 4 Switze… autonom… 233 0 4.07 0.694 1 4 4 4 5 4 ## 5 UK autonom… 210 1 4.08 0.838 2 4 4 5 5 3 ## # ℹ 4 more variables: CI_95_LL &lt;dbl&gt;, CI_95_UL &lt;dbl&gt;, Skewness &lt;dbl&gt;, ## # Kurtosis &lt;dbl&gt; Finally, you can create visualizations of your variables by applying the visualize() function to your data: WoJ %&gt;% describe(autonomy_emphasis) %&gt;% visualize() Second, the tab_percentiles function tabulates percentiles for at least one continuous variable: WoJ %&gt;% tab_percentiles(autonomy_emphasis) ## # A tibble: 1 × 11 ## Variable p10 p20 p30 p40 p50 p60 p70 p80 p90 p100 ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonomy_emphasis 3 4 4 4 4 4 4 5 5 5 You can use it to tabulate percentiles for more than one variable: WoJ %&gt;% tab_percentiles(autonomy_emphasis, ethics_1) ## # A tibble: 2 × 11 ## Variable p10 p20 p30 p40 p50 p60 p70 p80 p90 p100 ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonomy_emphasis 3 4 4 4 4 4 4 5 5 5 ## 2 ethics_1 1 1 1 1 1 2 2 2 3 5 You can also specify your own percentiles: WoJ %&gt;% tab_percentiles(autonomy_emphasis, ethics_1, levels = c(0.16, 0.50, 0.84, 1.0)) ## # A tibble: 2 × 5 ## Variable p16 p50 p84 p100 ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonomy_emphasis 3 4 5 5 ## 2 ethics_1 1 1 2 5 And you can visualize your percentiles: WoJ %&gt;% tab_percentiles(autonomy_emphasis) %&gt;% visualize() 8.3.3 Bivariate analysis You can perform a descriptive, bivariate analysis using the crosstab() function. The crosstab() function computes contingency tables for one independent (column) variable and one or more dependent (row) variables. WoJ %&gt;% crosstab(reach, employment) ## # A tibble: 3 × 5 ## employment Local Regional National Transnational ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Freelancer 23 36 104 9 ## 2 Full-time 111 287 438 66 ## 3 Part-time 15 32 75 4 You can also add a ‘Total’ column to the contingency table and output column-wise percentages instead of absolute values by using additional arguments: WoJ %&gt;% crosstab(reach, employment, add_total = TRUE, percentages = TRUE ) ## # A tibble: 3 × 6 ## employment Local Regional National Transnational Total ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Freelancer 0.154 0.101 0.169 0.114 0.143 ## 2 Full-time 0.745 0.808 0.710 0.835 0.752 ## 3 Part-time 0.101 0.0901 0.122 0.0506 0.105 Finally, you can visualize your variables using the visualize() function: WoJ %&gt;% crosstab(reach, employment, chi_square = TRUE) %&gt;% visualize() 8.4 How to run significance tests 8.4.1 crosstab() The ‘crosstab()’ function also offers a chi_square argument that, when set to TRUE, will calculate the chi-square test and Cramer’s V. WoJ %&gt;% crosstab(reach, employment, chi_square = TRUE) ## # A tibble: 3 × 5 ## employment Local Regional National Transnational ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Freelancer 23 36 104 9 ## 2 Full-time 111 287 438 66 ## 3 Part-time 15 32 75 4 ## # Chi-square = 16.005, df = 6, p = 0.014, V = 0.082 Remember that you can access the full documentation of this function using the help() function, which will give you access to additional arguments / parameters and run examples of the function: WoJ %&gt;% crosstab(reach, employment, chi_square = TRUE) ## # A tibble: 3 × 5 ## employment Local Regional National Transnational ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Freelancer 23 36 104 9 ## 2 Full-time 111 287 438 66 ## 3 Part-time 15 32 75 4 ## # Chi-square = 16.005, df = 6, p = 0.014, V = 0.082 8.4.2 t_test() The t_test() function is used either to calculate a one-sample t-test or to compute t-tests for one group variable and specified test variables. If no variables are specified, all numeric (integer or double) variables are used. t_test() by default tests for equal variance (using a Levene test) to decide whether to use pooled variance or to use the Welch approximation to the degrees of freedom. You can provide an independent (group) variable and a dependent variable and the t-values, p-values and Cohen’s d will be calculated. WoJ %&gt;% t_test(temp_contract, autonomy_emphasis) ## # A tibble: 1 × 12 ## Variable M_Permanent SD_Permanent M_Temporary SD_Temporary Delta_M t df ## * &lt;chr&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.&gt; &lt;num&gt; &lt;dbl&gt; ## 1 autonom… 4.124 0.768 3.887 0.870 0.237 2.171 995 ## # ℹ 4 more variables: p &lt;num:.3!&gt;, d &lt;num:.3!&gt;, Levene_p &lt;dbl&gt;, var_equal &lt;chr&gt; Remember that you can always save your analysis into an R object and inspect it with View(). This is very helpful if the resulting output is larger than your screen: model1 &lt;- WoJ %&gt;% t_test(temp_contract, autonomy_emphasis) View(model1) You can also specify more than one dependent variable: WoJ %&gt;% t_test(temp_contract, autonomy_emphasis, ethics_1) ## # A tibble: 2 × 12 ## Variable M_Permanent SD_Permanent M_Temporary SD_Temporary Delta_M t ## * &lt;chr&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.&gt; &lt;num:&gt; ## 1 autonomy_emp… 4.124 0.768 3.887 0.870 0.237 2.171 ## 2 ethics_1 1.568 0.850 1.981 0.990 -0.414 -3.415 ## # ℹ 5 more variables: df &lt;dbl&gt;, p &lt;num:.3!&gt;, d &lt;num:.3!&gt;, Levene_p &lt;dbl&gt;, ## # var_equal &lt;chr&gt; If you do not specify a dependent variable, all suitable variables in your data set will be used: WoJ %&gt;% t_test(temp_contract) ## # A tibble: 12 × 12 ## Variable M_Permanent SD_Permanent M_Temporary SD_Temporary Delta_M t ## * &lt;chr&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.&gt; &lt;num:&gt; ## 1 autonomy_se… 3.910 0.755 3.698 0.932 0.212 1.627 ## 2 autonomy_em… 4.124 0.768 3.887 0.870 0.237 2.171 ## 3 ethics_1 1.568 0.850 1.981 0.990 -0.414 -3.415 ## 4 ethics_2 3.241 1.263 3.509 1.234 -0.269 -1.510 ## 5 ethics_3 2.369 1.121 2.283 0.928 0.086 0.549 ## 6 ethics_4 2.534 1.239 2.566 1.217 -0.032 -0.185 ## 7 work_experi… 17.707 10.540 11.283 11.821 6.424 4.288 ## 8 trust_parli… 3.073 0.797 3.019 0.772 0.054 0.480 ## 9 trust_gover… 2.870 0.847 2.642 0.811 0.229 1.918 ## 10 trust_parti… 2.430 0.724 2.358 0.736 0.072 0.703 ## 11 trust_polit… 2.533 0.707 2.396 0.689 0.136 1.369 ## 12 ethical_con… 2.428 0.772 2.585 0.774 -0.157 -1.443 ## # ℹ 5 more variables: df &lt;dbl&gt;, p &lt;num:.3!&gt;, d &lt;num:.3!&gt;, Levene_p &lt;dbl&gt;, ## # var_equal &lt;chr&gt; If you have an independent (group) variable with more than two levels, you can also specify the levels that you want to use for your t_test(): WoJ %&gt;% t_test(employment, autonomy_emphasis, levels = c(&quot;Full-time&quot;, &quot;Freelancer&quot;)) ## # A tibble: 1 × 12 ## Variable `M_Full-time` `SD_Full-time` M_Freelancer SD_Freelancer Delta_M t ## * &lt;chr&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.&gt; &lt;num&gt; ## 1 autonom… 4.118 0.781 3.901 0.852 0.217 3.287 ## # ℹ 5 more variables: df &lt;dbl&gt;, p &lt;num:.3!&gt;, d &lt;num:.3!&gt;, Levene_p &lt;dbl&gt;, ## # var_equal &lt;chr&gt; Finally, t_test() by default tests for equal variance (using a Levene test) to decide whether to use pooled variance or to use the Welch approximation to the degrees of freedom. This is an example for the use of Welch’s approximation to account for unequal variances between groups: WoJ %&gt;% t_test(temp_contract, autonomy_selection) ## # A tibble: 1 × 12 ## Variable M_Permanent SD_Permanent M_Temporary SD_Temporary Delta_M t df ## * &lt;chr&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;num:.&gt; &lt;num&gt; &lt;dbl&gt; ## 1 autonom… 3.910 0.755 3.698 0.932 0.212 1.627 56 ## # ℹ 4 more variables: p &lt;num:.3!&gt;, d &lt;num:.3!&gt;, Levene_p &lt;dbl&gt;, var_equal &lt;chr&gt; You can also run a one-sample t-test (also called: location test) by providing a variable and checking whether the mean of this variable is equal to a provided population mean mu: WoJ %&gt;% t_test(autonomy_selection, mu = 3) ## # A tibble: 1 × 9 ## Variable M SD CI_95_LL CI_95_UL Mu t df p ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonomy_selection 3.88 0.803 3.83 3.92 3 37.7 1196 6.32e-206 Finally, you can visualize your test results by calling the visualize() function: WoJ %&gt;% t_test(temp_contract, autonomy_selection) %&gt;% visualize() To access the full documentation / help: ?t_test() 8.4.3 unianova() The unianova() function is used to compute one-way ANOVAs for one group variable and specified test variables. If no variables are specified, all numeric (integer or double) variables are used. Additionally, unianova() also conducts a Levene test just like the t_test() function to check the assumption of equal variances. If the data doesn’t meet this assumption, the function will switch to using Welch’s test. For PostHoc tests, Tukey’s HSD is the default choice. However, if the assumption of equal variances isn’t met, the function will instead automatically use the Games-Howell test. unianova works similarly to t_test(), i.e., you specify an independent (group) variable followed by one or more dependent variables. WoJ %&gt;% unianova(employment, autonomy_emphasis) ## # A tibble: 1 × 8 ## Variable F df_num df_denom p eta_squared Levene_p var_equal ## * &lt;chr&gt; &lt;num:.&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;num&gt; &lt;num:.3!&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 autonomy_emphasis 5.861 2 1192 0.003 0.010 0.175 TRUE Provide only an independent variable to use all suitable variables in your data set as dependent variables: WoJ %&gt;% unianova(employment) ## # A tibble: 12 × 9 ## Variable F df_num df_denom p omega_squared eta_squared Levene_p ## * &lt;chr&gt; &lt;num:&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;num&gt; &lt;num:.3!&gt; &lt;num:.3!&gt; &lt;dbl&gt; ## 1 autonomy_sel… 2.012 2 251 0.136 0.002 NA 0 ## 2 autonomy_emp… 5.861 2 1192 0.003 NA 0.010 0.175 ## 3 ethics_1 2.171 2 1197 0.115 NA 0.004 0.093 ## 4 ethics_2 2.204 2 1197 0.111 NA 0.004 0.802 ## 5 ethics_3 5.823 2 253 0.003 0.007 NA 0.001 ## 6 ethics_4 3.453 2 1197 0.032 NA 0.006 0.059 ## 7 work_experie… 3.739 2 240 0.025 0.006 NA 0.034 ## 8 trust_parlia… 1.527 2 1197 0.218 NA 0.003 0.103 ## 9 trust_govern… 12.864 2 1197 0.000 NA 0.021 0.083 ## 10 trust_parties 0.842 2 1197 0.431 NA 0.001 0.64 ## 11 trust_politi… 0.328 2 1197 0.721 NA 0.001 0.58 ## 12 ethical_conc… 2.408 2 1197 0.090 NA 0.004 0.206 ## # ℹ 1 more variable: var_equal &lt;chr&gt; You can obtain the descriptives (mean and standard deviation for all group levels) by providing the additional argument descriptives = TRUE. WoJ %&gt;% unianova(employment, autonomy_emphasis, descriptives = TRUE) ## # A tibble: 1 × 14 ## Variable F df_num df_denom p eta_squared `M_Full-time` `SD_Full-time` ## * &lt;chr&gt; &lt;num&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;num&gt; &lt;num:.3!&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonomy… 5.861 2 1192 0.003 0.010 4.12 0.781 ## # ℹ 6 more variables: `M_Part-time` &lt;dbl&gt;, `SD_Part-time` &lt;dbl&gt;, ## # M_Freelancer &lt;dbl&gt;, SD_Freelancer &lt;dbl&gt;, Levene_p &lt;dbl&gt;, var_equal &lt;chr&gt; Similarly, you can retrieve PostHoc tests by providing the additional argument post_hoc = TRUE (default: Tukey’s HSD, otehrwise: Games-Howell). Please note that the post-hoc test results are best inspected by saving your analysis in a separate model and then using View(). Once View() has opened your model, you can navigate to the rightmost part and click on the 1 variable cell under the post hoc column. This will display your post hoc test results. WoJ %&gt;% unianova(employment, autonomy_emphasis, post_hoc = TRUE) ## # A tibble: 1 × 9 ## Variable F df_num df_denom p eta_squared post_hoc Levene_p var_equal ## * &lt;chr&gt; &lt;num&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;num&gt; &lt;num:.3!&gt; &lt;list&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 autonomy_… 5.861 2 1192 0.003 0.010 &lt;df&gt; 0.175 TRUE # model2 &lt;- WoJ %&gt;% unianova(employment, autonomy_emphasis, post_hoc = TRUE) # View(model2) Alternatively, you can extract the PostHoc test results with this code: WoJ %&gt;% unianova(employment, autonomy_selection, post_hoc = TRUE) %&gt;% dplyr::select(Variable, post_hoc) %&gt;% tidyr::unnest(post_hoc) ## # A tibble: 3 × 11 ## Variable Group_Var contrast Delta_M conf_lower conf_upper p d se ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonom… employme… Full-ti… -0.0780 -0.225 0.0688 0.422 -0.110 0.0440 ## 2 autonom… employme… Full-ti… -0.139 -0.329 0.0512 0.199 -0.155 0.0569 ## 3 autonom… employme… Part-ti… -0.0607 -0.284 0.163 0.798 -0.0729 0.0670 ## # ℹ 2 more variables: t &lt;dbl&gt;, df &lt;dbl&gt; If the variances are not equal, a Welch test and a Games-Howell test will be performed automatically, replacing the classic ANOVA method: WoJ %&gt;% unianova(employment, autonomy_selection, descriptives = TRUE) ## # A tibble: 1 × 14 ## Variable F df_num df_denom p omega_squared `M_Full-time` ## * &lt;chr&gt; &lt;num:.3!&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;num&gt; &lt;num:.3!&gt; &lt;dbl&gt; ## 1 autonomy_selection 2.012 2 251 0.136 0.002 3.90 ## # ℹ 7 more variables: `SD_Full-time` &lt;dbl&gt;, `M_Part-time` &lt;dbl&gt;, ## # `SD_Part-time` &lt;dbl&gt;, M_Freelancer &lt;dbl&gt;, SD_Freelancer &lt;dbl&gt;, ## # Levene_p &lt;dbl&gt;, var_equal &lt;chr&gt; WoJ %&gt;% unianova(employment, autonomy_selection, post_hoc = TRUE) %&gt;% dplyr::select(Variable, post_hoc) %&gt;% tidyr::unnest(post_hoc) ## # A tibble: 3 × 11 ## Variable Group_Var contrast Delta_M conf_lower conf_upper p d se ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonom… employme… Full-ti… -0.0780 -0.225 0.0688 0.422 -0.110 0.0440 ## 2 autonom… employme… Full-ti… -0.139 -0.329 0.0512 0.199 -0.155 0.0569 ## 3 autonom… employme… Part-ti… -0.0607 -0.284 0.163 0.798 -0.0729 0.0670 ## # ℹ 2 more variables: t &lt;dbl&gt;, df &lt;dbl&gt; Finally, you can visualize your test results by calling the visualize() function: WoJ %&gt;% unianova(employment, autonomy_emphasis) %&gt;% visualize() For full documentation / help: ?unianova() 8.4.4 correlate() The correlate() function computes correlation coefficients for all combinations of the specified variables. If no variables are specified, all numeric (integer or double) variables are used. WoJ %&gt;% correlate(ethics_1, autonomy_selection) ## # A tibble: 1 × 5 ## x y r df p ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 ethics_1 autonomy_selection -0.0766 1195 0.00798 Once again, you can specify more than two variables: WoJ %&gt;% correlate(ethics_1, autonomy_selection, work_experience) ## # A tibble: 3 × 5 ## x y r df p ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 ethics_1 autonomy_selection -0.0766 1195 0.00798 ## 2 ethics_1 work_experience -0.103 1185 0.000387 ## 3 autonomy_selection work_experience 0.161 1182 0.0000000271 Three variables? That screams “partial correlation” to me! If you’d like to calculate the partial correlation coefficient of three variables, just add the optional parameter partial = TRUE. WoJ %&gt;% correlate(ethics_1, autonomy_selection, work_experience, partial = TRUE) ## # A tibble: 3 × 6 ## x y z r df p ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ethics_1 autonomy_selection work_experience -0.0619 1181 3.32e-2 ## 2 ethics_1 work_experience autonomy_selection -0.0924 1181 1.46e-3 ## 3 work_experience autonomy_selection ethics_1 0.154 1181 1.03e-7 And you can get the correlation for all suitable variables in your data set: WoJ %&gt;% correlate() ## # A tibble: 66 × 5 ## x y r df p ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 autonomy_selection autonomy_emphasis 0.644 1192 4.83e-141 ## 2 autonomy_selection ethics_1 -0.0766 1195 7.98e- 3 ## 3 autonomy_selection ethics_2 -0.0274 1195 3.43e- 1 ## 4 autonomy_selection ethics_3 -0.0257 1195 3.73e- 1 ## 5 autonomy_selection ethics_4 -0.0781 1195 6.89e- 3 ## 6 autonomy_selection work_experience 0.161 1182 2.71e- 8 ## 7 autonomy_selection trust_parliament -0.00840 1195 7.72e- 1 ## 8 autonomy_selection trust_government 0.0414 1195 1.53e- 1 ## 9 autonomy_selection trust_parties 0.0269 1195 3.52e- 1 ## 10 autonomy_selection trust_politicians 0.0109 1195 7.07e- 1 ## # ℹ 56 more rows You might want to turn these correlations into an advanced correlation matrix, just like you find them in SPSS. You can do that using an additional function to_correlation_matrix after your correlate() function: WoJ %&gt;% correlate() %&gt;% to_correlation_matrix() ## # A tibble: 12 × 13 ## r autonomy_selection autonomy_emphasis ethics_1 ethics_2 ethics_3 ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autonomy_sel… 1 0.644 -0.0766 -0.0274 -0.0257 ## 2 autonomy_emp… 0.644 1 -0.114 -0.0337 -0.0297 ## 3 ethics_1 -0.0766 -0.114 1 0.172 0.165 ## 4 ethics_2 -0.0274 -0.0337 0.172 1 0.409 ## 5 ethics_3 -0.0257 -0.0297 0.165 0.409 1 ## 6 ethics_4 -0.0781 -0.127 0.343 0.321 0.273 ## 7 work_experie… 0.161 0.155 -0.103 -0.168 -0.0442 ## 8 trust_parlia… -0.00840 -0.00465 -0.0378 0.00161 -0.0486 ## 9 trust_govern… 0.0414 0.0268 -0.102 0.0374 -0.0743 ## 10 trust_parties 0.0269 0.0102 -0.0472 0.0238 -0.0115 ## 11 trust_politi… 0.0109 0.00242 -0.00725 0.0250 -0.0212 ## 12 ethical_conc… -0.0738 -0.108 0.555 0.734 0.687 ## # ℹ 7 more variables: ethics_4 &lt;dbl&gt;, work_experience &lt;dbl&gt;, ## # trust_parliament &lt;dbl&gt;, trust_government &lt;dbl&gt;, trust_parties &lt;dbl&gt;, ## # trust_politicians &lt;dbl&gt;, ethical_concerns &lt;dbl&gt; Of course, you can change the correlation method: Using Pearson’s r (default): WoJ %&gt;% correlate(ethics_1, autonomy_selection, method = &quot;pearson&quot;) ## # A tibble: 1 × 5 ## x y r df p ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 ethics_1 autonomy_selection -0.0766 1195 0.00798 Using Spearman’s rho: WoJ %&gt;% correlate(ethics_1, autonomy_selection, method = &quot;spearman&quot;) ## # A tibble: 1 × 5 ## x y rho df p ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; ## 1 ethics_1 autonomy_selection -0.0716 NA 0.0132 Using Kendall’s tau: WoJ %&gt;% correlate(ethics_1, autonomy_selection, method = &quot;kendall&quot;) ## # A tibble: 1 × 5 ## x y tau df p ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; ## 1 ethics_1 autonomy_selection -0.0646 NA 0.0130 Finally, you can visualize your test results by calling the visualize() function. Based on your input variables and whether you want to visualize a partial correlation, the choice of graph might vary: Visualize a bivariate correlation: WoJ %&gt;% correlate(ethics_1, autonomy_selection) %&gt;% visualize() # Pro tip: use parameters which = jitter and which = alpha to change layout of the geom_points Visualize with multiple variables: WoJ %&gt;% correlate(ethics_1, autonomy_selection, work_experience) %&gt;% visualize() Visualize a partial correlation: WoJ %&gt;% correlate(ethics_1, autonomy_selection, work_experience, partial = TRUE) %&gt;% visualize() Of course, you can always get help: ?correlate() 8.4.5 regress() Finally, you can also run linear regressions. The regress() function will compute a linear regression for all independent variables on the specified dependent variable. WoJ %&gt;% regress(ethics_1, autonomy_selection, work_experience) ## # A tibble: 3 × 6 ## Variable B StdErr beta t p ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 2.03 0.129 NA 15.8 5.32e-51 ## 2 autonomy_selection -0.0692 0.0325 -0.0624 -2.13 3.32e- 2 ## 3 work_experience -0.00762 0.00239 -0.0934 -3.19 1.46e- 3 ## # F(2, 1181) = 8.677001, p = 0.000182, R-square = 0.014482 You can also perform a linear modeling of multiple independent variables (this will use stepwise regression modeling): WoJ %&gt;% regress(ethics_1, autonomy_selection, work_experience) ## # A tibble: 3 × 6 ## Variable B StdErr beta t p ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 2.03 0.129 NA 15.8 5.32e-51 ## 2 autonomy_selection -0.0692 0.0325 -0.0624 -2.13 3.32e- 2 ## 3 work_experience -0.00762 0.00239 -0.0934 -3.19 1.46e- 3 ## # F(2, 1181) = 8.677001, p = 0.000182, R-square = 0.014482 You can even check the preconditions of a linear regression (e.g., multicollinearity and homoscedasticity) by providing optional arguments / parameters: WoJ %&gt;% regress(ethics_1, autonomy_selection, work_experience, check_independenterrors = TRUE, check_multicollinearity = TRUE, check_homoscedasticity = TRUE ) ## # A tibble: 3 × 8 ## Variable B StdErr beta t p VIF tolerance ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 2.03 0.129 NA 15.8 5.32e-51 NA NA ## 2 autonomy_selection -0.0692 0.0325 -0.0624 -2.13 3.32e- 2 1.03 0.974 ## 3 work_experience -0.00762 0.00239 -0.0934 -3.19 1.46e- 3 1.03 0.974 ## # F(2, 1181) = 8.677001, p = 0.000182, R-square = 0.014482 ## - Check for independent errors: Durbin-Watson = 2.037690 (p = 0.540000) ## - Check for homoscedasticity: Breusch-Pagan = 6.966472 (p = 0.008305) ## - Check for multicollinearity: VIF/tolerance added to output Or you can make visual inspections to check the preconditions using several different visualizations: Base visualization: WoJ %&gt;% regress(ethics_1, autonomy_selection, work_experience) %&gt;% visualize() # Pro tip: use parameters which = jitter and which = alpha to change layout of the geom_points Correlograms among independent variables: WoJ %&gt;% regress(ethics_1, autonomy_selection, work_experience) %&gt;% visualize(which = &quot;correlogram&quot;) Residuals-versus-fitted plot to determine distributions: WoJ %&gt;% regress(ethics_1, autonomy_selection, work_experience) %&gt;% visualize(which = &quot;resfit&quot;) Normal probability-probability plot to check for multicollinearity: WoJ %&gt;% regress(ethics_1, autonomy_selection, work_experience) %&gt;% visualize(which = &quot;pp&quot;) Scale-location (sometimes also called spread-location) plot to check whether residuals are spread equally (to help check for homoscedasticity): WoJ %&gt;% regress(ethics_1, autonomy_selection, work_experience) %&gt;% visualize(which = &quot;scaloc&quot;) Residuals-versus-leverage plot to check for influential outliers affecting the final model more than the rest of the data: WoJ %&gt;% regress(ethics_1, autonomy_selection, work_experience) %&gt;% visualize(which = &quot;reslev&quot;) Again, you can always get help: ?regress() We are done with our tutorial about data analysis! Let’s have a final exercise to repeat what we’ve learned: Exercise 6: dplyr, ggplot, tidycomm. "],["exercise-6-dplyr-ggplot-tidycomm.html", "Exercise 6: dplyr, ggplot, tidycomm Task 1 Task 2 Task 3 Task 4 Task 5 Task 6 Task 7 Task 8", " Exercise 6: dplyr, ggplot, tidycomm After working through Exercise 6, you’ll… have repeated the most important functions of dplyr and ggplot2 In this exercise, we will work with the mtcars data that comes pre-installed with dplyr. library(tidyverse) data &lt;- mtcars # To make the data somewhat more interesting, let&#39;s set a few values to missing values (you don&#39;t need to know this code): data$wt &lt;- na_if(data$wt, 4.070) data$mpg &lt;- na_if(data$mpg, 22.8) Let’s first get to know this data. We can get some information about the variables that are included in the dataset by using Rs help() function: help(mtcars) Image: Output of the help(mtcars) function: We get to know that this is a data set was created from the 1974 Motor Trend US magazine, and that it comprises fuel consumption (mpg) and 10 other aspects (cyl, wt) of automobile design and performance for 32 different cars. Task 1 Check the dataset for missing values (NAs) and delete all observations that have missing values. Task 2 Let’s transform the weight wt of the cars. Currently, it’s given as Weight in 1000 lbs. I guess you are not used to lbs, so try to mutate wt to represent Weight in 1000 kg. 1000 lbs = 453.59 kg, so we will need to divide by 2.20. Similarly, I think that you are not very familiar with the unit Miles per gallon of the mpg variable. Let’s transform it into Kilometer per liter. 1 m/g = 0.425144 km/l, so again divide by 2.20. Task 3 Now we want to group the weight of the cars in three categories: light, medium, heavy. But how to define light, medium, and heavy cars, i.e., at what kg should you put the threshold? A reasonable approach is to use quantiles (see Tutorial: summarize() [+ group_by()]). Quantiles divide data. For example, the 75% quantile states that exactly 75% of the data values are equal or below the quantile value. The rest of the values are equal or above it. Use the lower quantile (0.25) and the upper quantile (0.75) to estimate two values that divide the weight of the cars in three groups. What are these values? Task 4 Use the values from Task 3 to create a new variable wt_cat that divides the cars in three groups: light, medium, and heavy cars. Task 5 How many light, medium, and heavy cars are part of the data? Task 6 Now sort this count of the car weight classes from highest to lowest. Task 7 Make a scatter plot to indicate how many km per liter (mpg) a car can drive depending on its weight (wt). Facet the plot by weight class (wt_cat). Try to hide the plot legend (you have learned that in Exercise 3, Task 1). Task 8 Recreate the diagram from Task 7, but exclude all cars that weigh between 1.4613636 and 1.5636364 *1000kg from it. When you’re ready to look at the solutions, you can find them here: Solutions for Exercise 6. We have officially finished our chapters on data management and visualization! "],["tutorial-introduction-to-r-markdown.html", " 9 Tutorial: Introduction to R Markdown", " 9 Tutorial: Introduction to R Markdown R Markdown is a powerful tool for scientists that allows you to intermingle code and text in a single document. It’s a versatile R package that combines the core syntax of markdown (an easy-to-write plain text format) with embedded R code chunks, enabling the creation of dynamic documents, presentations, dashboards, and even entire books (R Markdown supports a variety of output formats, including HTML, PDF, Microsoft Word and MANY more!). Developed by Yihui Xie in 2012, and actively maintained by the RStudio team, R Markdown was designed to provide a seamless workflow for both data analysis and reporting. One of the key features of R Markdown is its ability to execute R code chunks in the document and automatically capture the output and include it in the final document. This can include results of computations, tables, and even graphics generated by the R code. R Markdown documents are completely reproducible and can be automatically regenerated whenever the underlying data or analysis code changes. Creating an R Markdown document is an interactive process that combines elements of coding, data analysis, and scientific writing. Let’s get started. 9.0.1 Packages Firstly, you’ll need to install the rmarkdown package and its dependencies, including knitr for executing code chunks. You can do this from within R or RStudio: install.packages(&quot;rmarkdown&quot;) install.packages(&quot;knitr&quot;) library(rmarkdown) 9.0.2 Creating a new R Markdown file You can create a new R Markdown file in RStudio by clicking on File &gt; New File &gt; R Markdown... This will open a dialog box where you can give the document a title and author, and choose the output format (HTML, PDF, or Word). 9.0.3 Structure of R Markdown documents An R Markdown document consists of YAML metadata, markdown text, and R code chunks. YAML Metadata: This is the section at the top of the document, enclosed in —. It contains information like the title, author, date, and output format of the document. Markdown Text: Markdown is a simple formatting syntax that allows you to include things like headers, links, italics, bullet lists, images, etc., in plain text. R Code Chunks: You can insert R code into your document by enclosing it in {r} and. This code chunk would be executed when the document is rendered, and the description of the WoJ dataset would be included in the final document. 9.0.4 Rendering the document To convert your R Markdown document into a final, shareable format, you need to ‘render’ it. You can do this in RStudio by clicking the ‘Knit’ button. You can also use the render() function from the rmarkdown package: rmarkdown::render(&quot;my_document.Rmd&quot;) This will execute all of the R code chunks, convert the markdown text to formatted text, and combine everything into a final document. 9.0.5 Formatting the document You can format your R Markdown document by using Markdown as a simple formatting syntax. This is the basic syntax: Headers: Use # for a top-level header (H1), ## for H2, up to ###### for H6. The more #s, the smaller the header. Emphasis: For italic text, wrap words in * or _ , like * italic * or _ italic _ . For bold, use double ** or __ , like ** bold ** or __ bold __. Lists: Use *, -, or + followed by a space for bullet points. For numbered items, start the line with the number, a period, and a space. Links: Wrap the clickable text in square brackets [] and the URL in parentheses (), like this but without the space: [Lara Kobike] (homepage_url). Images: Similar to links, but prefix the square bracket with an exclamation point !, like this but without the space: [Alt text] (image_url). Code: Use backticks ` around inline code snippets. For larger blocks of code, use triple backticks. Blockquotes: Start the line with a &gt; to create a blockquote. Footnotes: The footnote number is placed inside the square bracket after a caret: ^[ 4 ]. Then you put the text of the footnote after another caret: ^[ 4 ]: This is how a footnote looks like after rednering.4 Finally, you can use this R Markdown cheat sheet to quickly learn more. Advanced tip: The bookdown package extends the functionality of the rmarkdown package. It can be used to create long and more complicated documents. Here is an introduction to bookdown by Benjamin Fretwurst, which he created for his students in Zurich (including videos): Link.” 9.0.6 Citing papers with Zotero You can integrate Zotero to cite your sources within an R Markdown document. First, you need to download and install Zotero. It’s a free, open-source tool that helps you collect, organize, cite, and share your research sources. After you have Zotero installed, you also need to install an extension called Better BibTeX for Zotero, which simplifies the process of exporting your Zotero libraries in a format that is easy to use with R Markdown. To install Better BibTeX, open Zotero and follow this path: Tools &gt; Add-Ons &gt; Gear Icon &gt; Install Add-On From File…. Then go to the folder you downloaded the Better Bibtex file to. Select the BetterBibtex.xpi file, click “Install Now” in the Zotero pop-up, and follow the system setup. Pro tip: Better BibTeX will create dynamic citation keys from the Zotero paper information, and this key may change when you edit the paper in Zotero. You can generate a pinned (i.e., fixed) citation key by selecting one or more items, right-clicking, and selecting Pin BibTeX key, which will add the current citation key to the “extra” field, thereby pinning it. If you want to update your citation key default style, go to Tools &gt; Better BibTex &gt; Open Better BibTex Preferences and enter your desired citation key style, e.g. “auth.fold.lower + year”. See this screenshot for a visual aid: How to pin BibTex keys in Zotero: Next, you need to connect Zotero with R Markdown. The easiest way that I’ve found is through using the rbbt package (see the author’s blog here). However, it’s not hosted on CRAN, so be careful. This package might not run stable in the future. remotes::install_github(&quot;paleolimbot/rbbt&quot;) After installing rbbt and restarting RStudio, go to Tools &gt; Modify Keyboard Shortcuts. Search for zotero and click on the ‘Shortcut’ field for the ‘Insert Zotero Bibliography from Zotero Selection’ line and type in your desired shortcut keys, e.g. CNTRL + B. See this screenshot for a visual aid: How to modify your Zotero BibTex Shortcuts in RStudio: Alright, now it’s time to open a new R script. Go to File &gt; New File &gt; R Script and open an empty document. Save this document via File &gt; Save As and call it “references.bib”. You will see a warning that this is changing the R script to be a bib file. This warning is great news because that’s exactly what we want. Make sure that your references.bib is placed in the same directory as your R Markdown .Rmd file. Next, switch to Zotero and select all references that you want to cite. For example, use the shortcut CNTRL + A in your Zotero project to select all papers in that project at the same time. Move back to R Markdown and into your “references.bib” file. Go in there and hit your ‘Insert Zotero Bibliography from Zotero Selection’ shortcut (i.e. CNTRL + B). Voilá, you got yourself a bibliography to cite from that you can always easily update using CNTRL + B. Save that updated .bib file. Now, whenever you are in your R Markdown file, you can just type an “@” symbol and RStudio will automatically prompt you with the options from your .bib file. Choose your reference and hit Enter. This will insert the citation key in your R Markdown document, e.g. @smith2023. In the actual output, @smith2023 will be replaced by a properly formatted citation, and a reference list will be automatically generated at the end of your document. For more details on how to use Zotero with R Markdown, including how to specify citation style and how to cite page numbers, see the official guide on using Zotero with R Markdown. This is how a footnote looks like after rendering.]↩︎ "],["tutorial-good-coding-style-project-management.html", " 10 Tutorial: Good coding style &amp; project management 10.1 Naming conventions for variables 10.2 Spacing and operators 10.3 Commenting your code 10.4 Don’t Repeat Yourself: DRY code 10.5 Using tidyverse functions 10.6 File and script organization 10.7 Using R Projects 10.8 Function documentation with Roxygen2 10.9 Automated code styling", " 10 Tutorial: Good coding style &amp; project management After working through Tutorial 10, you’ll… have received some tips about how to organize your R projects know about how to write good code according to the tidyverse principles Writing clean, understandable code is fundamental in programming. It’s not just for the machine to execute, but also for humans to read and comprehend. The Tidyverse style guide by Hadley Wickham offers a set of conventions that can help you achieve this. In this tutorial, we’ll go over some of these guidelines, and we’ll also discuss some packages that can enforce good coding style in R. 10.1 Naming conventions for variables Variable names: Use lowercase and separate words with underscores. Avoid dots in variable names, as they have a special meaning in R. # Good variable_name &lt;- &quot;example&quot; # Bad VariableName &lt;- &quot;example&quot; variable.name &lt;- &quot;example&quot; Long variable names: While it can be tempting to use short, cryptic variable names, it’s often a good idea to use longer, more descriptive names. This makes your code easier to understand and maintain. And you can always copy and paste variable names (and RStudio will provide the full name once you start typing the first letters anyway), so long names are no problem. Here’s a very simple example: # Good average_work_experience &lt;- 10.3 # Bad work_exp &lt;- 10.3 Function names: Use lowercase and separate words with underscores. Use verbs because functions are doing something! # Good calculate_mean &lt;- function(x) { mean(x, na.rm = TRUE) } # Bad calculateMean &lt;- function(x) { mean(x, na.rm = TRUE) } # Bad mean_calculation &lt;- function(x) { mean(x, na.rm = TRUE) } 10.2 Spacing and operators Insert spaces around all binary operators (=, +, -, &lt;, &gt;, etc.). # Good average &lt;- sum(x) / length(x) # Bad average &lt;- sum(x) / length(x) Never place a space before a comma, but always after a comma. # Good average &lt;- mean(x, na.rm = TRUE) # Bad average &lt;- mean(x, na.rm = TRUE) 10.3 Commenting your code Good commenting is a crucial aspect of writing clean, understandable code. Comments should provide clarity and context to your code. Here are some guidelines: Purpose of the code: Every nontrivial function should have a comment explaining what it does. The comment should explain what the function does, not how it does it. Assumptions and constraints: If your code makes certain assumptions (e.g., about the input data such as numbers must be inserted as strings and not as integers) or has certain constraints, it’s good to document them in comments. Do not over-comment: Avoid commenting on obvious things. Good code is self-documenting to some extent. If you’re finding that you need to add a lot of comments to explain what your code is doing, it may be a sign that you need to refactor your code to make it clearer. If you follow all of the above guidelines on how to write clean code, then you won’t need as many comments! Update comments as you update code: There’s nothing more confusing than comments that don’t match the code. If you change your code, make sure to update the relevant comments as well. 10.4 Don’t Repeat Yourself: DRY code The DRY principle is a fundamental concept in software development. You should strive to avoid duplicating code, as it inflates your code and makes it harder to read. If you find yourself writing the same or very similar code in multiple places, consider creating a function, which can then be called from those places. # Bad x &lt;- x - mean(x) y &lt;- y - mean(y) z &lt;- z - mean(z) # Good center &lt;- function(x) { x - mean(x) } x &lt;- center(x) y &lt;- center(y) z &lt;- center(z) 10.5 Using tidyverse functions The pipe operator %&gt;% is a valuable tool for chaining multiple operations. Each step in the chain should be on a new line. Use mutate to add new variables that are functions of existing variables. # Good WoJ %&gt;% mutate(work_experience_in_days = work_experience * 365) # Bad WoJ$work_experience_in_days &lt;- WoJ$work_experience * 365 10.6 File and script organization The organization of files and directories in your project, as well as the naming and organization of scripts, is a critical aspect of good coding practices. Here are some tips to get you started: Consistent project structure: Make sure your project has a consistent structure. project/ │ ├── R/ │ ├── functions.R │ └── main_script.R │ ├── data/ │ ├── raw/ │ └── processed/ │ ├── figures/ │ └── plot.png │ ├── doc/ │ ├── report.Rmd │ └── report.html │ └── project.Rproj Separate raw and processed data: Keep raw and processed data in separate folders. Use meaningful names: Use clear and descriptive names for your files and folders. Enumerate scripts: It’s often a good idea to separate data preparation (loading, cleaning, transforming) and data analysis (statistical analysis, plotting) into separate scripts. If there’s a specific order in which scripts should be run, consider enumerating them in your R/ folder. For example: 01_load_data.R 02_clean_data.R 03_analyze_data.R 04_plot_data.R Function scripts: If you have functions that are used in multiple scripts, consider putting them in their own script, like utilities.R or functions.R, and source this script when you need to use those functions, i.e. source(functions.R). 10.7 Using R Projects R Projects, via RStudio, offer a straightforward way to organize your work. An R Project is simply a working directory designated with a .Rproj file. When you open an R Project, RStudio sets the working directory to the project root directory, which is very helpful for file referencing and reproducibility. To create an R Project in RStudio, go to File -&gt; New Project. You can then choose to create a new directory for your project or to associate the project with an existing directory. After you’ve created your R Project, RStudio will create a .Rproj file in the project directory. This file contains various settings and preferences, which RStudio will restore each time you open the project. Using R Projects brings several benefits: Reproducibility: Since the working directory is set to the project root, you can use relative file paths in your code, which makes it more likely to run on other machines. Organization: Each project is self-contained, making it easier to manage files, variables, packages, and more. Integration with version control systems: RStudio’s Projects integrate well with version control systems like Git, making it easier to track changes, collaborate with others, and sync your work across different machines. Multiple sessions: You can work on multiple projects in separate sessions, each with its own working directory and workspace. Restoring previous work: When you reopen a project, RStudio restores the working directory, the command history, and the previously opened scripts, helping you pick up right where you left off. 10.8 Function documentation with Roxygen2 When you’re writing functions, especially if you’re planning to share your code or use it in the future, it’s important to document what the function does, what inputs it expects, and what it returns. The Roxygen2 package in R makes this easy. # Install the roxygen2 package install.packages(&quot;roxygen2&quot;) Roxygen2 uses specially formatted comments that start with #’ to generate documentation for your functions that is universally known by other R programmers. Here’s an example of how to use roxygen2 to document a function: #&#39; Calculate the mean of a vector #&#39; #&#39; This function calculates the mean of a vector, excluding NA values. #&#39; #&#39; @param x A numeric vector. #&#39; @return The mean of the vector, excluding NA values. #&#39; @examples #&#39; calculate_mean(c(1, 2, 3, NA)) calculate_mean &lt;- function(x) { mean(x, na.rm = TRUE) } 10.9 Automated code styling While adhering to coding style guidelines is crucial, it can sometimes be challenging to manage manually. Thankfully, R has several packages to help with this: 10.9.1 styler The styler package can automatically format your R code to adhere to the tidyverse style guide without changing the code’s behavior. # Install the styler package install.packages(&quot;styler&quot;) # Load the styler package library(styler) # Style a single line of code style_text(&quot;a=1+2&quot;) # Style an entire script style_file(&quot;path/to/your/script.R&quot;) # Style an entire package style_pkg(&quot;path/to/your/package&quot;) 10.9.2 lintr The lintr package provides static code analysis for R, enforcing good coding style. It can be integrated with various text editors, including RStudio. # Install the lintr package install.packages(&quot;lintr&quot;) # Load the lintr package library(lintr) # Lint a single file lint(&quot;path/to/your/script.R&quot;) # Lint an entire package lint_package(&quot;path/to/your/package&quot;) The lint() function returns a list of issues with your code, including stylistic issues, syntax errors, and potential bugs. "],["solutions.html", "Solutions Solutions for Exercise 1 Solutions for Exercise 2 Solutions for Exercise 3 Solutions for Exercise 4 Solutions for Exercise 5 Solutions for Exercise 6", " Solutions This is where you’ll find solutions for all of the tutorials. Solutions for Exercise 1 Task 1 Below you will see multiple choice questions. Please try to identify the correct answers. 1, 2, 3 and 4 correct answers are possible for each question. 1. What panels are part of RStudio? Solution: source (x) console (x) packages, files &amp; plots (x) 2. How do you activate R packages after you have installed them? Solution: library() (x) 3. How do you create a vector in R with elements 1, 2, 3? Solution: c(1,2,3) (x) 4. Imagine you have a vector called ‘vector’ with 10 numeric elements. How do you retrieve the 8th element? Solution: vector[8] (x) 5. Imagine you have a vector called ‘hair’ with 5 elements: brown, black, red, blond, other. How do you retrieve the color ‘blond’? Solution: hair[4] (x) Task 2 Create a numeric vector with 8 values and assign the name age to the vector. First, display all elements of the vector. Then print only the 5th element. After that, display all elements except the 5th. Finally, display the elements at the positions 6 to 8. Solution: age &lt;- c(65, 52, 73, 71, 80, 62, 68, 87) age ## [1] 65 52 73 71 80 62 68 87 age[5] ## [1] 80 age[-5] ## [1] 65 52 73 71 62 68 87 age[6:8] ## [1] 62 68 87 Task 3 Create a non-numeric, i.e. character, vector with 4 elements and assign the name eye_color to the vector. First, print all elements of this vector to the console. Then have only the value in the 2nd element displayed, then all values except the 2nd element. At the end, display the elements at the positions 2 to 4. Solution: eye_color &lt;- c(&quot;blue&quot;, &quot;green&quot;, &quot;brown&quot;, &quot;grey&quot;) eye_color ## [1] &quot;blue&quot; &quot;green&quot; &quot;brown&quot; &quot;grey&quot; eye_color[2] ## [1] &quot;green&quot; eye_color[-2] ## [1] &quot;blue&quot; &quot;brown&quot; &quot;grey&quot; eye_color[2:4] ## [1] &quot;green&quot; &quot;brown&quot; &quot;grey&quot; # Alternatively, you could also use this approach: eye_color[c(2)] ## [1] &quot;green&quot; eye_color[c(-2)] ## [1] &quot;blue&quot; &quot;brown&quot; &quot;grey&quot; eye_color[c(2, 3, 4)] ## [1] &quot;green&quot; &quot;brown&quot; &quot;grey&quot; Solutions for Exercise 2 Task 1 Download the “WoJ_names.csv” from LRZ Sync &amp; Share (click here) and put it into the folder that you want to use as working directory. Set your working directory and load the data into R by saving it into a source object called data. Note: This time, it’s a csv that is separated by semicolons, not by commas. Solution: setwd(&quot;C:/Users/LaraK/Documents/IPR/&quot;) data &lt;- read.csv2(&quot;WoJ_names.csv&quot;, header = TRUE) Task 2 Now, print only the column to the console that shows the trust in government. Use the $ operator first. Then try to achieve the same result using the subsetting operators, i.e. []. Solution: data$trust_government # first version ## [1] 3 4 4 4 2 4 1 3 1 3 2 3 2 2 2 2 3 3 4 3 3 2 3 4 3 3 3 2 3 3 3 3 4 2 3 2 2 2 ## [39] 2 3 data[, 8] # second version ## [1] 3 4 4 4 2 4 1 3 1 3 2 3 2 2 2 2 3 3 4 3 3 2 3 4 3 3 3 2 3 3 3 3 4 2 3 2 2 2 ## [39] 2 3 Task 3 Print only the first 6 trust in government numbers to the console. Use the $ operator first. Then try to achieve the same result using the subsetting operators, i.e. []. Solution: data$trust_government[1:6] # first version ## [1] 3 4 4 4 2 4 data[1:6, 8] # second version ## [1] 3 4 4 4 2 4 Solutions for Exercise 3 Task 1 Below you will see multiple choice questions. Please try to identify the correct answers. 1, 2, 3 and 4 correct answers are possible for each question. 1. What are the main characteristics of tidy data? Solution: Every observation is a row. (x) 2. What are dplyr functions? Solution: mutate() (x) 3. How can you sort the eye_color of Star Wars characters from Z to A? Solution: starwars_data %&gt;% arrange(desc(eye_color)) (x) starwars_data %&gt;% select(eye_color) %&gt;% arrange(desc(eye_color)) 4. Imagine you want to recode the height of the these characters. You want to have three categories from small and medium to tall. What is a valid approach? Solution: starwars_data %&gt;% mutate(height = case_when(height&lt;=150~\"small\",height&lt;=190~\"medium\",height&gt;190~\"tall\")) 5. Imagine you want to provide a systematic overview over all hair colors and what species wear these hair colors frequently (not accounting for the skewed sampling of species)? What is a valid approach? Solution: starwars_data %&gt;% group_by(hair_color, species) %&gt;% summarize(count = n()) %&gt;% arrange(hair_color) Task 2 Now it’s you turn. Load the starwars data like this: library(dplyr) # to activate the dplyr package starwars_data &lt;- starwars # to assign the pre-installed starwars data set (dplyr) into a source object in our environment How many humans are contained in the starwars data overall? (Hint: use summarize(count = n()) or count())? Solution: You can use summarize(count = n()): starwars_data %&gt;% filter(species == &quot;Human&quot;) %&gt;% summarize(count = n()) ## # A tibble: 1 × 1 ## count ## &lt;int&gt; ## 1 35 Alternatively, you can use the count() function: starwars_data %&gt;% filter(species == &quot;Human&quot;) %&gt;% count(species) ## # A tibble: 1 × 2 ## species n ## &lt;chr&gt; &lt;int&gt; ## 1 Human 35 Task 3 How many humans are contained in starwars by gender? Solution: You can use summarize(count = n()): starwars_data %&gt;% filter(species == &quot;Human&quot;) %&gt;% group_by(species, gender) %&gt;% summarize(count = n()) ## # A tibble: 2 × 3 ## # Groups: species [1] ## species gender count ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Human feminine 9 ## 2 Human masculine 26 Alternatively, you can use the count() function: starwars_data %&gt;% filter(species == &quot;Human&quot;) %&gt;% count(species, gender) ## # A tibble: 2 × 3 ## species gender n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Human feminine 9 ## 2 Human masculine 26 Task 4 What is the most common eye_color among Star Wars characters? (Hint: use arrange())__ Solution: starwars_data %&gt;% group_by(eye_color) %&gt;% summarize(count = n()) %&gt;% arrange(desc(count)) ## # A tibble: 15 × 2 ## eye_color count ## &lt;chr&gt; &lt;int&gt; ## 1 brown 21 ## 2 blue 19 ## 3 yellow 11 ## 4 black 10 ## 5 orange 8 ## 6 red 5 ## 7 hazel 3 ## 8 unknown 3 ## 9 blue-gray 1 ## 10 dark 1 ## 11 gold 1 ## 12 green, yellow 1 ## 13 pink 1 ## 14 red, blue 1 ## 15 white 1 Alternatively, you can use the count() function: starwars_data %&gt;% count(eye_color) %&gt;% arrange(desc(n)) ## # A tibble: 15 × 2 ## eye_color n ## &lt;chr&gt; &lt;int&gt; ## 1 brown 21 ## 2 blue 19 ## 3 yellow 11 ## 4 black 10 ## 5 orange 8 ## 6 red 5 ## 7 hazel 3 ## 8 unknown 3 ## 9 blue-gray 1 ## 10 dark 1 ## 11 gold 1 ## 12 green, yellow 1 ## 13 pink 1 ## 14 red, blue 1 ## 15 white 1 Task 5 What is the average mass of Star Wars characters that are not human and have yellow eyes? (Hint: remove all NAs)__ Solution: starwars_data %&gt;% filter(species != &quot;Human&quot; &amp; eye_color == &quot;yellow&quot;) %&gt;% summarize(mean_mass = mean(mass, na.rm = TRUE)) ## # A tibble: 1 × 1 ## mean_mass ## &lt;dbl&gt; ## 1 74.1 Task 6 Compare the mean, median, and standard deviation of mass for all humans and droids. (Hint: remove all NAs)__ Solution: starwars_data %&gt;% filter(species == &quot;Human&quot; | species == &quot;Droid&quot;) %&gt;% group_by(species) %&gt;% summarize( M = mean(mass, na.rm = TRUE), Med = median(mass, na.rm = TRUE), SD = sd(mass, na.rm = TRUE) ) ## # A tibble: 2 × 4 ## species M Med SD ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Droid 69.8 53.5 51.0 ## 2 Human 82.8 79 19.4 Task 7 Create a new variable in which you store the mass in gram. Add it to the data frame. Solution: starwars_data &lt;- starwars_data %&gt;% mutate(gr_mass = mass * 1000) starwars_data %&gt;% select(name, species, mass, gr_mass) ## # A tibble: 87 × 4 ## name species mass gr_mass ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Luke Skywalker Human 77 77000 ## 2 C-3PO Droid 75 75000 ## 3 R2-D2 Droid 32 32000 ## 4 Darth Vader Human 136 136000 ## 5 Leia Organa Human 49 49000 ## 6 Owen Lars Human 120 120000 ## 7 Beru Whitesun lars Human 75 75000 ## 8 R5-D4 Droid 32 32000 ## 9 Biggs Darklighter Human 84 84000 ## 10 Obi-Wan Kenobi Human 77 77000 ## # ℹ 77 more rows Solutions for Exercise 4 Task 1 Show how journalists’ work experience (work_experience) is associated with their trust in politicians (trust_politicians). To do this, create a very basic scatter plot using ggplot2 and the respective ggplot() function. Use the aes() function inside ggplot() to map variables to the visual properties. Use geom_point() to add points to the plot. Solution: Task 2 Do more experienced journalists become less trusting in politicians? Add this code to your plot to create a regression line: + geom_smooth(method = lm, se = FALSE). What can you conclude from the regression line? Solution: The regression line shows us that there is no relationship between work experience and trust in politicians. In other words, more experienced journalists do not become less trusting in politicians. Task 3 Does the relationship between work experience and trust in politicians remain stable across different countries? Alternatively, does work experience influence trust in politicians differently depending on the specific country context? Try to create a visualization to answer this question using facet_wrap(). Solution: Task 4 In your current visualization, it may be challenging to discern cross-country differences. Let’s aim to create a visualization that illustrates these differences across countries more distinctly. Remove the facet_wrap() and the geom_point() code line. This leaves you with this graph: WoJ %&gt;% ggplot(aes(x = work_experience, y = trust_politicians)) + geom_smooth(method = lm, se = FALSE) Now, display every country in a separate color by using the color argument inside the aes() function. Solution: Task 5 Add fitting labels to your plot. For example, set the main title to display: “Impact of Work Experience on Trust in Politicians”. The x-axis label should read “Years of Work Experience in Journalism”, and the y-axis label should read “Trust in Politicians on a 5-point Likert Scale”. The label for the color legend should be “Country”. Solution: Task 6 Add a nice theme that you like, e.g. theme_minimal(), theme_classic() or theme_bw(). Solution: Solutions for Exercise 5 Task 1 Solution: data %&gt;% ggplot(aes(x = country, y = work_experience)) + geom_boxplot() + theme_bw() + labs(x = &quot;Country&quot;, y = &quot;Work Experience (Years)&quot;, title = &quot;Distribution of Work Experience by Country&quot;) Task 2 Solution: data %&gt;% ggplot(aes(x = work_experience, y = trust_government, color = country)) + geom_point() + theme_bw() + labs(x = &quot;Work Experience (Years)&quot;, y = &quot;Trust in Government&quot;, color = &quot;Country&quot;, title = &quot;Trust in Government by Work Experience and Country&quot;) Task 3 Solution: data %&gt;% ggplot(aes(x = work_experience, y = trust_government, color = country)) + geom_point() + geom_text(aes(label = name), check_overlap = TRUE, hjust = 0, vjust = 0) + theme_bw() + labs(x = &quot;Work Experience (Years)&quot;, y = &quot;Trust in Government&quot;, color = &quot;Country&quot;, title = &quot;Trust in Government by Work Experience and Country&quot;) Task 4 Solution: data %&gt;% ggplot(aes(x = country, fill = employment)) + geom_bar(position = &quot;dodge&quot;) + theme_bw() + labs(x = &quot;Country&quot;, y = &quot;Count&quot;, fill = &quot;Employment Type&quot;, title = &quot;Employment Types by Country&quot;) Alternative Solution: Those who prefer the width of the bars to be aligned can use this code: data %&gt;% ggplot(aes(x = country, fill = employment)) + geom_bar(position = position_dodge(preserve = &quot;single&quot;)) + theme_bw() + labs(x = &quot;Country&quot;, y = &quot;Count&quot;, fill = &quot;Employment Type&quot;, title = &quot;Employment Types by Country&quot;) Task 5 You can solve this exercise using two approaches. The first approach is to create a new variable called experience_level and save it in your original data set to be used for data visualization in the next, separate step: Solution: data &lt;- data %&gt;% mutate(experience_level = case_when( work_experience &lt;= 10 ~ &quot;Junior&quot;, work_experience &gt; 10 &amp; work_experience &lt;= 20 ~ &quot;Mid-Level&quot;, work_experience &gt; 20 ~ &quot;Senior&quot; )) data %&gt;% ggplot(aes(x = country, fill = employment)) + geom_bar(position = &quot;dodge&quot;) + theme_bw() + labs(x = &quot;Country&quot;, y = &quot;Count&quot;, fill = &quot;Employment Type&quot;, title = &quot;Employment Types by Country and Level of Experience&quot;) + facet_wrap(~experience_level) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) The more elegant solution is to perform your data management in one go without saving the variable experience_level back into your original data set. Using this approach will help declutter your data because you won’t need to create and save a new variable that is only required for a single visualization: data %&gt;% mutate(experience_level = case_when( work_experience &lt;= 10 ~ &quot;Junior&quot;, work_experience &gt; 10 &amp; work_experience &lt;= 20 ~ &quot;Mid-Level&quot;, work_experience &gt; 20 ~ &quot;Senior&quot; )) %&gt;% ggplot(aes(x = country, fill = employment)) + geom_bar(position = &quot;dodge&quot;) + theme_bw() + labs(x = &quot;Country&quot;, y = &quot;Count&quot;, fill = &quot;Employment Type&quot;, title = &quot;Employment Types by Country and Level of Experience&quot;) + facet_wrap(~experience_level) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) Solutions for Exercise 6 In this exercise, we will work with the mtcars data that comes pre-installed with dplyr. library(tidyverse) data &lt;- as_tibble(mtcars) # To make the data somewhat more interesting, let&#39;s set a few values to missing values: data$wt &lt;- na_if(data$wt, 4.070) data$mpg &lt;- na_if(data$mpg, 22.8) Task 1 Check the data set for missing values (NAs) and delete all observations that have missing values. Solution: You can solve this by excluding NAs in every single column: data &lt;- data %&gt;% # we&#39;ll now only keep observations that are NOT NAs in the following variables (remember that &amp; = AND): filter(!is.na(mpg) &amp; !is.na(cyl) &amp; !is.na(disp) &amp; !is.na(hp) &amp; !is.na(drat) &amp; !is.na(wt) &amp; !is.na(qsec) &amp; !is.na(vs) &amp; !is.na(am) &amp; !is.na(gear) &amp; !is.na(carb)) Alternatively, excluding NAs from the entire data set works, too, but you have not learned the drop_na()function in the tutorials: data &lt;- data %&gt;% drop_na() Task 2 Let’s transform the weight wt of the cars. Currently, it’s given as Weight in 1000 lbs. I guess you are not used to lbs, so try to mutate wt to represent Weight in 1000 kg. 1000 lbs = 453.59 kg, so we will need to divide by 2.20. Similarly, I think that you are not very familiar with the unit Miles per gallon of the mpg variable. Let’s transform it into Kilometer per liter. 1 m/g = 0.425144 km/l, so again divide by 2.20. Solution: data &lt;- data %&gt;% mutate(wt = wt / 2.20) data &lt;- data %&gt;% mutate(mpg = mpg / 2.20) Task 3 Now we want to group the weight of the cars in three categories: light, medium, heavy. But how to define light, medium, and heavy cars, i.e., at what kg should you put the threshold? A reasonable approach is to use quantiles (see Tutorial: summarize() [+ group_by()]). Quantiles divide data. For example, the 75% quantile states that exactly 75% of the data values are equal or below the quantile value. The rest of the values are equal or above it. Use the lower quantile (0.25) and the upper quantile (0.75) to estimate two values that divide the weight of the cars in three groups. What are these values? Solution: You can use dplyrfor this job: data %&gt;% summarize( LQ_wt = quantile(wt, 0.25), UQ_wt = quantile(wt, 0.75) ) ## # A tibble: 1 × 2 ## LQ_wt UQ_wt ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1.19 1.62 Or you can use the tidycomm package: data %&gt;% tidycomm::tab_percentiles(wt, levels = c(0.25, 0.75)) ## # A tibble: 1 × 3 ## Variable p25 p75 ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 wt 1.19 1.62 75% of all cars weigh 1.622727* 1000kg or less and 25% of all cars weigh 1.190909* 1000kg or less. Task 4 Use the values from Task 3 to create a new variable wt_cat that divides the cars in three groups: light, medium, and heavy cars. Solution: data &lt;- data %&gt;% mutate(wt_cat = case_when( wt &lt;= 1.190909 ~ &quot;light car&quot;, wt &lt; 1.622727 ~ &quot;medium car&quot;, wt &gt;= 1.622727 ~ &quot;heavy car&quot; )) Task 5 How many light, medium, and heavy cars are part of the data? Solution: You can solve this with the summarize(count = n() function: data %&gt;% group_by(wt_cat) %&gt;% summarize(count = n()) ## # A tibble: 3 × 2 ## wt_cat count ## &lt;chr&gt; &lt;int&gt; ## 1 heavy car 9 ## 2 light car 7 ## 3 medium car 13 9 heavy cars, 13 medium cars, and 7 light cars. Alternatively, you can also use the count() function: data %&gt;% count(wt_cat) ## # A tibble: 3 × 2 ## wt_cat n ## &lt;chr&gt; &lt;int&gt; ## 1 heavy car 9 ## 2 light car 7 ## 3 medium car 13 Alternatively, you can use the tab_frequencies() fucntion of the tidycomm: data %&gt;% tidycomm::tab_frequencies(wt_cat) ## # A tibble: 3 × 5 ## wt_cat n percent cum_n cum_percent ## * &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 heavy car 9 0.310 9 0.310 ## 2 light car 7 0.241 16 0.552 ## 3 medium car 13 0.448 29 1 Task 6 Now sort this count of the car weight classes from highest to lowest. Solution: data %&gt;% group_by(wt_cat) %&gt;% summarize(count = n()) %&gt;% arrange(desc(count)) ## # A tibble: 3 × 2 ## wt_cat count ## &lt;chr&gt; &lt;int&gt; ## 1 medium car 13 ## 2 heavy car 9 ## 3 light car 7 Alternatively, use tidycomm: data %&gt;% tidycomm::tab_frequencies(wt_cat) %&gt;% arrange(desc(n)) ## # A tibble: 3 × 5 ## wt_cat n percent cum_n cum_percent ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 medium car 13 0.448 29 1 ## 2 heavy car 9 0.310 9 0.310 ## 3 light car 7 0.241 16 0.552 Task 7 Make a scatter plot to indicate how many km per liter (mpg) a car can drive depending on its weight (wt). Facet the plot by weight class (wt_cat). Try to hide the plot legend (you have learned that in another exercise). Solution: data %&gt;% mutate(wt_cat = factor(wt_cat, levels = c(&quot;light car&quot;, &quot;medium car&quot;, &quot;heavy car&quot;))) %&gt;% ggplot(aes(x = wt, y = mpg)) + geom_point() + theme_bw() + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Relationship between car weight and\\n achieved kilometers per liter&quot;, x = &quot;Weight in 1000kg&quot;, y = &quot;km/l&quot;) + facet_wrap(~wt_cat) Alternatively, you can use tidycomm: data %&gt;% mutate(wt_cat = factor(wt_cat, levels = c(&quot;light car&quot;, &quot;medium car&quot;, &quot;heavy car&quot;))) %&gt;% tidycomm::correlate(wt, mpg) %&gt;% tidycomm::visualize() + labs(title = &quot;Relationship between car weight and\\n achieved kilometers per liter&quot;, x = &quot;Weight in 1000kg&quot;, y = &quot;km/l&quot;) + theme_bw() + facet_wrap(~wt_cat) Task 8 Recreate the diagram from Task 7, but exclude all cars that weigh between 1.4613636 and 1.5636364 *1000kg from it. Solution: data %&gt;% filter(wt &lt; 1.4613636 | wt &gt; 1.5636364) %&gt;% mutate(wt_cat = factor(wt_cat, levels = c(&quot;light car&quot;, &quot;medium car&quot;, &quot;heavy car&quot;))) %&gt;% ggplot(aes(x = wt, y = mpg)) + geom_point() + theme_bw() + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Relationship between car weight and\\n achieved kilometers per liter&quot;, x = &quot;Weight in 1000kg&quot;, y = &quot;km/l&quot;) + facet_wrap(~wt_cat) With tidycomm: data %&gt;% filter(wt &lt; 1.4613636 | wt &gt; 1.5636364) %&gt;% mutate(wt_cat = factor(wt_cat, levels = c(&quot;light car&quot;, &quot;medium car&quot;, &quot;heavy car&quot;))) %&gt;% tidycomm::correlate(wt, mpg) %&gt;% tidycomm::visualize() + labs(title = &quot;Relationship between car weight and\\n achieved kilometers per liter&quot;, x = &quot;Weight in 1000kg&quot;, y = &quot;km/l&quot;) + theme_bw() + facet_wrap(~wt_cat) Why would we use data %&gt;% filter(wt &lt; 1.4613636 | wt &gt; 1.5636364) instead of data %&gt;% filter(wt &gt; 1.4613636 | wt &lt; 1.5636364)? Let’s look at the resulting data sets when you apply those filters to compare them: data %&gt;% select(wt) %&gt;% filter(wt &lt; 1.4613636 | wt &gt; 1.5636364) ## # A tibble: 24 × 1 ## wt ## &lt;dbl&gt; ## 1 1.19 ## 2 1.31 ## 3 1.57 ## 4 1.62 ## 5 1.45 ## 6 1.70 ## 7 1.72 ## 8 2.39 ## 9 2.47 ## 10 2.43 ## # ℹ 14 more rows The resulting table does not include any cars that weigh between 1.4613636 and 1.5636364. But if you use data %&gt;% filter(wt &gt; 1.4613636 | wt &lt; 1.5636364)… data %&gt;% select(wt) %&gt;% filter(wt &gt; 1.4613636 | wt &lt; 1.5636364) ## # A tibble: 29 × 1 ## wt ## &lt;dbl&gt; ## 1 1.19 ## 2 1.31 ## 3 1.46 ## 4 1.56 ## 5 1.57 ## 6 1.62 ## 7 1.45 ## 8 1.56 ## 9 1.56 ## 10 1.70 ## # ℹ 19 more rows … cars that weigh between 1.4613636 and 1.5636364 are still included! But why? The filter()function always keeps cases based on the criteria that you provide. In plain English, my solution code says the following: Take my dataset “data” and keep only those cases where the weight variable wt is less than 1.4613636 OR larger than 1.5636364. Put differently, the solution code says: Delete all cases that are greater than 1.4613636 but are also less than 1.5636364. The wrong code, on the other hand, says: Take my dataset “data” and keep only those cases where the weight variable wt is greater than 1.4613636 OR smaller than 1.5636364. This is ALL the data because all your cases will be greater than 1.4613636 OR smaller than 1.5636364. You are not excluding any cars. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
